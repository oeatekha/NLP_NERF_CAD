{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVpB7lcsSZlZ"
      },
      "source": [
        "**Let's Figure Out how we can embed the text and floating point parameters**\n",
        "\n",
        "Embedding is the method in which a continue value or a discrete variable can be represented in a continuous vector. Embedding is a highly utilized method in machine translation and entity embedding for categorical variables. \n",
        "\n",
        "An embedding is a mapping of a discrete — categorical — variable to a vector of continuous numbers. In the context of neural networks, embeddings are low-dimensional, learned continuous vector representations of discrete variables.\n",
        "\n",
        "The primary reasons for embedding content is to the nearest neighbors within a given embedding space, as an input for a supervised task, or visualization of categories. \n",
        "\n",
        "In a nutshell, NN embeddings can easily take all 37,000 book articles on Wikipedia and represent each one using only 50 numbers in a vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytq4ceXn5Sk0"
      },
      "source": [
        "**MLP AutoEncoder**\n",
        "\n",
        "An autoencoder is not used for supervised learning. We will no longer try to predict something about our input. Instead, an autoencoder is considered a generative model: it learns a distributed representation of our training data, and can even be used to generate new instances of the training data.\n",
        "\n",
        "An autoencoder model contains two components:\n",
        "\n",
        "An encoder that takes an image as input, and outputs a high-dimensional embedding (representation) of the flaot.\n",
        "A decoder that takes the high-dimensional embedding, and reconstructs the float."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZenpAmxM5fJa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.nn import Embedding\n",
        "import os.path\n",
        "\n",
        "pathAE = \"/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD/autoencoder.pth\"\n",
        "\n",
        "class MLPAutoE(nn.Module):\n",
        "  # Initialize Neural Network\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # Encoder \n",
        "    self.encoder = nn.Sequential(\n",
        "      nn.Linear(1, 5),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(5, 10),\n",
        "      \n",
        "    )\n",
        "\n",
        "    # Decoder\n",
        "    self.decoder = nn.Sequential(\n",
        "      nn.Linear(10, 5),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(5, 1),\n",
        "      \n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    encoded = self.encoder(x) \n",
        "    decoded = self.decoder(encoded)\n",
        "\n",
        "    return decoded\n",
        "\n",
        "    # Note the last layer is range [0, infinity], so we will apply a relu function\n",
        "\n",
        "# Load the Model\n",
        "autoencoder = MLPAutoE()\n",
        "model = autoencoder \n",
        "model.load_state_dict(torch.load(pathAE))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCA_Vd11Xqjt"
      },
      "source": [
        "**Creating the Token Embedder**\n",
        "\n",
        "Then what I had in mind was:\n",
        "<CLS> ==> [tokenizer embedding module] ==> embedding in R^d\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk72jRN_SkTE",
        "outputId": "5def0f6d-6def-4d7a-a976-d259cc92a3dc"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.nn import Embedding\n",
        "pathE = \"/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD/embedder.pth\"\n",
        "\n",
        "\n",
        "\"\"\" The Embedding takes in the tokenized word and returns a R^d vector where d = 10. Our Language has 10 different words. within the dictionary\n",
        "    Although we are only using 7 different words in our language to begin with. \n",
        "    \n",
        "    Instead of generating random hidden layers, we can use the given weights to generate constant embeddings for our various words. This ensures, \n",
        "    that the embeddings are consistent and do not change. \n",
        "\n",
        "    The Code above is the same as the code below. The only difference is that the weights are given to the embedding layer. Furthermore,\n",
        "    the number_embeddings = 10, d is the length of the emvedding vector. d = 10.\n",
        "\"\"\"\n",
        "\n",
        "\" Create Embedding and set weights as a constant. \"\n",
        "weight = torch.FloatTensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
        "          0.0000,  0.0000],\n",
        "        [ 2.0938,  0.6383,  0.4265, -0.1057, -0.9903,  0.0483,  2.0725,  2.7587,\n",
        "          1.9364,  0.5201],\n",
        "        [-0.7956, -0.1561, -0.6276,  2.1033, -2.6051,  0.1143,  1.1203, -0.5265,\n",
        "          0.2124,  0.3033],\n",
        "        [ 0.2314, -1.1640, -0.5984,  0.5727, -1.4985,  0.0431, -0.2939,  1.4067,\n",
        "          0.9089, -0.5380],\n",
        "        [ 0.2106,  0.5994,  2.9547,  1.3907, -0.8808, -0.3567,  0.0752, -0.1998,\n",
        "         -1.2545, -1.0933],\n",
        "        [-0.6807,  0.1290, -0.8570, -0.0191,  1.2586, -0.6069,  0.5996,  0.7852,\n",
        "         -0.1459, -0.0803],\n",
        "        [ 1.0895, -0.9596,  0.0159,  0.3027,  1.2430,  0.7185,  0.1470,  0.2592,\n",
        "          1.7928, -1.2126],\n",
        "        [ 1.2758, -0.3504, -0.2135, -1.0314,  0.1238, -2.0741,  1.2185, -0.3169,\n",
        "         -0.4115,  0.5401],\n",
        "        [-1.7623, -0.3535,  0.2283, -0.3083, -1.4517, -1.0330, -0.4992, -1.3504,\n",
        "          0.0828, -0.4922],\n",
        "        [-0.7633, -0.5626, -0.1650,  3.0397, -1.5256, -0.8837,  1.1996, -1.1857,\n",
        "         -1.1322, -0.6586]])\n",
        "\n",
        "\n",
        "embedding = nn.Embedding.from_pretrained(weight)\n",
        "input = torch.LongTensor([7])\n",
        "embedding(input)\n",
        "\n",
        "torch.save(embedding.state_dict(), pathE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[CLS] Sphere { 78.05 }', '[CLS] Cubic { 17.69, 20.54, 56.97 }', '[CLS] Cylinder { 84.57, 98.97 }', '[CLS] Sphere { 63.46 }', '[CLS] Cylinder { 6.98, 2.55 }', '[CLS] Cubic { 37.43, 48.53, 99.02 }', '[CLS] Cylinder { 45.28, 73.16 }', '[CLS] Sphere { 12.7 }', '[CLS] Cubic { 23.12, 68.9, 55.91 }', '[CLS] Cylinder { 53.93, 67.91 }']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import random\n",
        "\n",
        "\n",
        "token_0 = \"[CLS]\"\n",
        "numberOfExamples = 500\n",
        "shapes = [\"Sphere\", \"Cylinder\", \"Cubic\"]\n",
        "\n",
        "#sentence = \"[CLS] Shape { 23.2,13,14.2 }\"\n",
        "\n",
        "def createSentece(numberOfExamples):\n",
        "    shapeList = []\n",
        "\n",
        "    for i in range(numberOfExamples):\n",
        "        shape = random.choice(shapes)\n",
        "        \n",
        "        sentence = \"\"\n",
        "\n",
        "        if shape == \"Sphere\":\n",
        "            radius = np.random.uniform(0, 100).__round__(2)\n",
        "            sentence = \"[CLS] \" + shape + \" { \" + str(radius) + \" }\"\n",
        "        elif shape == \"Cylinder\":\n",
        "            radius = np.random.uniform(0, 100).__round__(2)\n",
        "            height = np.random.uniform(0, 100).__round__(2)\n",
        "            sentence =  \"[CLS] \" + shape + \" { \" + str(radius) + \", \" + str(height) + \" }\" \n",
        "        elif shape == \"Cubic\":\n",
        "            length = np.random.uniform(0, 100).__round__(2)\n",
        "            height = np.random.uniform(0, 100).__round__(2)\n",
        "            width = np.random.uniform(0, 100).__round__(2)\n",
        "            sentence =  \"[CLS] \" + shape + \" { \" + str(length) + \", \" + str(height) + \", \" + str(width) + \" }\"\n",
        "        else:\n",
        "            print(\"Error\")\n",
        "\n",
        "        shapeList.append(sentence)\n",
        "        #print(sentence)\n",
        "    return shapeList\n",
        "\n",
        "generatedShape = createSentece(10)\n",
        "print(generatedShape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnVjX2uszakz"
      },
      "source": [
        "**Creating a Tokenizer and LxD Matrix for Transformers**\n",
        "\n",
        "Tokenization — this preprocessing step means transforming unstructured Natural Language input in something better structured (in computer terms). The main idea is to break the textual input into fragments that contain granular, yet useful data — these are called Tokens. \n",
        "\n",
        "Following the tokenization process and the MLP encoding into (1,10) vectors. We have to create a LxD matrix to pass into the nn.transformer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exzDP7mL17A_",
        "outputId": "19de4b99-03e9-4c99-8a68-b83b84464d48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([80, 7, 10])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.nn import Embedding\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "\n",
        "# Load the Models\n",
        "embeder = nn.Embedding(10, 10)\n",
        "embeder.load_state_dict(torch.load(pathE))\n",
        "#embeder(input)\n",
        "\n",
        "# Load the Model\n",
        "mlp = autoencoder = MLPAutoE()\n",
        "mlp.load_state_dict(torch.load(pathAE))\n",
        "#mlp.encoder(t)\n",
        "\n",
        "dictionary = \"\"\"[SEP] [CLS] Cylinder Sphere Cubic [SEP] { } ,\"\"\"\n",
        "sentence = \"[CLS] Cubic { 23.2,13,14.2 }\"\n",
        "tokens = dictionary.split()\n",
        "d = 10\n",
        "\n",
        "\n",
        "def processText(text):\n",
        "  text = text.replace('{', '{ ')\n",
        "  text = text.replace('}', '} ')\n",
        "  updatedText = text.replace(',', ' ').split(' ')\n",
        "  updatedText = ' '.join(updatedText).split()\n",
        "  return updatedText\n",
        "\n",
        "class token:\n",
        "  def __init__(self, tokens):\n",
        "    self.tokens = tokens.split()\n",
        "    self.embedding = nn.Embedding(50, d) \n",
        "    \n",
        "  def encode(self, sentence):\n",
        "\n",
        "    split = processText(sentence)\n",
        "    encoded = []\n",
        "    \n",
        "    for word in split:\n",
        "      if word in self.tokens:\n",
        "        encoded.append(self.tokens.index(word))\n",
        "      else:\n",
        "        encoded.append(word)\n",
        "\n",
        "    return encoded\n",
        "\n",
        "  def decode(self, encoded):\n",
        "    decoded = []\n",
        "    #print(encoded)\n",
        "    for i in encoded:\n",
        "      \n",
        "      if type(i) == str:\n",
        "        decoded.append(float(i))\n",
        "      else:\n",
        "        decoded.append(self.tokens[i])\n",
        "    return decoded\n",
        "\n",
        "\n",
        "  def tensorEncoded(self, encoded):\n",
        "    newList = []\n",
        "    tensorList = []\n",
        "    for i in encoded:\n",
        "      newList.append(float(i))\n",
        "\n",
        "    for i in newList:\n",
        "      tensorList.append(torch.tensor([i]))\n",
        "\n",
        "    return tensorList\n",
        "\n",
        "  def tensorList(self, encoded):\n",
        "    array = []\n",
        "    for i in encoded:\n",
        "      array.append(np.array(i)[0])\n",
        "\n",
        "    return(array)\n",
        "\n",
        "  def encodeD(self, sentence):\n",
        "    encoded = self.encode(sentence)\n",
        "    tensor = self.tensorEncoded(encoded)\n",
        "    D = torch.tensor([]) \n",
        "\n",
        "    for i in range(len(tensor)):\n",
        "      \n",
        "      if (i < 3) or (i == len(tensor) - 1):\n",
        "        temp = embeder(tensor[i].to(torch.int32))\n",
        "        #print(temp)\n",
        "        D = torch.cat((D, temp), 0)\n",
        "        #temp = embeder(tensor[i])\n",
        "        #temp = tensor[i].view(1, 10) \n",
        "      else:\n",
        "        temp = (mlp.encoder(tensor[i])).view(1, 10)\n",
        "        #print(temp)\n",
        "        D = torch.cat((D, temp), 0)\n",
        "        #print(tensor[i])\n",
        "        #tensor[i] = tensor[i]\n",
        "    if len(tensor) < 7:\n",
        "      for i in range(7 - len(tensor)):\n",
        "        temp = torch.zeros(1, 10)\n",
        "        D = torch.cat((D, temp), 0)\n",
        "      \n",
        "    \n",
        "    return D\n",
        "\n",
        "def createDataSet(text):\n",
        "  dataSet = []\n",
        "  for i in text:\n",
        "    dataSet.append(tokens.encodeD(i))\n",
        "  dataSet = torch.stack(dataSet)\n",
        "  return dataSet\n",
        "\n",
        "tokens = token(dictionary)\n",
        "encoded = tokens.encode(sentence)\n",
        "decoded = tokens.decode(encoded)\n",
        "tokens = token(dictionary)\n",
        "DataSentece = createSentece(100)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "DataSentece = createDataSet(DataSentece)\n",
        "train_data = DataSentece[:80] \n",
        "val_data = DataSentece[80:90] \n",
        "test_data = DataSentece[:90] \n",
        "\n",
        "train_data.shape\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Positional Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Create the Custom Transormer**\n",
        "\n",
        "Unlike a typical transformer, we ourselves, decode end encode the tokens of the sentence, allowing us to encode both words and floating points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset\n",
        "bptt = 1\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
        "                 nlayers: int, dropout: float = 0.5):\n",
        "        super().__init__()\n",
        "        self.model_type = 'Transformer'\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.d_model = d_model\n",
        "        self.decoder = nn.Linear(d_model, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "    \n",
        "    def encoder(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
        "\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src: Tensor, shape [seq_len, batch_size]\n",
        "            src_mask: Tensor, shape [seq_len, seq_len]\n",
        "\n",
        "        Returns:\n",
        "            output is encoded tensor \n",
        "        \"\"\"\n",
        "\n",
        "        src =  src * math.sqrt(self.d_model) #self.encoder(src) *\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        #print(output[0])\n",
        "        return output\n",
        "\n",
        "    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src: Tensor, shape [seq_len, batch_size]\n",
        "            src_mask: Tensor, shape [seq_len, seq_len]\n",
        "\n",
        "        Returns:\n",
        "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
        "        \"\"\"\n",
        "\n",
        "        output = self.encoder(src, src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return output\n",
        "\n",
        "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
        "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
        "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
        "\n",
        "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        source: Tensor, shape [full_seq_len, batch_size]\n",
        "        i: int\n",
        "\n",
        "    Returns:\n",
        "        tuple (data, target), where data has shape [seq_len, batch_size] and\n",
        "        target has shape [seq_len * batch_size]\n",
        "    \"\"\"\n",
        "    seq_len = min(bptt, len(source) - 1 - i)\n",
        "    #print(seq_len)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len]\n",
        "    return data, target\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Train the Model**\n",
        "\n",
        "During this step we have to train the model to ensure our decoder can effectively account for the position of each word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import copy\n",
        "import time\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 5.0  # learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "pathAE = \"/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD/transformer.pth\"\n",
        "ntokens = 10 \n",
        "\n",
        "def train(model: nn.Module) -> None:\n",
        "    model.train()  # turn on train mode\n",
        "    total_loss = 0.\n",
        "    log_interval = 200\n",
        "    start_time = time.time()\n",
        "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
        "\n",
        "    num_batches = len(train_data) // bptt\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
        "        data, targets = get_batch(train_data, i)\n",
        "        seq_len = data.size(0)\n",
        "        if seq_len != bptt:  # only on last batch\n",
        "            src_mask = src_mask[:seq_len, :seq_len]\n",
        "        output = model(data, src_mask)\n",
        "        loss = criterion(output.view(-1, ntokens), targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            lr = scheduler.get_last_lr()[0]\n",
        "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "            cur_loss = total_loss / log_interval\n",
        "            ppl = math.exp(cur_loss)\n",
        "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
        "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
        "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
        "    model.eval()  # turn on evaluation mode\n",
        "    total_loss = 0.\n",
        "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
        "            data, targets = get_batch(eval_data, i)\n",
        "            seq_len = data.size(0)\n",
        "            if seq_len != bptt:\n",
        "                src_mask = src_mask[:seq_len, :seq_len]\n",
        "            output = model(data, src_mask)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += seq_len * criterion(output_flat, targets).item()\n",
        "    return total_loss / (len(eval_data) - 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Intiate Sequence, Basically Create the transformermodel..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 2.0628,  1.6931,  1.1046, -1.6519, -1.1936,  2.2579,  4.3355,  0.4922,\n",
            "         -1.6703, -1.1022],\n",
            "        [ 0.6443,  0.5314,  0.1297,  0.3806,  0.4825,  0.3323,  0.6154, -0.4884,\n",
            "         -0.2348, -0.3301],\n",
            "        [ 1.8987,  1.5587,  0.9918, -1.4167, -0.9997,  2.0351,  3.9051,  0.3788,\n",
            "         -1.5042, -1.0129]], grad_fn=<SliceBackward0>)\n",
            "tensor([[ 0.6443,  0.5314,  0.1297,  0.3806,  0.4825,  0.3323,  0.6154, -0.4884,\n",
            "         -0.2348, -0.3301],\n",
            "        [ 1.8987,  1.5587,  0.9918, -1.4167, -0.9997,  2.0351,  3.9051,  0.3788,\n",
            "         -1.5042, -1.0129],\n",
            "        [ 1.2758, -0.3504, -0.2135, -1.0314,  0.1238, -2.0741,  1.2185, -0.3169,\n",
            "         -0.4115,  0.5401]], grad_fn=<SliceBackward0>)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 2.0938,  0.6383,  0.4265, -0.1057, -0.9903,  0.0483,  2.0725,  2.7587,\n",
              "          1.9364,  0.5201],\n",
              "        [ 0.2106,  0.5994,  2.9547,  1.3907, -0.8808, -0.3567,  0.0752, -0.1998,\n",
              "         -1.2545, -1.0933],\n",
              "        [ 1.0895, -0.9596,  0.0159,  0.3027,  1.2430,  0.7185,  0.1470,  0.2592,\n",
              "          1.7928, -1.2126],\n",
              "        [ 2.0628,  1.6931,  1.1046, -1.6519, -1.1936,  2.2579,  4.3355,  0.4922,\n",
              "         -1.6703, -1.1022],\n",
              "        [ 0.6443,  0.5314,  0.1297,  0.3806,  0.4825,  0.3323,  0.6154, -0.4884,\n",
              "         -0.2348, -0.3301],\n",
              "        [ 1.8987,  1.5587,  0.9918, -1.4167, -0.9997,  2.0351,  3.9051,  0.3788,\n",
              "         -1.5042, -1.0129],\n",
              "        [ 1.2758, -0.3504, -0.2135, -1.0314,  0.1238, -2.0741,  1.2185, -0.3169,\n",
              "         -0.4115,  0.5401]], grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "ntokens = 10  # size of vocabulary\n",
        "d_model = 10  # embedding dimension\n",
        "d_hid = 200  # dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 6  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 10  # number of heads in nn.MultiheadAttention\n",
        "dropout = 0.2  # dropout probability\n",
        "model = TransformerModel(ntokens, d_model, nhead, d_hid, nlayers, dropout).to(device)\n",
        "\n",
        "train_data[0]\n",
        "\n",
        "bptt = 3\n",
        "#for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
        "        \n",
        "        #bptt = 3\n",
        "        #data, targets = get_batch(train_data[i], i)\n",
        "        #print(\"training sentence \" , i  , \" \")\n",
        "       # print(train_data[i])\n",
        "       #print()\n",
        "\n",
        "#print(data)\n",
        "#print(targets[0])\n",
        "#print(train_data[0])\n",
        "# \n",
        "data, targets = get_batch(train_data[0], 3)      \n",
        "print(data)\n",
        "print(targets)      \n",
        "train_data[0]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Training the Embedding Models**\n",
        "\n",
        "Below is the code that allows us to embed our sentence and floating parameters to a higer dimensional space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVXSbBSD-Pi6",
        "outputId": "09d3b677-3dad-40d8-bb51-05be7a20f0b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1, Loss:0.000001\n",
            "Epoch:1, Loss:0.001319\n",
            "Epoch:1, Loss:0.000083\n",
            "Epoch:1, Loss:0.118781\n",
            "Epoch:1, Loss:0.000000\n",
            "Epoch:1, Loss:0.145028\n",
            "Epoch:1, Loss:0.735905\n",
            "Epoch:1, Loss:0.003593\n",
            "Epoch:11, Loss:0.000260\n",
            "Epoch:11, Loss:0.000247\n",
            "Epoch:11, Loss:0.000232\n",
            "Epoch:11, Loss:0.005157\n",
            "Epoch:11, Loss:0.000297\n",
            "Epoch:11, Loss:0.002096\n",
            "Epoch:11, Loss:0.001132\n",
            "Epoch:11, Loss:0.000203\n",
            "Epoch:21, Loss:0.000553\n",
            "Epoch:21, Loss:0.000088\n",
            "Epoch:21, Loss:0.000050\n",
            "Epoch:21, Loss:0.759409\n",
            "Epoch:21, Loss:0.000052\n",
            "Epoch:21, Loss:0.876105\n",
            "Epoch:21, Loss:2.259578\n",
            "Epoch:21, Loss:0.357284\n",
            "Epoch:31, Loss:0.000229\n",
            "Epoch:31, Loss:0.000202\n",
            "Epoch:31, Loss:0.000176\n",
            "Epoch:31, Loss:0.000426\n",
            "Epoch:31, Loss:0.000159\n",
            "Epoch:31, Loss:0.000199\n",
            "Epoch:31, Loss:0.000179\n",
            "Epoch:31, Loss:0.000021\n",
            "Epoch:41, Loss:0.000000\n",
            "Epoch:41, Loss:0.000001\n",
            "Epoch:41, Loss:0.000004\n",
            "Epoch:41, Loss:0.001920\n",
            "Epoch:41, Loss:0.000003\n",
            "Epoch:41, Loss:0.001667\n",
            "Epoch:41, Loss:0.003011\n",
            "Epoch:41, Loss:0.000443\n",
            "Epoch:51, Loss:0.000879\n",
            "Epoch:51, Loss:0.000055\n",
            "Epoch:51, Loss:0.000308\n",
            "Epoch:51, Loss:1.200616\n",
            "Epoch:51, Loss:0.000526\n",
            "Epoch:51, Loss:1.327483\n",
            "Epoch:51, Loss:9.207635\n",
            "Epoch:51, Loss:0.279074\n",
            "Epoch:61, Loss:0.007847\n",
            "Epoch:61, Loss:0.007436\n",
            "Epoch:61, Loss:0.007005\n",
            "Epoch:61, Loss:0.007345\n",
            "Epoch:61, Loss:0.007043\n",
            "Epoch:61, Loss:0.002217\n",
            "Epoch:61, Loss:0.003109\n",
            "Epoch:61, Loss:0.000003\n",
            "Epoch:71, Loss:0.000135\n",
            "Epoch:71, Loss:0.000125\n",
            "Epoch:71, Loss:0.000116\n",
            "Epoch:71, Loss:0.000114\n",
            "Epoch:71, Loss:0.000112\n",
            "Epoch:71, Loss:0.000022\n",
            "Epoch:71, Loss:0.000063\n",
            "Epoch:71, Loss:0.000000\n",
            "Epoch:81, Loss:0.000000\n",
            "Epoch:81, Loss:0.000000\n",
            "Epoch:81, Loss:0.000000\n",
            "Epoch:81, Loss:0.000001\n",
            "Epoch:81, Loss:0.000000\n",
            "Epoch:81, Loss:0.000000\n",
            "Epoch:81, Loss:0.000000\n",
            "Epoch:81, Loss:0.000000\n",
            "Epoch:91, Loss:0.000001\n",
            "Epoch:91, Loss:0.000001\n",
            "Epoch:91, Loss:0.000001\n",
            "Epoch:91, Loss:0.000003\n",
            "Epoch:91, Loss:0.000001\n",
            "Epoch:91, Loss:0.000003\n",
            "Epoch:91, Loss:0.000003\n",
            "Epoch:91, Loss:0.000001\n",
            "Epoch:101, Loss:0.000001\n",
            "Epoch:101, Loss:0.000003\n",
            "Epoch:101, Loss:0.000006\n",
            "Epoch:101, Loss:0.002024\n",
            "Epoch:101, Loss:0.000005\n",
            "Epoch:101, Loss:0.001788\n",
            "Epoch:101, Loss:0.005054\n",
            "Epoch:101, Loss:0.000393\n",
            "Epoch:111, Loss:0.001818\n",
            "Epoch:111, Loss:0.000198\n",
            "Epoch:111, Loss:0.000338\n",
            "Epoch:111, Loss:1.780736\n",
            "Epoch:111, Loss:0.000889\n",
            "Epoch:111, Loss:2.256012\n",
            "Epoch:111, Loss:15.681774\n",
            "Epoch:111, Loss:0.591175\n",
            "Epoch:121, Loss:0.014341\n",
            "Epoch:121, Loss:0.013702\n",
            "Epoch:121, Loss:0.013011\n",
            "Epoch:121, Loss:0.037737\n",
            "Epoch:121, Loss:0.013880\n",
            "Epoch:121, Loss:0.012802\n",
            "Epoch:121, Loss:0.000098\n",
            "Epoch:121, Loss:0.001136\n",
            "Epoch:131, Loss:0.000441\n",
            "Epoch:131, Loss:0.000408\n",
            "Epoch:131, Loss:0.000376\n",
            "Epoch:131, Loss:0.000392\n",
            "Epoch:131, Loss:0.000362\n",
            "Epoch:131, Loss:0.000095\n",
            "Epoch:131, Loss:0.000113\n",
            "Epoch:131, Loss:0.000003\n",
            "Epoch:141, Loss:0.000005\n",
            "Epoch:141, Loss:0.000005\n",
            "Epoch:141, Loss:0.000004\n",
            "Epoch:141, Loss:0.000006\n",
            "Epoch:141, Loss:0.000004\n",
            "Epoch:141, Loss:0.000002\n",
            "Epoch:141, Loss:0.000002\n",
            "Epoch:141, Loss:0.000000\n",
            "Epoch:151, Loss:0.000000\n",
            "Epoch:151, Loss:0.000000\n",
            "Epoch:151, Loss:0.000000\n",
            "Epoch:151, Loss:0.000000\n",
            "Epoch:151, Loss:0.000000\n",
            "Epoch:151, Loss:0.000000\n",
            "Epoch:151, Loss:0.000000\n",
            "Epoch:151, Loss:0.000000\n",
            "Epoch:161, Loss:0.000000\n",
            "Epoch:161, Loss:0.000001\n",
            "Epoch:161, Loss:0.000001\n",
            "Epoch:161, Loss:0.000027\n",
            "Epoch:161, Loss:0.000001\n",
            "Epoch:161, Loss:0.000032\n",
            "Epoch:161, Loss:0.000183\n",
            "Epoch:161, Loss:0.000008\n",
            "Epoch:171, Loss:0.000000\n",
            "Epoch:171, Loss:0.000004\n",
            "Epoch:171, Loss:0.000013\n",
            "Epoch:171, Loss:0.006367\n",
            "Epoch:171, Loss:0.000012\n",
            "Epoch:171, Loss:0.006057\n",
            "Epoch:171, Loss:0.017906\n",
            "Epoch:171, Loss:0.001531\n",
            "Epoch:181, Loss:0.000193\n",
            "Epoch:181, Loss:0.000079\n",
            "Epoch:181, Loss:0.001207\n",
            "Epoch:181, Loss:2.233437\n",
            "Epoch:181, Loss:0.000878\n",
            "Epoch:181, Loss:2.181679\n",
            "Epoch:181, Loss:8.874692\n",
            "Epoch:181, Loss:0.542893\n",
            "Epoch:191, Loss:0.000316\n",
            "Epoch:191, Loss:0.000316\n",
            "Epoch:191, Loss:0.000321\n",
            "Epoch:191, Loss:0.000050\n",
            "Epoch:191, Loss:0.000334\n",
            "Epoch:191, Loss:0.000921\n",
            "Epoch:191, Loss:0.013237\n",
            "Epoch:191, Loss:0.000585\n",
            "Epoch:201, Loss:0.000001\n",
            "Epoch:201, Loss:0.000001\n",
            "Epoch:201, Loss:0.000001\n",
            "Epoch:201, Loss:0.000003\n",
            "Epoch:201, Loss:0.000001\n",
            "Epoch:201, Loss:0.000002\n",
            "Epoch:201, Loss:0.000002\n",
            "Epoch:201, Loss:0.000000\n",
            "Epoch:211, Loss:0.000001\n",
            "Epoch:211, Loss:0.000001\n",
            "Epoch:211, Loss:0.000001\n",
            "Epoch:211, Loss:0.000001\n",
            "Epoch:211, Loss:0.000001\n",
            "Epoch:211, Loss:0.000001\n",
            "Epoch:211, Loss:0.000000\n",
            "Epoch:211, Loss:0.000001\n",
            "Epoch:221, Loss:0.000000\n",
            "Epoch:221, Loss:0.000000\n",
            "Epoch:221, Loss:0.000001\n",
            "Epoch:221, Loss:0.000011\n",
            "Epoch:221, Loss:0.000001\n",
            "Epoch:221, Loss:0.000011\n",
            "Epoch:221, Loss:0.000035\n",
            "Epoch:221, Loss:0.000003\n",
            "Epoch:231, Loss:0.000000\n",
            "Epoch:231, Loss:0.000001\n",
            "Epoch:231, Loss:0.000002\n",
            "Epoch:231, Loss:0.000733\n",
            "Epoch:231, Loss:0.000002\n",
            "Epoch:231, Loss:0.000695\n",
            "Epoch:231, Loss:0.001690\n",
            "Epoch:231, Loss:0.000195\n",
            "Epoch:241, Loss:0.000106\n",
            "Epoch:241, Loss:0.000017\n",
            "Epoch:241, Loss:0.000007\n",
            "Epoch:241, Loss:0.108536\n",
            "Epoch:241, Loss:0.000008\n",
            "Epoch:241, Loss:0.108200\n",
            "Epoch:241, Loss:0.736809\n",
            "Epoch:241, Loss:0.015485\n",
            "Epoch:251, Loss:0.002135\n",
            "Epoch:251, Loss:0.001629\n",
            "Epoch:251, Loss:0.001118\n",
            "Epoch:251, Loss:0.002214\n",
            "Epoch:251, Loss:0.000541\n",
            "Epoch:251, Loss:0.029642\n",
            "Epoch:251, Loss:0.301489\n",
            "Epoch:251, Loss:0.017367\n",
            "Epoch:261, Loss:0.000003\n",
            "Epoch:261, Loss:0.000003\n",
            "Epoch:261, Loss:0.000002\n",
            "Epoch:261, Loss:0.000016\n",
            "Epoch:261, Loss:0.000002\n",
            "Epoch:261, Loss:0.000006\n",
            "Epoch:261, Loss:0.000009\n",
            "Epoch:261, Loss:0.000000\n",
            "Epoch:271, Loss:0.000001\n",
            "Epoch:271, Loss:0.000001\n",
            "Epoch:271, Loss:0.000001\n",
            "Epoch:271, Loss:0.000025\n",
            "Epoch:271, Loss:0.000001\n",
            "Epoch:271, Loss:0.000026\n",
            "Epoch:271, Loss:0.000116\n",
            "Epoch:271, Loss:0.000007\n",
            "Epoch:281, Loss:0.000000\n",
            "Epoch:281, Loss:0.000000\n",
            "Epoch:281, Loss:0.000000\n",
            "Epoch:281, Loss:0.000023\n",
            "Epoch:281, Loss:0.000000\n",
            "Epoch:281, Loss:0.000026\n",
            "Epoch:281, Loss:0.000153\n",
            "Epoch:281, Loss:0.000006\n",
            "Epoch:291, Loss:0.000000\n",
            "Epoch:291, Loss:0.000000\n",
            "Epoch:291, Loss:0.000000\n",
            "Epoch:291, Loss:0.000404\n",
            "Epoch:291, Loss:0.000000\n",
            "Epoch:291, Loss:0.000344\n",
            "Epoch:291, Loss:0.001079\n",
            "Epoch:291, Loss:0.000078\n",
            "Epoch:301, Loss:0.000003\n",
            "Epoch:301, Loss:0.000002\n",
            "Epoch:301, Loss:0.000024\n",
            "Epoch:301, Loss:0.033550\n",
            "Epoch:301, Loss:0.000020\n",
            "Epoch:301, Loss:0.030280\n",
            "Epoch:301, Loss:0.063673\n",
            "Epoch:301, Loss:0.008178\n",
            "Epoch:311, Loss:0.004567\n",
            "Epoch:311, Loss:0.002060\n",
            "Epoch:311, Loss:0.000400\n",
            "Epoch:311, Loss:1.098313\n",
            "Epoch:311, Loss:0.000145\n",
            "Epoch:311, Loss:1.356463\n",
            "Epoch:311, Loss:8.877147\n",
            "Epoch:311, Loss:0.330793\n",
            "Epoch:321, Loss:0.004855\n",
            "Epoch:321, Loss:0.004754\n",
            "Epoch:321, Loss:0.004640\n",
            "Epoch:321, Loss:0.000004\n",
            "Epoch:321, Loss:0.004628\n",
            "Epoch:321, Loss:0.000824\n",
            "Epoch:321, Loss:0.004921\n",
            "Epoch:321, Loss:0.001364\n",
            "Epoch:331, Loss:0.000018\n",
            "Epoch:331, Loss:0.000016\n",
            "Epoch:331, Loss:0.000015\n",
            "Epoch:331, Loss:0.000016\n",
            "Epoch:331, Loss:0.000014\n",
            "Epoch:331, Loss:0.000003\n",
            "Epoch:331, Loss:0.000003\n",
            "Epoch:331, Loss:0.000000\n",
            "Epoch:341, Loss:0.000000\n",
            "Epoch:341, Loss:0.000000\n",
            "Epoch:341, Loss:0.000000\n",
            "Epoch:341, Loss:0.000000\n",
            "Epoch:341, Loss:0.000000\n",
            "Epoch:341, Loss:0.000000\n",
            "Epoch:341, Loss:0.000000\n",
            "Epoch:341, Loss:0.000000\n",
            "Epoch:351, Loss:0.000000\n",
            "Epoch:351, Loss:0.000000\n",
            "Epoch:351, Loss:0.000000\n",
            "Epoch:351, Loss:0.000007\n",
            "Epoch:351, Loss:0.000000\n",
            "Epoch:351, Loss:0.000007\n",
            "Epoch:351, Loss:0.000018\n",
            "Epoch:351, Loss:0.000002\n",
            "Epoch:361, Loss:0.000001\n",
            "Epoch:361, Loss:0.000003\n",
            "Epoch:361, Loss:0.000007\n",
            "Epoch:361, Loss:0.002811\n",
            "Epoch:361, Loss:0.000006\n",
            "Epoch:361, Loss:0.002579\n",
            "Epoch:361, Loss:0.005496\n",
            "Epoch:361, Loss:0.000725\n",
            "Epoch:371, Loss:0.000420\n",
            "Epoch:371, Loss:0.000101\n",
            "Epoch:371, Loss:0.000002\n",
            "Epoch:371, Loss:0.295885\n",
            "Epoch:371, Loss:0.000006\n",
            "Epoch:371, Loss:0.298918\n",
            "Epoch:371, Loss:2.047957\n",
            "Epoch:371, Loss:0.044189\n",
            "Epoch:381, Loss:0.003430\n",
            "Epoch:381, Loss:0.003151\n",
            "Epoch:381, Loss:0.002843\n",
            "Epoch:381, Loss:0.001826\n",
            "Epoch:381, Loss:0.002284\n",
            "Epoch:381, Loss:0.000014\n",
            "Epoch:381, Loss:0.003679\n",
            "Epoch:381, Loss:0.000024\n",
            "Epoch:391, Loss:0.000005\n",
            "Epoch:391, Loss:0.000004\n",
            "Epoch:391, Loss:0.000004\n",
            "Epoch:391, Loss:0.000009\n",
            "Epoch:391, Loss:0.000004\n",
            "Epoch:391, Loss:0.000002\n",
            "Epoch:391, Loss:0.000000\n",
            "Epoch:391, Loss:0.000000\n",
            "Epoch:401, Loss:0.000000\n",
            "Epoch:401, Loss:0.000000\n",
            "Epoch:401, Loss:0.000000\n",
            "Epoch:401, Loss:0.000001\n",
            "Epoch:401, Loss:0.000000\n",
            "Epoch:401, Loss:0.000001\n",
            "Epoch:401, Loss:0.000002\n",
            "Epoch:401, Loss:0.000001\n",
            "Epoch:411, Loss:0.000000\n",
            "Epoch:411, Loss:0.000000\n",
            "Epoch:411, Loss:0.000000\n",
            "Epoch:411, Loss:0.000002\n",
            "Epoch:411, Loss:0.000000\n",
            "Epoch:411, Loss:0.000003\n",
            "Epoch:411, Loss:0.000015\n",
            "Epoch:411, Loss:0.000001\n",
            "Epoch:421, Loss:0.000001\n",
            "Epoch:421, Loss:0.000000\n",
            "Epoch:421, Loss:0.000000\n",
            "Epoch:421, Loss:0.000273\n",
            "Epoch:421, Loss:0.000000\n",
            "Epoch:421, Loss:0.000290\n",
            "Epoch:421, Loss:0.001884\n",
            "Epoch:421, Loss:0.000054\n",
            "Epoch:431, Loss:0.000021\n",
            "Epoch:431, Loss:0.000003\n",
            "Epoch:431, Loss:0.000002\n",
            "Epoch:431, Loss:0.038059\n",
            "Epoch:431, Loss:0.000000\n",
            "Epoch:431, Loss:0.031957\n",
            "Epoch:431, Loss:0.121114\n",
            "Epoch:431, Loss:0.005930\n",
            "Epoch:441, Loss:0.001592\n",
            "Epoch:441, Loss:0.000075\n",
            "Epoch:441, Loss:0.000675\n",
            "Epoch:441, Loss:2.347718\n",
            "Epoch:441, Loss:0.001297\n",
            "Epoch:441, Loss:2.648516\n",
            "Epoch:441, Loss:6.415340\n",
            "Epoch:441, Loss:0.970775\n",
            "Epoch:451, Loss:0.006464\n",
            "Epoch:451, Loss:0.006115\n",
            "Epoch:451, Loss:0.005772\n",
            "Epoch:451, Loss:0.000268\n",
            "Epoch:451, Loss:0.005491\n",
            "Epoch:451, Loss:0.000349\n",
            "Epoch:451, Loss:0.005645\n",
            "Epoch:451, Loss:0.000976\n",
            "Epoch:461, Loss:0.000027\n",
            "Epoch:461, Loss:0.000025\n",
            "Epoch:461, Loss:0.000022\n",
            "Epoch:461, Loss:0.000035\n",
            "Epoch:461, Loss:0.000021\n",
            "Epoch:461, Loss:0.000011\n",
            "Epoch:461, Loss:0.000002\n",
            "Epoch:461, Loss:0.000001\n",
            "Epoch:471, Loss:0.000000\n",
            "Epoch:471, Loss:0.000000\n",
            "Epoch:471, Loss:0.000000\n",
            "Epoch:471, Loss:0.000000\n",
            "Epoch:471, Loss:0.000000\n",
            "Epoch:471, Loss:0.000000\n",
            "Epoch:471, Loss:0.000000\n",
            "Epoch:471, Loss:0.000000\n",
            "Epoch:481, Loss:0.000000\n",
            "Epoch:481, Loss:0.000001\n",
            "Epoch:481, Loss:0.000001\n",
            "Epoch:481, Loss:0.000008\n",
            "Epoch:481, Loss:0.000001\n",
            "Epoch:481, Loss:0.000009\n",
            "Epoch:481, Loss:0.000018\n",
            "Epoch:481, Loss:0.000003\n",
            "Epoch:491, Loss:0.000000\n",
            "Epoch:491, Loss:0.000000\n",
            "Epoch:491, Loss:0.000000\n",
            "Epoch:491, Loss:0.000077\n",
            "Epoch:491, Loss:0.000000\n",
            "Epoch:491, Loss:0.000085\n",
            "Epoch:491, Loss:0.000528\n",
            "Epoch:491, Loss:0.000018\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'path' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD/Embbeding_and_Encoders.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m outputs\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m train(autoencoder, \u001b[39m500\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m torch\u001b[39m.\u001b[39msave(autoencoder\u001b[39m.\u001b[39mstate_dict(), path)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
          ]
        }
      ],
      "source": [
        "# Let's Train the AutoEncoder on a small generated set of data that should not be too terrible.\n",
        "def train(model, num_epochs):\n",
        "\n",
        "  criterion = nn.MSELoss()\n",
        "  autoencoder = model\n",
        "  optimizer = torch.optim.Adam(autoencoder.parameters(), lr=1e-3, weight_decay=1e-3)\n",
        "  outputs = []\n",
        "  data_set = torch.tensor([[1.65], [2], [2.3], [54], [1.3], [43.2], [120.324], [32.123]])\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    for p_i in data_set:\n",
        "      p_pred = autoencoder(p_i)\n",
        "      loss = criterion(p_i, p_pred)\n",
        "\n",
        "      \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      #print(\"p_i: \", p_i, \" predicted: \", p_pred)\n",
        "      if epoch % 10 == 0:\n",
        "        print(f'Epoch:{epoch+1}, Loss:{loss.item():4f}')\n",
        "\n",
        "    outputs.append((epoch, p_i, p_pred))\n",
        "  \n",
        "  return outputs\n",
        "\n",
        "train(autoencoder, 500)\n",
        "torch.save(autoencoder.state_dict(), path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "72OErFNTV0JC",
        "outputId": "60f8bafd-081a-48ac-f6c5-a55fcf95e33b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'path' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD/Embbeding_and_Encoders.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Load the Model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model \u001b[39m=\u001b[39m autoencoder \u001b[39m=\u001b[39m MLPAutoE()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(path))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model\u001b[39m.\u001b[39mencoder(t)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
          ]
        }
      ],
      "source": [
        "# Check the model\n",
        "t = torch.tensor([[1], [2], [2.3], [54], [1.3], [43.2], [120.324], [32.123]])\n",
        "P_t = autoencoder.encoder(t)\n",
        "autoencoder.decoder(P_t)\n",
        "\n",
        "# Load the Model\n",
        "model = autoencoder = MLPAutoE()\n",
        "model.load_state_dict(torch.load(path))\n",
        "model.encoder(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InajYBPlYpno"
      },
      "source": [
        "**MLP Encoder**\n",
        "\n",
        "Now if you want to share the same MLP encoder for all numerical inputs (regardless of whether they are radius or height measurements,  etc), then your MLP encoder would take in R^1 and output R^d. These are floating point values, for both input and output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUDrvlGoYo0Q",
        "outputId": "69090ab0-6628-4ebb-963b-ed23cd3ee8aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.3786,  0.3023,  0.3095,  0.0118,  0.4308,  0.1019,  0.0553,  0.1434,\n",
            "          0.1401, -0.3750]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3786,  0.3023,  0.3095,  0.0118,  0.4308,  0.1019,  0.0553,  0.1434,\n",
            "          0.1401, -0.3750]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.nn import Embedding\n",
        "\n",
        "# MLP to take in a 1D float and encode it into a higher dimensional space.\n",
        "# Input:  Tensor of R^1  (Shape: (1, ))\n",
        "# Output: Tensor of R^10 (Shape: (1, 10))\n",
        "\n",
        "# Create Encoder and Decoder Model with some random hidden weights and layers\n",
        "\n",
        "inputsize = (1,)\n",
        "outputsize = (1,10)\n",
        "t = torch.tensor([[1.5]])\n",
        "\n",
        "class MLPEncoder(nn.Module):\n",
        "  # Initialize Neural Network\n",
        "  def __init__(self):\n",
        "    super(MLPEncoder, self).__init__()\n",
        "    self.l1 = nn.Linear(1, 5)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.l2 = nn.Linear(5, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.l1(x) \n",
        "    output = self.relu(output)\n",
        "    output = self.l2(output)\n",
        "    return output\n",
        "\n",
        "net = MLPEncoder()\n",
        "\n",
        "outputs = net(t)\n",
        "print(outputs)\n",
        "outputs = net(t)\n",
        "print(outputs)\n",
        "\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "177def0c22df55f44c7bc43ed6b35a63880eb2c6466160d1b315a26cc91306d6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
