{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVpB7lcsSZlZ"
      },
      "source": [
        "**Let's Figure Out how we can embed the text and floating point parameters**\n",
        "\n",
        "Embedding is the method in which a continue value or a discrete variable can be represented in a continuous vector. Embedding is a highly utilized method in machine translation and entity embedding for categorical variables. \n",
        "\n",
        "An embedding is a mapping of a discrete — categorical — variable to a vector of continuous numbers. In the context of neural networks, embeddings are low-dimensional, learned continuous vector representations of discrete variables.\n",
        "\n",
        "The primary reasons for embedding content is to the nearest neighbors within a given embedding space, as an input for a supervised task, or visualization of categories. \n",
        "\n",
        "In a nutshell, NN embeddings can easily take all 37,000 book articles on Wikipedia and represent each one using only 50 numbers in a vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCA_Vd11Xqjt"
      },
      "source": [
        "**Creating the Token Embedder**\n",
        "\n",
        "Then what I had in mind was:\n",
        "<CLS> ==> [tokenizer embedding module] ==> embedding in R^d\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 356,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[CLS] Cubic { 2.61, 4.69, 1.49 }', '[CLS] Cubic { 2.47, 4.2, 1.11 }', '[CLS] Cylinder { 3.8, 1.21 }', '[CLS] Sphere { 1.54 }', '[CLS] Sphere { 2.4 }', '[CLS] Cylinder { 3.36, 2.12 }', '[CLS] Cylinder { 1.5, 3.22 }', '[CLS] Sphere { 2.81 }', '[CLS] Sphere { 4.64 }', '[CLS] Sphere { 3.59 }']\n",
            "6400\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import random\n",
        "import json\n",
        "\n",
        "\n",
        "\n",
        "token_0 = \"[CLS]\"\n",
        "numberOfExamples = 6400\n",
        "shapes = [\"Sphere\", \"Cylinder\", \"Cubic\"]\n",
        "\n",
        "#sentence = \"[CLS] Shape { 23.2,13,14.2 }\"\n",
        "\n",
        "def createSentece(numberOfExamples):\n",
        "    shapeList = []\n",
        "\n",
        "    for i in range(numberOfExamples):\n",
        "        shape = random.choice(shapes)\n",
        "        \n",
        "        sentence = \"\"\n",
        "\n",
        "        if shape == \"Sphere\":\n",
        "            radius = np.random.uniform(1, 5).__round__(2)\n",
        "            sentence = \"[CLS] \" + shape + \" { \" + str(radius) + \" }\"\n",
        "        elif shape == \"Cylinder\":\n",
        "            radius = np.random.uniform(1, 5).__round__(2)\n",
        "            height = np.random.uniform(1, 5).__round__(2)\n",
        "            sentence =  \"[CLS] \" + shape + \" { \" + str(radius) + \", \" + str(height) + \" }\" \n",
        "        elif shape == \"Cubic\":\n",
        "            length = np.random.uniform(1, 5).__round__(2)\n",
        "            height = np.random.uniform(1, 5).__round__(2)\n",
        "            width = np.random.uniform(1, 5).__round__(2)\n",
        "            sentence =  \"[CLS] \" + shape + \" { \" + str(length) + \", \" + str(height) + \", \" + str(width) + \" }\"\n",
        "        else:\n",
        "            print(\"Error\")\n",
        "\n",
        "        shapeList.append(sentence)\n",
        "        #print(sentence)\n",
        "    return shapeList\n",
        "\n",
        "generatedShape = createSentece(numberOfExamples)\n",
        "#print(generatedShape)\n",
        "\n",
        "with open(\"sentences.json\", 'w') as f:\n",
        "    json.dump(generatedShape, f, indent=2) \n",
        "\n",
        "with open(\"sentences.json\", 'r') as f:\n",
        "    s = json.load(f)\n",
        "\n",
        "print(s[:10])\n",
        "print(len(s))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Importing all Relevent Images and Data**\n",
        "\n",
        "This section is dedicated to importing all the images, of the dataset created in the json file above. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 0 directories and 64 images in '/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD/renders'.\n",
            "Random image path: /Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD/renders/3_300.png\n",
            "Image class: renders\n",
            "Image height: 500\n",
            "Image width: 500\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "#image_path = Path(\"/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD/renders\")\n",
        "\n",
        "image_path = Path(\"/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD\")\n",
        "train_dir = image_path / \"renders\"\n",
        "\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Walks through dir_path returning its contents.\n",
        "  Args:\n",
        "    dir_path (str or pathlib.Path): target directory\n",
        "  \n",
        "  Returns:\n",
        "    A print out of:\n",
        "      number of subdiretories in dir_path\n",
        "      number of images (files) in each subdirectory\n",
        "      name of each subdirectory\n",
        "  \"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
        "    \n",
        "walk_through_dir(train_dir)\n",
        "\n",
        "import random\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "# Set seed\n",
        "random.seed(42) # <- try changing this and see what happens\n",
        "\n",
        "# 1. Get all image paths (* means \"any combination\")\n",
        "image_path_list = list(train_dir.glob(\"*.png\"))\n",
        "train_image_list, valid_image_list = image_path_list[:int(0.8*len(image_path_list))], image_path_list[int(0.8*len(image_path_list)):] \n",
        "\n",
        "\n",
        "\n",
        "# 2. Get random image path\n",
        "random_image_path = random.choice(image_path_list)\n",
        "\n",
        "# 3. Get image class from path name (the image class is the name of the directory where the image is stored)\n",
        "image_class = random_image_path.parent.stem\n",
        "\n",
        "# 4. Open image\n",
        "img = Image.open(random_image_path)\n",
        "\n",
        "# 5. Print metadata\n",
        "print(f\"Random image path: {random_image_path}\")\n",
        "print(f\"Image class: {image_class}\")\n",
        "print(f\"Image height: {img.height}\") \n",
        "print(f\"Image width: {img.width}\")\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Turn the image into an array\n",
        "img_as_array = np.asarray(img)\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    # Resize the images to 64x64\n",
        "    transforms.Resize(size=(32, 32)),\n",
        "    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 \n",
        "])\n",
        "\n",
        "\n",
        "def plot_transformed_images(image_paths, transform, n=3, seed=42):\n",
        "    \"\"\"Plots a series of random images from image_paths.\n",
        "\n",
        "    Will open n image paths from image_paths, transform them\n",
        "    with transform and plot them side by side.\n",
        "\n",
        "    Args:\n",
        "        image_paths (list): List of target image paths. \n",
        "        transform (PyTorch Transforms): Transforms to apply to images.\n",
        "        n (int, optional): Number of images to plot. Defaults to 3.\n",
        "        seed (int, optional): Random seed for the random generator. Defaults to 42.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    random_image_paths = random.sample(image_paths, k=n)\n",
        "    for image_path in random_image_paths:\n",
        "        with Image.open(image_path) as f:\n",
        "            fig, ax = plt.subplots(1, 2)\n",
        "            ax[0].imshow(f) \n",
        "            ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
        "            ax[0].axis(\"off\")\n",
        "\n",
        "            # Transform and plot image\n",
        "            # Note: permute() will change shape of image to suit matplotlib \n",
        "            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])\n",
        "            transformed_image = transform(f).permute(1, 2, 0) \n",
        "            ax[1].imshow(transformed_image) \n",
        "            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
        "            ax[1].axis(\"off\")\n",
        "\n",
        "            \n",
        "\n",
        "plot_transformed_images(train_image_list, \n",
        "                        transform=data_transform, \n",
        "                        n=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Loading the Images using the dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 357,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD\n"
          ]
        }
      ],
      "source": [
        "# Use ImageFolder to create dataset(s)\n",
        "from torchvision import datasets\n",
        "image_path = Path(\"/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/\")\n",
        "train_dir = image_path / \"NLP_NERF_CAD\"\n",
        "\n",
        "\n",
        "\n",
        "print(train_dir)\n",
        "# Batch size will now be 32, try changing the batch_size parameter above and see what happens\n",
        "totalImgs = numberOfExamples\n",
        "\n",
        "img_data = datasets.ImageFolder(root=image_path, # target folder of images\n",
        "                                  transform=data_transform, # transforms to perform on data (images)\n",
        "                                  target_transform=None) # transforms to perform on labels (if necessary)\n",
        "\n",
        "\n",
        "img_dataloader = DataLoader(dataset=img_data, \n",
        "                              batch_size=numberOfExamples, # how many samples per batch?\n",
        "                              num_workers=1, # how many subprocesses to use for data loading? (higher = more)\n",
        "                              shuffle=False) # shuffle the data?\n",
        "\n",
        "img = next(iter(img_dataloader))[0].numpy()\n",
        "# I need to get total img dataset size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 358,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([6400, 3, 32, 32])"
            ]
          },
          "execution_count": 358,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#img[0].shape\n",
        "#img_data.shape\n",
        "img = next(iter(img_dataloader))[0]\n",
        "img.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnVjX2uszakz"
      },
      "source": [
        "**Creating a Tokenizer and LxD Matrix for Transformers**\n",
        "\n",
        "Tokenization — this preprocessing step means transforming unstructured Natural Language input in something better structured (in computer terms). The main idea is to break the textual input into fragments that contain granular, yet useful data — these are called Tokens. \n",
        "\n",
        "Following the tokenization process and the MLP encoding into (1,10) vectors. We have to create a LxD matrix to pass into the nn.transformer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exzDP7mL17A_",
        "outputId": "19de4b99-03e9-4c99-8a68-b83b84464d48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "([1.0, 4.0, 6.0, 23.2, 13.0, 14.2, 7.0], [1, 1, 1, 0, 0, 0, 1])\n"
          ]
        }
      ],
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.nn import Embedding\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "\n",
        "dictionary = \"\"\"[SEP] [CLS] Cylinder Sphere Cubic [SEP] { } ,\"\"\"\n",
        "sentence = \"[CLS] Cubic { 23.2,13,14.2 }\"\n",
        "tokens = dictionary.split()\n",
        "d = 10\n",
        "\n",
        "\n",
        "def processText(text):\n",
        "  text = text.replace('{', '{ ')\n",
        "  text = text.replace('}', '} ')\n",
        "  updatedText = text.replace(',', ' ').split(' ')\n",
        "  updatedText = ' '.join(updatedText).split()\n",
        "  return updatedText\n",
        "\n",
        "class token:\n",
        "  def __init__(self, tokens):\n",
        "    self.tokens = tokens.split()\n",
        "    self.embedding = nn.Embedding(50, d) \n",
        "    \n",
        "  def encode(self, sentence):\n",
        "\n",
        "    split = processText(sentence)\n",
        "    encoded = []\n",
        "    \n",
        "    for word in split:\n",
        "      if word in self.tokens:\n",
        "        encoded.append(self.tokens.index(word))\n",
        "      else:\n",
        "        encoded.append(word)\n",
        "\n",
        "    return encoded\n",
        "\n",
        "  def decode(self, encoded):\n",
        "    decoded = []\n",
        "    #print(encoded)\n",
        "    for i in encoded:\n",
        "      \n",
        "      if type(i) == str:\n",
        "        decoded.append(float(i))\n",
        "      else:\n",
        "        decoded.append(self.tokens[i])\n",
        "    return decoded\n",
        "\n",
        "\n",
        "  def tensorEncoded(self, encoded):\n",
        "    newList = []\n",
        "    tensorList = []\n",
        "    for i in encoded:\n",
        "      newList.append(float(i))\n",
        "\n",
        "    for i in newList:\n",
        "      tensorList.append(torch.tensor([i]))\n",
        "\n",
        "    return tensorList\n",
        "  \n",
        "  def npEncode(self, sentence):\n",
        "    newList = []\n",
        "    maskList = []\n",
        "    encoded = self.encode(sentence)\n",
        "\n",
        "    for i in encoded:\n",
        "\n",
        "      newList.append(float(i))\n",
        "      if (encoded.index(i) < 3) or (encoded.index(i) == len(encoded) - 1):\n",
        "        maskList.append(1)\n",
        "      else:\n",
        "        maskList.append(0)\n",
        "\n",
        "    \n",
        "    if len(newList) < 7:\n",
        "      for i in range(7-len(newList)):\n",
        "        newList.append(0.0)\n",
        "        maskList.append(0)\n",
        "\n",
        "    return newList, maskList\n",
        "\n",
        "  def tensorList(self, encoded):\n",
        "    array = []\n",
        "    for i in encoded:\n",
        "      array.append(np.array(i)[0])\n",
        "\n",
        "    return(array)\n",
        "\n",
        "def createDataSet(text):\n",
        "  dataSet = []\n",
        "  for i in text:\n",
        "    dataSet.append(tokens.encodeD(i))\n",
        "  dataSet = torch.stack(dataSet)\n",
        "  return dataSet\n",
        "\n",
        "def createData(text):\n",
        "  dataSet = []\n",
        "  masks = []\n",
        "  for i in text:\n",
        "    dataSet.append(tokens.npEncode(i)[0])\n",
        "    masks.append(tokens.npEncode(i)[1])\n",
        "  \n",
        "  return np.array(dataSet), np.array(masks)\n",
        "\n",
        "\n",
        "\n",
        "tokens = token(dictionary)\n",
        "encoded = tokens.encode(sentence)\n",
        "decoded = tokens.decode(encoded)\n",
        "tokens = token(dictionary)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x = tokens.npEncode(sentence)\n",
        "print(x)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Creating a Custom Embedding, Transformer, and Classifier Module**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 542,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import Tuple\n",
        "bttp = 16\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset\n",
        "\n",
        "\n",
        "\n",
        "class customEmbedding(nn.Module):\n",
        "    def __init__(self, len_vocab=10, embedding_dimension=128):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(len_vocab, embedding_dimension)\n",
        "        self.linear = nn.Linear(1, embedding_dimension)\n",
        "\n",
        "    def forward(self, tokens, discrete_mask):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            Embed the tokens through a 1 layer MLP, and through the nn.Embedding layer\n",
        "            tokens: (batch_size, seq_len)\n",
        "            discrete_mask: (batch_size, seq_len)\n",
        "        Output:\n",
        "            embeddings: (batch_size, seq_len, d)\n",
        "        \"\"\"\n",
        "\n",
        "        tokens = tokens.to(torch.float32)\n",
        "        discrete_mask = discrete_mask.to(torch.float32)\n",
        "\n",
        "        # Mask the tokens to remove float values that may be larger than the number of embeddings\n",
        "        token_mask = torch.mul(tokens.to(torch.int64), discrete_mask.to(torch.int64))\n",
        "        embeddings = self.embedding(token_mask)\n",
        "\n",
        "        # Use the size of the tokens to get the batch size dim\n",
        "        batch_size = tokens.size(0)\n",
        "\n",
        "        # Embed the Sentence as if it were a continuous value\n",
        "        token_reshaped = tokens.view(batch_size, 7, 1) # (batch_size, seq_len, 1) basically update the shape of the tensor\n",
        "        linear_embeddings = self.linear(token_reshaped)\n",
        "\n",
        "        # Create the continuous mask, and expand it to match the embedding dimension\n",
        "        discrete_mask = discrete_mask.unsqueeze(-1)\n",
        "        discrete_mask = discrete_mask.expand_as(embeddings)\n",
        "        discrete_mask_inv = 1 - discrete_mask\n",
        "\n",
        "        embeded = embeddings * discrete_mask + linear_embeddings * discrete_mask_inv\n",
        "        return embeded\n",
        "        \n",
        "# custom convolutional neural network to embed the 32x32 images into a 1 x 10d vector\n",
        "class customCNN(nn.Module):\n",
        "    def __init__(self, embedding_dim: int):\n",
        "\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 6, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(6, 16, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(16 * 5 * 5, embedding_dim*2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(embedding_dim*2, embedding_dim),\n",
        "            \n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
        "                 nlayers: int, dropout: float = 0.5):\n",
        "        super().__init__()\n",
        "        self.model_type = 'Transformer'\n",
        "        self.embeder = customEmbedding(len_vocab=10, embedding_dimension=128)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    \n",
        "    def encoder(self, src: Tensor, msk_list: Tensor, src_mask: Tensor) -> Tensor:\n",
        "\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src: Tensor, shape [seq_len, batch_size]\n",
        "            src_mask: Tensor, shape [seq_len, seq_len]\n",
        "\n",
        "        Returns:\n",
        "            output is encoded tensor \n",
        "        \"\"\"\n",
        "\n",
        "        src =  self.embeder(src, msk_list) * math.sqrt(self.d_model) #self.encoder(src) *\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        #print(output[0])\n",
        "        return output\n",
        "\n",
        "\n",
        "    def forward(self, src: Tensor, msk_list: Tensor, src_mask: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src: Tensor, shape [seq_len, batch_size]\n",
        "            src_mask: Tensor, shape [seq_len, seq_len]\n",
        "\n",
        "        Returns:\n",
        "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
        "        \"\"\"\n",
        "        \n",
        "        output = self.encoder(src, msk_list, src_mask)\n",
        "        \n",
        "        \n",
        "        return output\n",
        "\n",
        "\n",
        "# Create a Custom MLP that takes in the output of the CNN and outputs a 1 x 10d vector, and use a cross entropy loss to determine if it can correctly choose the correct class\n",
        "class customMLP(nn.Module):\n",
        "    def __init__(self, ntoken=10, d_model=128, nhead=8, d_hid=128, nlayers=6, dropout=0.5): # add in all the parameters that you want to pass in\n",
        "        super().__init__()\n",
        "        \n",
        "\n",
        "        # Pass the sentence through the embedder which goes through the custom transformer layer\n",
        "        self.token_encoder = TransformerModel(ntoken=10, d_model=128, nhead=8, d_hid=128, nlayers=6, dropout=0.5) #TransformerModel(src, src_mask)\n",
        "        # Encode the images using the customCNN\n",
        "        self.cnn_encoder = customCNN(embedding_dim=d_model) #customCNN(images)\n",
        "        # Concatenate the two vectors together, the first vector is the sentence, the second vector is the image. the sentence has the dimensions of\n",
        "        # BatchSize x LenghtOfSentence x EmbeddingDimension, and the image has the dimensions of BatchSize x 1 x EmbeddingDimension\n",
        "        self.concat = nn.Linear(2*d_model, d_model)\n",
        "\n",
        "        # Pass the concatenated vector through a softmax layer to get the final output\n",
        "        # Linear and Softmax layer for the final output\n",
        "        self.sigmoid = nn.Sigmoid() \n",
        "        self.fc = nn.Linear(d_model, round(d_model/2))\n",
        "        self.fc2 = nn.Linear(round(d_model/2), 1)\n",
        "    \n",
        "\n",
        "    def forward(self, src, msk_list, src_mask, images):\n",
        "        # Pass the sentence through the embedder which goes through the custom transformer layer\n",
        "        token_output = self.token_encoder(src, msk_list, src_mask)   # (b, L, d)\n",
        "        # Encode the images using the customCNN\n",
        "        image_output = self.cnn_encoder(images)\n",
        "\n",
        "        token_output= token_output[:, 0 , :] # (b, d)\n",
        "        # Concatenate the two vectors together\n",
        "        concat_output = self.concat(torch.cat((token_output, image_output), 1)) # (b, 2d) -> (b, d)\n",
        "        # Pass the concatenated vector through a softmax layer to get the final output\n",
        "        output = self.fc(concat_output) # (b, embedding_dim)\n",
        "        output = self.fc2(output) # (b, 1)\n",
        "        # maybe add a second hidden laer\n",
        "        #output = self.sigmoid(output)\n",
        "        #score = self.fc(output) # `score` is the output of the MLP (b, 1)\n",
        "\n",
        "        return output\n",
        "        \n",
        "\n",
        "\n",
        "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
        "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
        "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.0000, 4.0000, 6.0000, 3.4400, 2.4400, 2.4700, 7.0000],\n",
            "        [1.0000, 2.0000, 6.0000, 2.0800, 1.6200, 7.0000, 0.0000]],\n",
            "       dtype=torch.float64) tensor([[1, 1, 1, 0, 0, 0, 1],\n",
            "        [1, 1, 1, 0, 0, 1, 0]])\n"
          ]
        }
      ],
      "source": [
        "sentence_set = createSentece(64)\n",
        "data, masks  = createData(s)\n",
        "\n",
        "tensor_data = torch.tensor(data)\n",
        "tensor_masks = torch.tensor(masks)\n",
        "\n",
        "dataset = TensorDataset(tensor_data, tensor_masks)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "d = dataset[0:2][0]\n",
        "m = dataset[0:2][1]\n",
        "model = customEmbedding()\n",
        "output = model(d, m)\n",
        "output.shape\n",
        "print(d,m)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 7, 128])\n"
          ]
        }
      ],
      "source": [
        "encoder_layer = nn.TransformerEncoderLayer(d_model=128, nhead=8)\n",
        "bsize = 2\n",
        "src = torch.rand(10, 32, 512)\n",
        "out = encoder_layer(output)\n",
        "out.shape\n",
        "\n",
        "msk = generate_square_subsequent_mask(2)\n",
        "tm = TransformerModel(ntoken=10, d_model=128, nhead=8, d_hid=128, nlayers=6, dropout=0.5)\n",
        "model = customCNN(embedding_dim=128)\n",
        "\n",
        "print(tm(d, m, msk).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.4197],\n",
            "        [0.4328]], grad_fn=<SigmoidBackward0>)\n",
            "tensor([[0.4197, 0.4197],\n",
            "        [0.4328, 0.4328]], grad_fn=<CatBackward0>)\n",
            "tensor([[1., 1.],\n",
            "        [0., 0.]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 32])"
            ]
          },
          "execution_count": 228,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "mlp_model = customMLP(ntoken=10, d_model=128, nhead=8, d_hid=128, nlayers=6, dropout=0.5)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(mlp_model.parameters(), lr=0.001, momentum=0.9)\n",
        "out2 = mlp_model(d, m, msk, img[0][:2])\n",
        "out2.shape\n",
        "print(out2)\n",
        "\n",
        "# convert to torch to float\n",
        "#img = torch.tensor(img).float()\n",
        "output = torch.cat((out2, out2), 1).float()\n",
        "gt = torch.tensor([[1], [0]]).float()\n",
        "\n",
        "\n",
        "trn = gt.expand(output.shape) # ground truth tensor of 1, 0 expanded to fit the concatenated output for the given batch size\n",
        "print(output)\n",
        "print(trn)\n",
        "loss = nn.BCELoss()\n",
        "output = loss(output, trn)\n",
        "output\n",
        "\n",
        "\n",
        "load_eval_batches = DataLoader(data_complete, batch_size=32, shuffle=False)\n",
        "\n",
        "setset = img[0]\n",
        "setset[0,1].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 543,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([6400, 7])\n",
            "torch.Size([6400, 7])\n",
            "torch.Size([6400, 3, 32, 32])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "execution_count": 543,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data, masks  = createData(s)\n",
        "tensor_data = torch.tensor(data)\n",
        "tensor_masks = torch.tensor(masks)\n",
        "\n",
        "\n",
        "# Basically every batch can be divided like this...\n",
        "print(tensor_data.shape)\n",
        "print(tensor_masks.shape)\n",
        "print(img.shape)\n",
        "\n",
        "\n",
        "data_complete = TensorDataset(tensor_data, tensor_masks, img) # torch.Size([b, 7]), torch.Size([b, 7]), torch.Size([b, 3, 32, 32])\n",
        "load_batches = DataLoader(data_complete, batch_size=16, shuffle=False)\n",
        "train_data = next(iter(load_batches))\n",
        "\n",
        "sentenceD = train_data[0] # (b, L)\n",
        "sentenceMskD = train_data[1] # (b, L)\n",
        "imgD = train_data[2] # (b, 3, 32, 32)\n",
        "\n",
        "sentenceD.shape\n",
        "len(load_batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.0738, grad_fn=<BinaryCrossEntropyBackward0>)"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m = nn.Sigmoid()\n",
        "loss = nn.BCELoss()\n",
        "input = torch.randn(3, requires_grad=True)\n",
        "target = torch.empty(3).random_(2)\n",
        "output = loss(m(input), target)\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Positional Encoding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Create the Training for the CNN and Transformer Similarity**\n",
        "\n",
        "Unlike a typical transformer, we ourselves, encode the tokens of the sentence, allowing us to encode both words and floating points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 549,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "mlp = customMLP(ntoken=10, d_model=128, nhead=8, d_hid=128, nlayers=6, dropout=0.5)\n",
        "lr=0.00001 # learning rate\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(mlp.parameters(), lr=lr,  momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.8)\n",
        "bptt = 16 # batch size for training of 32\n",
        "transformer_msk = generate_square_subsequent_mask(bptt)\n",
        "\n",
        "def train(model: nn.Module) -> None:\n",
        "      #model.train()  # turn on train mode\n",
        "      total_loss = 0.\n",
        "      num_batches = len(load_batches)\n",
        "      optimizer.zero_grad() # zero out the gradients\n",
        "\n",
        "      for i, batch in enumerate(load_batches):\n",
        "\n",
        "            # Get the model's output for the tensor with the correct image and an incorrect image\n",
        "            # (batch_size x 2) Concatenated output of the two images, to compare to the ground truth Should be a 2d tensor 1,0 at convg.\n",
        "            # input (l, I_v) -> scalar output [x] -> batch_size x 1\n",
        "            \n",
        "            src = batch[0] # (b, L)\n",
        "            msk = batch[1] # (b, L)\n",
        "            img_c = batch[2] # (b, 3, 32, 32)\n",
        "            img_f = img_c[(randomShuffle(bptt))] # shuffle the images to get a false image\n",
        "\n",
        "            output_ic = model(src, msk, transformer_msk, img_c).float() # (b, 1)\n",
        "            output_if = model(src, msk, transformer_msk, img_f).float() # (b, 1)\n",
        "            output = torch.cat((output_ic, output_if), 1) # (2 x b) \n",
        "\n",
        "            # Put output_ground and false into one tensor continaing the other two tensors\n",
        "            # Tensor of labels to the corect size. Batch_size x 2 Ex when bttp=2: [[1, 1], [0, 0]]\n",
        "            target_1, target_0 = torch.tensor([[1]]).float(), torch.tensor([[0]]).float()\n",
        "            target_1 = target_1.expand(output_ic.shape)  # (2 x b)\n",
        "            target_0 = target_0.expand(output_if.shape)  # (2 x b)\n",
        "            target = torch.cat((target_1, target_0), 1) # (2 x b)\n",
        "            \n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            if i % bptt == 0 and i > 0:\n",
        "                lr = scheduler.get_last_lr()[0]\n",
        "                print(f'| epoch {epoch:3d} | {int(i):3d} / {num_batches:3d} batches | '\n",
        "                        f'lr {lr:00002.10f} | '\n",
        "                        f'loss {total_loss:5.2f} |')\n",
        "                total_loss = 0\n",
        "\n",
        "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
        "    model.eval()  # turn on evaluation mode\n",
        "    total_loss = 0.\n",
        "    src_mask = generate_square_subsequent_mask(bptt)\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(load_eval_batches):\n",
        "            \n",
        "            src = batch[0] # (b, L)\n",
        "            msk = batch[1] # (b, L)\n",
        "            img_c = batch[2] # (b, 3, 32, 32)\n",
        "            img_f = img_c[torch.tensor(randomShuffle(bptt))] # shuffle the images to get a false image\n",
        "\n",
        "            output_ic = model(src, msk, transformer_msk, img_c).float() # (b, 1)\n",
        "            output_if = model(src, msk, transformer_msk, img_f).float() # (b, 1)\n",
        "            data = torch.cat((output_ic, output_if), 1) # (2 x b) \n",
        "            \n",
        "            target = torch.tensor([[1], [0]]).float()\n",
        "            target = target.expand(output.shape)  # (2 x b)\n",
        "            \n",
        "            # Calculate the loss using BCE loss, optimizer step \n",
        "            total_loss += criterion(data, target)\n",
        "\n",
        "    return total_loss / (len(eval_data) - 1)\n",
        "\n",
        "# Shuffle Image Data for false image match to the correct text, returns a list of the shuffled indexes unlike the original\n",
        "# tensor=tensor[torch.tensor(randomShuffle(bttp))] \n",
        "\n",
        "def randomShuffle(batchSize):\n",
        "    original = np.arange(batchSize)\n",
        "    shuffled = np.arange(batchSize)\n",
        "    np.random.shuffle(shuffled)\n",
        "\n",
        "    dif = np.absolute(original - shuffled)\n",
        "    \n",
        "    if np.any(dif == 0):\n",
        "        shuffled = randomShuffle(batchSize)\n",
        "    \n",
        "    return shuffled\n",
        "\n",
        "\n",
        "# check = (img_c-img_f)\n",
        "# if torch.count_nonzero(check) <= 0:\n",
        "#     print(torch.count_nonzero(check))\n",
        "#     print(\"Images are supposedly the same\")\n",
        "#     break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Train the Model**\n",
        "\n",
        "During this step we have to train the model to ensure our decoder can effectively account for the position of each word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 550,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   9 |  16 / 400 batches | lr 0.0000100000 | loss 12.82 |\n",
            "| epoch   9 |  32 / 400 batches | lr 0.0000100000 | loss 12.09 |\n",
            "| epoch   9 |  48 / 400 batches | lr 0.0000100000 | loss 12.08 |\n",
            "| epoch   9 |  64 / 400 batches | lr 0.0000100000 | loss 12.10 |\n",
            "| epoch   9 |  80 / 400 batches | lr 0.0000100000 | loss 12.10 |\n",
            "| epoch   9 |  96 / 400 batches | lr 0.0000100000 | loss 12.08 |\n",
            "| epoch   9 | 112 / 400 batches | lr 0.0000100000 | loss 12.06 |\n",
            "| epoch   9 | 128 / 400 batches | lr 0.0000100000 | loss 12.10 |\n",
            "| epoch   9 | 144 / 400 batches | lr 0.0000100000 | loss 12.11 |\n",
            "| epoch   9 | 160 / 400 batches | lr 0.0000100000 | loss 12.10 |\n",
            "| epoch   9 | 176 / 400 batches | lr 0.0000100000 | loss 12.04 |\n",
            "| epoch   9 | 192 / 400 batches | lr 0.0000100000 | loss 12.11 |\n",
            "| epoch   9 | 208 / 400 batches | lr 0.0000100000 | loss 12.09 |\n",
            "| epoch   9 | 224 / 400 batches | lr 0.0000100000 | loss 12.08 |\n",
            "| epoch   9 | 240 / 400 batches | lr 0.0000100000 | loss 12.08 |\n",
            "| epoch   9 | 256 / 400 batches | lr 0.0000100000 | loss 12.08 |\n",
            "| epoch   9 | 272 / 400 batches | lr 0.0000100000 | loss 12.08 |\n",
            "| epoch   9 | 288 / 400 batches | lr 0.0000100000 | loss 12.11 |\n",
            "| epoch   9 | 304 / 400 batches | lr 0.0000100000 | loss 12.10 |\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train(model)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m best_val_loss \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minf\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n",
            "\u001b[1;32m/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb Cell 23\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m img_f \u001b[39m=\u001b[39m img_c[(randomShuffle(bptt))] \u001b[39m# shuffle the images to get a false image\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m output_ic \u001b[39m=\u001b[39m model(src, msk, transformer_msk, img_c)\u001b[39m.\u001b[39mfloat() \u001b[39m# (b, 1)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m output_if \u001b[39m=\u001b[39m model(src, msk, transformer_msk, img_f)\u001b[39m.\u001b[39mfloat() \u001b[39m# (b, 1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((output_ic, output_if), \u001b[39m1\u001b[39m) \u001b[39m# (2 x b) \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Put output_ground and false into one tensor continaing the other two tensors\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# Tensor of labels to the corect size. Batch_size x 2 Ex when bttp=2: [[1, 1], [0, 0]]\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32m/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb Cell 23\u001b[0m in \u001b[0;36mcustomMLP.forward\u001b[0;34m(self, src, msk_list, src_mask, images)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=178'>179</a>\u001b[0m token_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken_encoder(src, msk_list, src_mask)   \u001b[39m# (b, L, d)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=179'>180</a>\u001b[0m \u001b[39m# Encode the images using the customCNN\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=180'>181</a>\u001b[0m image_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcnn_encoder(images)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=182'>183</a>\u001b[0m token_output\u001b[39m=\u001b[39m token_output[:, \u001b[39m0\u001b[39m , :] \u001b[39m# (b, d)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=183'>184</a>\u001b[0m \u001b[39m# Concatenate the two vectors together\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32m/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb Cell 23\u001b[0m in \u001b[0;36mcustomCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train(model)\n",
        "best_val_loss = float('inf')\n",
        "epochs = 10\n",
        "best_model = None\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    epoch_start_time = time.time()\n",
        "    train(mlp)\n",
        "    #scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 547,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "token_encoder.embeder.embedding.weight tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0005, -0.0006, -0.0023,  ..., -0.0008, -0.0027,  0.0002],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
            "token_encoder.embeder.linear.weight tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]])\n",
            "token_encoder.embeder.linear.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "token_encoder.transformer_encoder.layers.0.self_attn.in_proj_weight tensor([[-0.0206, -0.0443,  0.0245,  ...,  0.0695,  0.0129, -0.0172],\n",
            "        [-0.0673,  0.0118,  0.0623,  ..., -0.0257, -0.0630,  0.0006],\n",
            "        [-0.0822, -0.0750,  0.0442,  ...,  0.0833,  0.0506,  0.0207],\n",
            "        ...,\n",
            "        [-0.0057,  0.0468, -0.0918,  ...,  0.0195, -0.1040, -0.0061],\n",
            "        [ 0.0214,  0.0100, -0.0558,  ...,  0.0089, -0.0197, -0.0070],\n",
            "        [-0.0933,  0.0894,  0.0328,  ..., -0.0678,  0.0126, -0.1011]])\n",
            "token_encoder.transformer_encoder.layers.0.self_attn.in_proj_bias tensor([ 5.4049e-11,  1.3548e-11,  1.8138e-10,  2.2153e-11,  1.0949e-11,\n",
            "        -1.4763e-11, -7.9987e-11,  3.9713e-11, -5.6131e-11, -5.4875e-11,\n",
            "         5.9858e-11,  5.9166e-11,  1.3010e-10, -1.7475e-10, -4.1302e-12,\n",
            "         3.9823e-12, -8.4711e-11, -6.4263e-11,  7.4553e-11,  1.6445e-11,\n",
            "         1.0316e-10,  1.0758e-11, -9.9333e-11,  1.1739e-10,  1.4495e-10,\n",
            "         2.4956e-12,  9.2561e-11, -9.8233e-11,  3.8872e-11,  8.9069e-12,\n",
            "         3.0602e-11,  5.6301e-11, -3.9807e-12,  7.0268e-11,  1.5038e-11,\n",
            "         1.0925e-10, -5.9800e-11,  1.4457e-11, -7.8848e-11, -7.4713e-12,\n",
            "         2.1938e-12, -7.6961e-11, -1.3134e-10,  8.2678e-11,  6.0222e-11,\n",
            "        -6.5189e-11,  4.3553e-11,  4.4470e-11,  2.0942e-10,  6.7203e-11,\n",
            "         5.6710e-11, -1.2826e-10,  1.7847e-11,  7.9555e-11, -1.2638e-11,\n",
            "        -4.0361e-11,  9.2473e-11,  1.4811e-11, -7.9880e-11,  9.5747e-11,\n",
            "        -4.6132e-11, -2.2866e-11, -4.4953e-11, -7.6669e-11,  8.7147e-11,\n",
            "         4.6949e-11, -1.2391e-11, -1.1706e-10,  7.2775e-11, -4.2101e-11,\n",
            "        -9.0197e-12, -4.5236e-11,  1.5983e-10,  6.7187e-11,  6.0786e-11,\n",
            "         6.7592e-11,  1.6696e-10, -1.0004e-10,  1.1331e-10, -1.8783e-10,\n",
            "         9.3181e-12, -5.5761e-11,  2.3167e-11, -5.9429e-11, -5.7696e-11,\n",
            "        -4.8142e-11,  1.0139e-11,  9.1224e-11,  1.1298e-10,  7.1792e-12,\n",
            "         9.5703e-11,  6.8027e-12, -4.4287e-12,  7.2701e-11,  1.2964e-11,\n",
            "         1.0480e-10, -3.8916e-11, -4.4707e-11, -7.3568e-11,  1.0810e-10,\n",
            "         6.2545e-11,  7.0157e-11, -1.2200e-10, -2.6309e-12, -9.9692e-11,\n",
            "        -4.8081e-11,  2.4731e-11,  9.2225e-11, -8.3990e-11,  3.7759e-11,\n",
            "         5.7126e-11, -6.0551e-11,  1.1912e-10,  2.2486e-10,  6.6189e-11,\n",
            "         5.6223e-11,  8.3040e-11, -1.0114e-10, -2.0764e-11, -8.8580e-11,\n",
            "        -1.3830e-10,  1.1666e-10, -3.3295e-11, -1.1728e-10, -7.9141e-11,\n",
            "         6.2896e-11, -1.2588e-10, -1.4692e-10,  9.9452e-18, -1.0946e-17,\n",
            "        -1.4293e-17,  9.3555e-18, -8.8361e-18,  3.9785e-18,  2.4963e-17,\n",
            "        -1.6813e-17, -7.0706e-18, -7.3105e-18, -3.3814e-19,  2.9825e-18,\n",
            "        -3.2925e-17,  1.0095e-17, -2.2916e-17,  3.8708e-18, -1.9960e-19,\n",
            "        -1.7711e-18,  6.4563e-18,  8.5365e-19,  8.2433e-19,  3.3674e-18,\n",
            "         1.2844e-17,  2.8213e-18, -5.5854e-18, -5.6964e-18,  5.8729e-18,\n",
            "        -9.1978e-18, -1.8581e-17,  3.9932e-18,  1.2117e-17, -6.2716e-18,\n",
            "         7.5432e-18, -1.4971e-17, -2.6216e-17, -1.2514e-19, -9.4858e-18,\n",
            "        -1.5952e-17,  6.7778e-18,  3.3285e-18, -4.1859e-18, -1.6826e-17,\n",
            "         1.6497e-17,  6.9899e-19,  6.7760e-18,  3.9725e-18, -9.7761e-18,\n",
            "        -8.6446e-18,  4.8167e-18, -2.1539e-17,  1.9280e-17,  3.9449e-17,\n",
            "         1.1175e-17, -1.0821e-17, -1.8260e-17,  1.0610e-17, -4.8687e-18,\n",
            "        -2.3195e-17,  3.0582e-17, -1.6369e-17,  1.2204e-17,  4.0427e-18,\n",
            "         1.3074e-17,  3.1755e-20, -1.4911e-17,  5.6540e-18,  1.7552e-17,\n",
            "         1.0129e-17,  8.2405e-18, -1.4965e-17,  1.5060e-18,  3.0870e-18,\n",
            "         1.7040e-17,  1.3834e-17,  1.1104e-17, -2.4959e-17, -3.6605e-18,\n",
            "         1.5930e-17, -2.3016e-18, -1.6977e-17,  1.7151e-17, -2.7194e-17,\n",
            "        -5.8004e-18, -3.6069e-17,  2.4707e-17, -2.2915e-20,  3.8897e-18,\n",
            "        -1.3032e-17, -5.5367e-18, -7.5428e-17, -4.1943e-17, -2.1729e-18,\n",
            "        -2.9783e-17,  6.3892e-17, -5.1287e-18, -5.4796e-18,  4.6454e-18,\n",
            "        -2.4093e-17, -3.4839e-18,  2.0707e-17,  1.0819e-17,  8.3289e-18,\n",
            "        -1.7548e-17, -1.2428e-17,  1.8162e-17, -1.4575e-17,  1.7397e-17,\n",
            "         1.0151e-17, -1.7793e-17, -1.9224e-17,  2.5931e-18, -4.1472e-18,\n",
            "         1.6725e-17, -1.1433e-17,  1.0170e-17,  6.4763e-19,  6.6926e-18,\n",
            "        -3.0211e-17,  1.3668e-17, -2.7775e-17,  1.4069e-17, -3.1633e-18,\n",
            "        -4.1406e-19,  1.0209e-17,  1.6458e-17,  3.1032e-18,  5.6974e-18,\n",
            "        -1.5354e-17,  8.7001e-05,  1.0873e-04,  1.1964e-04,  8.3576e-05,\n",
            "         2.7055e-05, -9.1123e-05, -5.8928e-05,  2.2379e-05,  7.2495e-05,\n",
            "         4.0821e-05, -9.9053e-05, -1.0681e-04,  2.2301e-05, -1.2273e-04,\n",
            "        -4.3088e-05,  3.8940e-05,  1.4739e-04, -4.2946e-05, -1.8540e-04,\n",
            "         3.1090e-05,  6.3270e-05, -2.4813e-04,  1.6830e-04, -1.9962e-04,\n",
            "        -8.1237e-05,  6.7735e-05, -1.1221e-04, -3.6421e-05,  3.4699e-05,\n",
            "         1.7339e-06, -4.6175e-05,  7.2104e-05,  1.8619e-07, -4.7472e-05,\n",
            "        -7.6775e-05,  1.0934e-05,  4.6066e-06, -2.5373e-05, -5.7939e-05,\n",
            "        -4.1677e-05, -7.5711e-05, -5.5683e-05, -2.3034e-05, -7.0436e-05,\n",
            "         8.5444e-05,  7.2821e-05,  5.6645e-05,  9.6587e-05, -9.4198e-05,\n",
            "         7.0795e-05, -1.5779e-04,  1.3634e-04, -2.3589e-05, -5.1190e-05,\n",
            "        -4.6035e-05,  2.4008e-05, -4.9183e-05,  6.1246e-06,  6.3834e-05,\n",
            "        -1.2558e-04, -4.6748e-05, -4.9949e-05,  5.7837e-05,  1.3055e-04,\n",
            "         1.8924e-04, -2.8743e-05,  2.0357e-05,  1.9994e-05,  4.8011e-05,\n",
            "        -7.8557e-05, -1.4767e-04,  1.3074e-04, -8.7645e-05,  8.1042e-05,\n",
            "         1.4910e-04,  1.0674e-05,  4.4706e-05, -3.4634e-05,  1.0629e-04,\n",
            "         4.8051e-05,  1.3532e-04,  1.2216e-04,  3.3308e-05, -1.8595e-04,\n",
            "         9.4373e-05, -1.8229e-04, -1.2443e-04,  1.8755e-04, -8.3006e-05,\n",
            "        -2.6806e-04,  1.5483e-04, -2.1407e-05, -8.5483e-05, -9.1833e-05,\n",
            "        -1.8741e-04, -5.1875e-05,  1.0897e-04,  1.1329e-04,  7.1218e-06,\n",
            "        -2.2792e-05, -9.9085e-05,  9.0718e-05, -5.0817e-05,  1.0419e-05,\n",
            "        -1.2407e-04,  1.4475e-04,  3.1307e-05,  1.5005e-05,  8.1288e-05,\n",
            "        -7.3545e-05,  1.1919e-04, -6.9996e-05, -7.4144e-05,  1.3931e-04,\n",
            "        -6.1945e-05,  7.2700e-05,  6.4727e-05, -1.8115e-04, -5.7583e-05,\n",
            "        -7.2736e-05,  9.5154e-05,  4.9408e-06,  1.3014e-04, -1.0780e-04,\n",
            "         2.5440e-05,  3.9142e-05,  8.2045e-05,  3.6168e-05])\n",
            "token_encoder.transformer_encoder.layers.0.self_attn.out_proj.weight tensor([[-0.0486, -0.0551, -0.0124,  ..., -0.0738, -0.0202, -0.0112],\n",
            "        [ 0.0414, -0.0782,  0.0360,  ..., -0.0850,  0.0135, -0.0172],\n",
            "        [ 0.0421,  0.0650, -0.0834,  ...,  0.0044, -0.0079,  0.0845],\n",
            "        ...,\n",
            "        [ 0.0634,  0.0509,  0.0373,  ...,  0.0335, -0.0538,  0.0432],\n",
            "        [-0.0754,  0.0440,  0.0274,  ..., -0.0472, -0.0735, -0.0036],\n",
            "        [-0.0016,  0.0141,  0.0085,  ...,  0.0873,  0.0173, -0.0135]])\n",
            "token_encoder.transformer_encoder.layers.0.self_attn.out_proj.bias tensor([-1.1638e-05,  6.2956e-05, -7.4280e-05, -2.3476e-05,  1.5258e-04,\n",
            "        -1.3721e-04, -1.0336e-04, -1.4036e-04, -4.5167e-05,  6.4025e-05,\n",
            "        -1.4522e-05,  5.9228e-05, -4.0967e-05, -2.0494e-04,  4.0333e-05,\n",
            "        -1.0984e-04,  1.7269e-04, -4.8137e-05,  7.8815e-05, -1.8790e-04,\n",
            "        -1.1314e-04,  1.4328e-04, -1.6914e-04,  9.3586e-06, -5.2019e-05,\n",
            "        -3.0265e-05,  3.1083e-04, -2.1363e-05, -8.7994e-05,  2.3971e-04,\n",
            "         8.3832e-05,  1.1983e-04,  2.1442e-05, -1.4774e-04,  2.2270e-04,\n",
            "        -9.0676e-05,  8.5445e-05,  9.4170e-05, -1.1203e-04, -1.9798e-04,\n",
            "        -2.4148e-04,  1.1942e-04, -1.3693e-04,  3.2487e-05,  2.5117e-04,\n",
            "        -2.4061e-04,  1.3884e-04,  1.1127e-04, -2.2086e-04, -2.7605e-05,\n",
            "        -1.7906e-04,  1.6750e-04,  1.5248e-04, -2.1718e-05, -1.7503e-04,\n",
            "        -2.0769e-04,  8.7847e-05,  8.1398e-06,  9.9671e-06, -9.5547e-05,\n",
            "        -6.4267e-05, -2.4790e-04, -1.9547e-04, -1.6908e-04, -1.0475e-04,\n",
            "        -1.0560e-04, -1.4288e-04,  1.6523e-04, -8.4179e-05, -2.4629e-05,\n",
            "         8.2734e-05, -3.2030e-04, -2.5483e-05,  3.3562e-05, -5.7252e-05,\n",
            "        -1.6124e-05, -4.4964e-05, -9.7913e-05,  2.6088e-04,  9.4598e-05,\n",
            "         1.3742e-04, -1.5531e-04,  1.1232e-04,  1.8520e-04,  1.2264e-04,\n",
            "         1.3517e-04,  6.5046e-05,  2.2666e-04,  1.2547e-04,  7.1225e-05,\n",
            "         4.4416e-05,  6.5353e-06,  1.8237e-05, -1.4712e-04, -2.4622e-04,\n",
            "        -7.5200e-05, -3.4600e-05,  2.0159e-04,  6.1718e-05,  1.0221e-05,\n",
            "        -2.7728e-05, -2.3792e-04,  3.3665e-05,  1.9094e-04, -5.4342e-05,\n",
            "        -1.0543e-04,  2.9285e-04,  5.2551e-05,  2.2138e-04,  5.9524e-05,\n",
            "        -1.6621e-05, -4.1945e-06,  1.5166e-04,  1.8255e-04, -7.9036e-05,\n",
            "         3.8730e-06,  9.4138e-05, -3.0890e-05, -1.7317e-05,  1.7419e-04,\n",
            "         4.2630e-05, -5.9232e-05, -1.5996e-04,  1.0547e-04, -7.6821e-05,\n",
            "        -7.5349e-05, -1.4531e-04, -1.0657e-04])\n",
            "token_encoder.transformer_encoder.layers.0.linear1.weight tensor([[ 0.0571,  0.0584,  0.0481,  ...,  0.0554, -0.0860, -0.0332],\n",
            "        [ 0.0024, -0.0642,  0.0629,  ..., -0.0878, -0.0876, -0.0085],\n",
            "        [ 0.0873, -0.0248, -0.0677,  ...,  0.0376, -0.0556, -0.0844],\n",
            "        ...,\n",
            "        [ 0.0053,  0.0725,  0.0214,  ...,  0.0507,  0.0543, -0.0073],\n",
            "        [ 0.0036, -0.0372,  0.0872,  ..., -0.0674, -0.0342, -0.0129],\n",
            "        [ 0.0791, -0.0020,  0.0156,  ..., -0.0286,  0.0857, -0.0044]])\n",
            "token_encoder.transformer_encoder.layers.0.linear1.bias tensor([ 0.0805,  0.0645,  0.0708,  0.0106, -0.0359,  0.0673, -0.0490, -0.0237,\n",
            "         0.0195, -0.0361,  0.0791,  0.0427,  0.0223, -0.0784, -0.0120, -0.0044,\n",
            "        -0.0263, -0.0268,  0.0388, -0.0349, -0.0571, -0.0779,  0.0744, -0.0014,\n",
            "        -0.0707, -0.0298, -0.0130, -0.0322, -0.0586, -0.0128,  0.0657,  0.0798,\n",
            "         0.0039, -0.0071,  0.0859, -0.0371, -0.0599,  0.0559,  0.0637, -0.0581,\n",
            "        -0.0570, -0.0676,  0.0667, -0.0303,  0.0844, -0.0602, -0.0138,  0.0791,\n",
            "        -0.0372,  0.0405, -0.0669, -0.0245, -0.0285, -0.0024, -0.0158,  0.0672,\n",
            "         0.0211, -0.0673,  0.0302,  0.0424, -0.0319, -0.0602,  0.0422,  0.0574,\n",
            "        -0.0241, -0.0672,  0.0263,  0.0002,  0.0198,  0.0877,  0.0178, -0.0661,\n",
            "        -0.0291, -0.0710,  0.0253, -0.0713, -0.0027, -0.0464,  0.0098, -0.0452,\n",
            "        -0.0769, -0.0025, -0.0241, -0.0703, -0.0825, -0.0580, -0.0321,  0.0019,\n",
            "         0.0698, -0.0119, -0.0202,  0.0221, -0.0869,  0.0477,  0.0763, -0.0352,\n",
            "        -0.0746,  0.0082,  0.0038, -0.0631, -0.0570, -0.0359,  0.0495,  0.0734,\n",
            "        -0.0126,  0.0669, -0.0752,  0.0277,  0.0752,  0.0248, -0.0117, -0.0408,\n",
            "        -0.0865, -0.0594,  0.0469,  0.0095,  0.0657, -0.0172,  0.0030, -0.0626,\n",
            "        -0.0739, -0.0876,  0.0419,  0.0131, -0.0588, -0.0035,  0.0224, -0.0343])\n",
            "token_encoder.transformer_encoder.layers.0.linear2.weight tensor([[-0.0713,  0.0368, -0.0236,  ..., -0.0532, -0.0118,  0.0241],\n",
            "        [-0.0635, -0.0315,  0.0215,  ...,  0.0819, -0.0870, -0.0466],\n",
            "        [-0.0136,  0.0712, -0.0599,  ..., -0.0559,  0.0848,  0.0543],\n",
            "        ...,\n",
            "        [-0.0010,  0.0134, -0.0321,  ..., -0.0444, -0.0406, -0.0521],\n",
            "        [ 0.0315,  0.0460,  0.0526,  ...,  0.0047,  0.0208,  0.0053],\n",
            "        [-0.0515, -0.0722, -0.0596,  ..., -0.0849, -0.0783,  0.0570]])\n",
            "token_encoder.transformer_encoder.layers.0.linear2.bias tensor([-0.0820, -0.0015,  0.0034,  0.0136, -0.0244,  0.0604,  0.0073,  0.0686,\n",
            "         0.0831,  0.0744,  0.0771,  0.0610, -0.0682,  0.0684,  0.0080, -0.0440,\n",
            "        -0.0761, -0.0401, -0.0584,  0.0392, -0.0703, -0.0450, -0.0306, -0.0610,\n",
            "         0.0640, -0.0075, -0.0770,  0.0671, -0.0113, -0.0350, -0.0757, -0.0784,\n",
            "         0.0458,  0.0095,  0.0776, -0.0811, -0.0071,  0.0665,  0.0655, -0.0298,\n",
            "        -0.0187, -0.0357, -0.0604,  0.0664, -0.0678,  0.0085,  0.0139,  0.0693,\n",
            "         0.0421,  0.0077, -0.0842, -0.0052, -0.0207,  0.0685,  0.0018, -0.0827,\n",
            "        -0.0042,  0.0858, -0.0600,  0.0434,  0.0680,  0.0452,  0.0031,  0.0642,\n",
            "         0.0361,  0.0078, -0.0651,  0.0498, -0.0326, -0.0095, -0.0605, -0.0508,\n",
            "         0.0326, -0.0715,  0.0446,  0.0345, -0.0012, -0.0703, -0.0687, -0.0438,\n",
            "         0.0846,  0.0561, -0.0330, -0.0171,  0.0344, -0.0697, -0.0590,  0.0646,\n",
            "         0.0735,  0.0047, -0.0521,  0.0486, -0.0863,  0.0244, -0.0167,  0.0291,\n",
            "         0.0435, -0.0818, -0.0091,  0.0860, -0.0300, -0.0855, -0.0519, -0.0436,\n",
            "         0.0156,  0.0218,  0.0883, -0.0369,  0.0432,  0.0854, -0.0689, -0.0499,\n",
            "        -0.0711, -0.0312, -0.0014,  0.0186, -0.0610, -0.0336, -0.0861, -0.0834,\n",
            "        -0.0072,  0.0451, -0.0667,  0.0381, -0.0458, -0.0283,  0.0339, -0.0330])\n",
            "token_encoder.transformer_encoder.layers.0.norm1.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.0.norm1.bias tensor([-2.0144e-08,  1.1913e-07,  5.3493e-08, -3.3260e-07,  2.9979e-07,\n",
            "        -8.9195e-08, -1.1333e-07, -1.9316e-07,  6.9850e-08,  3.0634e-08,\n",
            "        -2.2976e-08,  1.5162e-07, -1.9418e-07, -3.2870e-07,  1.6745e-07,\n",
            "        -1.4885e-07,  4.0711e-07, -8.9183e-08, -8.1393e-08, -4.2664e-07,\n",
            "        -3.7224e-08,  6.6614e-07, -3.7147e-07, -4.8411e-08,  1.5834e-08,\n",
            "        -6.8554e-08,  2.0855e-07, -1.1921e-08,  3.0350e-07,  2.5991e-07,\n",
            "         1.2230e-07,  4.3363e-08, -2.9491e-08, -2.6187e-07,  5.6670e-07,\n",
            "        -5.5859e-07, -7.3331e-08,  2.6522e-07,  1.0023e-07, -2.9171e-07,\n",
            "        -6.0511e-07,  5.0930e-07, -1.8222e-07,  2.4554e-07,  6.3827e-07,\n",
            "        -7.0837e-07,  1.5360e-07,  2.9572e-07, -4.1024e-07, -1.7138e-07,\n",
            "        -1.3818e-07,  2.8028e-07,  3.3873e-07, -8.2445e-08,  6.0475e-07,\n",
            "        -7.3775e-07,  4.8304e-07, -1.1762e-07,  2.6949e-07, -2.5024e-07,\n",
            "        -2.8777e-07, -5.9661e-07, -3.7268e-09, -2.6546e-07, -3.7276e-07,\n",
            "        -1.5634e-07, -3.1720e-07,  9.6608e-08, -2.3332e-07,  1.3683e-07,\n",
            "         4.4306e-08, -6.0884e-07, -4.0647e-07,  2.9910e-07, -4.1293e-07,\n",
            "         1.6754e-07, -2.2020e-07, -2.7241e-07,  5.1030e-07,  5.0319e-07,\n",
            "         1.3064e-07, -6.7177e-08,  1.7048e-07,  3.9402e-07,  1.5480e-07,\n",
            "         1.7914e-07,  9.6889e-08,  3.1774e-07,  1.3334e-07, -3.5095e-08,\n",
            "        -6.5025e-08, -1.7860e-07,  2.9259e-07, -3.7168e-07, -4.0494e-07,\n",
            "        -7.0172e-08, -3.1703e-07,  4.9733e-07,  3.1600e-07,  1.4707e-07,\n",
            "        -5.0909e-07, -3.9063e-07,  1.7627e-07,  2.3241e-07,  5.1697e-08,\n",
            "        -1.9286e-07,  2.8598e-07,  2.0143e-07,  2.8446e-07, -6.7206e-08,\n",
            "         1.4222e-07,  2.0646e-07,  6.2530e-07,  3.4284e-07, -2.1556e-07,\n",
            "        -9.1966e-09,  2.6882e-07, -1.6393e-07,  1.1763e-07,  3.8555e-07,\n",
            "        -1.4697e-07, -4.0155e-07, -2.0434e-07,  4.4014e-07, -5.2864e-07,\n",
            "        -1.5508e-07, -5.4010e-07, -3.6145e-07])\n",
            "token_encoder.transformer_encoder.layers.0.norm2.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.0.norm2.bias tensor([-1.0360e-07, -4.4160e-08,  9.8924e-08, -1.0386e-07, -2.7115e-08,\n",
            "        -8.6163e-08,  7.0414e-08, -1.3654e-08,  7.7569e-08,  5.8488e-08,\n",
            "         7.3028e-08,  3.7520e-08, -2.0100e-09, -1.0273e-07, -1.2794e-08,\n",
            "        -6.5740e-08,  6.1479e-08,  5.1959e-09,  1.4975e-08, -1.5540e-07,\n",
            "         5.1238e-08,  1.9426e-07, -2.5056e-08, -6.1187e-08,  1.0007e-07,\n",
            "        -3.7109e-08,  3.7809e-08, -6.1080e-08,  2.0287e-07,  8.7668e-09,\n",
            "        -4.1387e-08,  6.7032e-08,  4.2890e-08,  6.7605e-09,  1.0631e-07,\n",
            "        -6.6720e-08, -8.9098e-08,  2.9315e-09,  7.5066e-10, -5.9606e-08,\n",
            "        -2.0767e-07,  6.2526e-08, -4.0082e-08,  1.0771e-07, -1.8836e-08,\n",
            "        -8.3071e-08,  4.7877e-08,  8.4523e-08, -5.5592e-08,  3.0466e-08,\n",
            "        -1.3937e-08,  8.6820e-08, -3.0360e-10, -1.1066e-08,  6.8684e-09,\n",
            "        -3.5739e-08,  8.6668e-08, -5.6362e-08,  4.6070e-08, -6.1951e-08,\n",
            "        -7.4205e-09, -1.0509e-07,  1.3187e-08,  7.5100e-09, -7.5493e-08,\n",
            "        -4.8376e-08,  3.2613e-08, -1.8264e-08, -4.9420e-08,  4.5556e-08,\n",
            "         2.8088e-08, -1.2243e-07, -6.9126e-08, -2.7699e-08, -4.9896e-08,\n",
            "         1.5202e-07, -1.2663e-07, -1.0073e-07, -4.1216e-08,  1.0729e-07,\n",
            "         4.9552e-08, -6.5026e-08, -6.6109e-08, -1.0112e-08,  4.2278e-08,\n",
            "         2.2760e-08,  3.1238e-08,  3.5769e-08,  4.2986e-08,  7.0830e-08,\n",
            "        -7.1164e-08,  4.5339e-08,  5.4174e-09,  8.5153e-09, -5.9283e-08,\n",
            "        -2.6631e-08, -2.0344e-08,  6.7465e-08, -3.9696e-08,  6.1665e-08,\n",
            "        -8.6484e-08, -9.2959e-08, -1.0925e-07,  1.1778e-08, -3.3177e-08,\n",
            "        -4.6639e-08, -2.0294e-08,  6.8979e-08,  5.1028e-08,  7.9176e-09,\n",
            "        -8.0475e-08,  6.5882e-08, -7.8144e-09,  1.5102e-07, -4.7306e-09,\n",
            "        -1.2953e-07,  9.3162e-08,  2.8750e-08, -6.9478e-08,  5.5154e-08,\n",
            "        -6.3900e-09, -3.3976e-09, -8.9981e-08,  3.8255e-08, -8.8427e-08,\n",
            "        -7.2437e-09, -9.8118e-08, -4.9853e-08])\n",
            "token_encoder.transformer_encoder.layers.1.self_attn.in_proj_weight tensor([[-0.0206, -0.0443,  0.0245,  ...,  0.0695,  0.0129, -0.0172],\n",
            "        [-0.0673,  0.0118,  0.0623,  ..., -0.0257, -0.0630,  0.0006],\n",
            "        [-0.0822, -0.0750,  0.0442,  ...,  0.0833,  0.0506,  0.0207],\n",
            "        ...,\n",
            "        [-0.0057,  0.0468, -0.0918,  ...,  0.0195, -0.1040, -0.0061],\n",
            "        [ 0.0214,  0.0100, -0.0558,  ...,  0.0089, -0.0197, -0.0070],\n",
            "        [-0.0933,  0.0894,  0.0328,  ..., -0.0678,  0.0126, -0.1011]])\n",
            "token_encoder.transformer_encoder.layers.1.self_attn.in_proj_bias tensor([-3.3549e-09,  1.3870e-08, -1.9199e-08, -4.4467e-09, -2.4963e-09,\n",
            "         1.5254e-09, -3.6206e-09,  3.8330e-09,  1.2750e-08,  7.2850e-09,\n",
            "         3.7572e-09,  1.3379e-08,  1.3621e-08, -3.0544e-09, -7.8640e-09,\n",
            "        -3.1144e-09, -1.4513e-08,  4.6864e-10, -2.8535e-09,  3.1900e-09,\n",
            "         2.8096e-09,  5.9279e-10,  6.5107e-09,  2.6870e-09, -7.6408e-09,\n",
            "        -9.1754e-09, -6.8567e-09,  6.6009e-09,  1.7322e-09, -3.9667e-09,\n",
            "        -7.2856e-10, -1.2079e-08,  1.3659e-08,  1.6074e-08, -1.4612e-08,\n",
            "         1.2347e-08,  1.3943e-09, -3.0329e-09,  1.6820e-08,  4.1194e-09,\n",
            "        -7.9090e-09,  1.3923e-08,  1.0699e-08,  3.0543e-09,  8.4647e-09,\n",
            "        -1.8772e-09,  3.4633e-09, -1.6704e-08,  1.5665e-08, -1.1783e-09,\n",
            "         3.0519e-09, -1.3588e-08, -2.6767e-09,  8.7044e-09, -8.2951e-09,\n",
            "         7.0727e-09,  7.0813e-09,  1.7064e-08,  5.8714e-09, -2.4552e-08,\n",
            "        -8.6288e-10,  1.3507e-09, -4.6213e-09,  2.4450e-08, -1.8537e-08,\n",
            "        -1.5935e-09, -7.0215e-09, -7.4606e-09,  4.5934e-10, -1.8093e-09,\n",
            "        -2.5452e-09, -7.0255e-09,  2.6176e-10, -3.2015e-09,  6.5269e-10,\n",
            "         8.0269e-09,  1.0358e-08, -7.9819e-09, -7.5769e-09, -6.6405e-09,\n",
            "         4.1542e-09, -5.4224e-09, -6.8189e-09,  1.2235e-09, -4.6141e-09,\n",
            "        -5.8392e-09, -4.6230e-10, -2.2893e-09,  1.6516e-09, -3.4892e-09,\n",
            "         1.7142e-08,  1.8562e-09,  7.3477e-09,  5.0323e-09, -1.5128e-09,\n",
            "        -3.4163e-09, -3.7534e-09,  3.0622e-09, -1.7979e-09,  1.1189e-08,\n",
            "         1.4959e-08,  4.2508e-09,  1.6026e-08, -1.1704e-08, -1.6012e-08,\n",
            "        -1.1009e-08, -7.6677e-09,  1.1010e-08,  5.2859e-09, -7.9140e-09,\n",
            "         9.2027e-09, -1.1843e-08, -8.1030e-09, -2.7560e-09,  4.5978e-09,\n",
            "        -1.3946e-08,  1.3094e-08,  1.0465e-08, -1.5948e-08, -7.9266e-09,\n",
            "         9.9127e-09,  1.5535e-08,  6.4235e-09,  3.6630e-09, -2.6144e-09,\n",
            "         1.0066e-08, -2.4490e-08, -3.4854e-09, -1.3409e-16,  1.0537e-15,\n",
            "         1.4764e-15,  6.1434e-16, -3.8264e-16,  1.8723e-15, -2.8323e-16,\n",
            "        -2.6809e-15,  2.3850e-15,  3.1118e-17,  1.7892e-15, -2.9169e-15,\n",
            "         1.2447e-15, -4.6774e-16, -1.5083e-15,  1.4752e-15, -8.6004e-16,\n",
            "        -2.1128e-15,  1.6720e-15,  1.5012e-15,  8.6135e-16,  1.3413e-16,\n",
            "        -1.7825e-15,  2.1150e-15,  7.6148e-16, -1.1752e-15,  7.8717e-17,\n",
            "        -1.1857e-15, -1.0720e-15, -3.2841e-16,  2.7729e-16,  8.7088e-16,\n",
            "         6.6047e-16,  1.9307e-16, -7.1394e-16,  2.7674e-15, -8.4360e-16,\n",
            "         2.1917e-15, -2.6262e-16,  3.4647e-15, -1.7301e-15,  5.9461e-16,\n",
            "         1.1614e-15,  8.6046e-16,  1.3686e-15, -6.7204e-16,  1.2547e-15,\n",
            "         2.0620e-15, -4.3774e-16, -3.2229e-16,  8.9464e-16,  3.0894e-15,\n",
            "        -5.5670e-16, -1.9720e-15,  7.6116e-16,  2.3856e-16,  1.8047e-15,\n",
            "        -1.6426e-15,  9.0597e-16,  8.2146e-16,  1.8025e-16,  4.6219e-16,\n",
            "        -5.3444e-16, -3.2026e-16, -7.6956e-16, -3.4280e-16, -7.8089e-16,\n",
            "        -7.7145e-16, -5.5574e-16,  1.5413e-16,  5.0031e-16, -2.7527e-15,\n",
            "         8.1207e-16,  1.0813e-16, -8.2507e-16, -3.1201e-16,  1.2730e-15,\n",
            "         4.4765e-16, -3.4826e-15,  7.5957e-16, -1.9831e-15,  9.1616e-16,\n",
            "         1.3267e-15, -2.2239e-15, -4.6734e-16, -1.9212e-15,  1.5381e-15,\n",
            "         6.0030e-18,  2.1018e-15, -8.7409e-16, -1.6912e-15, -1.6017e-15,\n",
            "         2.5197e-15,  2.4141e-15, -1.9004e-15, -2.2432e-15, -1.4605e-15,\n",
            "         9.8988e-16, -6.9402e-16,  1.3467e-15, -2.9437e-16,  7.1523e-16,\n",
            "         6.3368e-16,  2.3412e-15,  1.2643e-16,  2.1353e-15, -3.9169e-15,\n",
            "        -4.8017e-15, -5.1403e-15, -4.6999e-16,  1.5455e-15,  7.7087e-16,\n",
            "         6.2169e-17,  2.2761e-15, -3.5736e-16, -1.1974e-15, -8.6922e-16,\n",
            "        -2.9651e-15, -3.1764e-16,  5.2557e-16,  1.9952e-15, -3.0011e-15,\n",
            "         6.0869e-16,  5.0854e-16,  1.5005e-15,  3.4272e-16,  6.6910e-16,\n",
            "        -5.9059e-16,  4.3887e-08,  1.4376e-07, -1.1570e-08,  1.4144e-08,\n",
            "         5.4819e-08,  2.5999e-08, -7.3965e-08,  9.2769e-09, -2.8498e-08,\n",
            "        -8.8968e-08,  4.9405e-08, -1.1208e-08, -7.0002e-08, -4.4878e-08,\n",
            "        -4.2282e-08,  3.8785e-08,  1.7180e-08, -6.5644e-08, -4.5046e-08,\n",
            "         7.8797e-08,  4.0961e-08,  2.6688e-08,  2.5375e-08, -1.4440e-10,\n",
            "         8.7697e-09,  9.7242e-08, -8.1723e-08, -3.5381e-08, -3.4692e-08,\n",
            "        -1.5424e-08, -4.4927e-08, -9.5661e-08,  1.8393e-08,  1.7382e-08,\n",
            "         1.0436e-08, -5.7078e-09, -1.2274e-08,  7.1102e-09, -5.6680e-08,\n",
            "         3.4087e-08, -3.9166e-08, -2.8731e-08,  1.4336e-08, -1.7130e-08,\n",
            "        -1.5300e-08,  6.9208e-08, -5.4885e-08, -7.5702e-08,  5.3109e-09,\n",
            "        -2.0692e-08, -4.2564e-08,  1.3884e-08,  5.7925e-08, -6.5028e-08,\n",
            "         2.3891e-08, -2.7286e-11,  8.5066e-09,  6.2938e-08, -1.3581e-08,\n",
            "        -4.6311e-08,  1.1901e-07,  9.0054e-08,  6.9685e-08,  3.6733e-08,\n",
            "         7.7356e-08, -3.4379e-09, -7.1492e-08,  3.9372e-09, -3.4475e-09,\n",
            "        -6.5023e-08, -7.1864e-09,  3.3593e-08, -7.4826e-08,  9.2179e-08,\n",
            "         4.6633e-08,  1.2770e-07, -2.8631e-08, -3.4078e-08,  1.9154e-08,\n",
            "         2.4414e-08,  2.9495e-08,  1.9160e-08, -1.5370e-08, -5.8136e-08,\n",
            "         6.3045e-08, -2.5594e-08,  3.5966e-08, -1.3181e-08,  5.6316e-09,\n",
            "         3.4110e-08, -1.2830e-07, -6.5256e-08, -9.7483e-08, -2.3603e-08,\n",
            "        -9.3434e-08, -8.8664e-08, -1.2283e-07,  3.2594e-08, -2.3053e-08,\n",
            "         3.5758e-08, -4.0521e-08, -5.7209e-08,  1.5489e-08,  1.0822e-08,\n",
            "         1.8331e-08, -1.0647e-08,  4.7483e-09,  8.0855e-08, -6.0799e-08,\n",
            "        -4.3107e-08,  6.2098e-09,  6.2732e-09, -2.2131e-08, -7.8226e-08,\n",
            "         1.0571e-08,  4.6808e-08, -5.4204e-08,  9.4879e-09, -8.2928e-08,\n",
            "         1.3033e-08,  9.4677e-08,  1.1529e-08,  1.3284e-07, -5.9459e-08,\n",
            "        -5.9234e-08, -1.0811e-08,  8.0390e-08,  4.0027e-08])\n",
            "token_encoder.transformer_encoder.layers.1.self_attn.out_proj.weight tensor([[-0.0486, -0.0551, -0.0124,  ..., -0.0738, -0.0202, -0.0112],\n",
            "        [ 0.0414, -0.0782,  0.0360,  ..., -0.0850,  0.0135, -0.0172],\n",
            "        [ 0.0421,  0.0650, -0.0834,  ...,  0.0044, -0.0079,  0.0845],\n",
            "        ...,\n",
            "        [ 0.0634,  0.0509,  0.0373,  ...,  0.0335, -0.0538,  0.0432],\n",
            "        [-0.0754,  0.0440,  0.0274,  ..., -0.0472, -0.0735, -0.0036],\n",
            "        [-0.0016,  0.0141,  0.0085,  ...,  0.0873,  0.0173, -0.0135]])\n",
            "token_encoder.transformer_encoder.layers.1.self_attn.out_proj.bias tensor([-1.1326e-07, -9.4326e-08,  9.7021e-08, -1.1526e-07, -6.4244e-08,\n",
            "        -9.7090e-08, -5.0285e-08,  8.8884e-08, -2.1845e-08,  4.5634e-08,\n",
            "         9.0246e-08,  1.1670e-07,  2.0870e-08, -5.8578e-08, -7.3657e-08,\n",
            "        -1.8170e-08, -4.7964e-08, -6.4908e-08, -2.4903e-08, -1.2150e-07,\n",
            "         1.8309e-09,  1.2736e-07,  3.5466e-08, -6.0864e-09,  7.7657e-08,\n",
            "         8.3095e-08,  1.0780e-07, -8.5598e-08,  1.5175e-07, -6.3597e-08,\n",
            "         4.0425e-08,  1.5931e-08, -7.1161e-08,  7.2746e-08,  4.6748e-08,\n",
            "        -8.5554e-08, -6.4640e-08, -3.9022e-09, -5.6471e-08, -5.9635e-08,\n",
            "        -1.3599e-07,  2.1230e-08, -1.0764e-07,  1.0755e-07, -2.0220e-08,\n",
            "        -6.3341e-08,  8.0637e-08,  4.4130e-10, -3.0553e-09, -3.8295e-08,\n",
            "        -6.6768e-08,  1.7067e-07,  2.5228e-08, -7.3480e-08, -1.2975e-07,\n",
            "         2.9511e-08,  5.1452e-08, -3.3548e-08,  5.4064e-08, -1.6396e-07,\n",
            "        -2.4287e-08, -9.7740e-08,  3.2734e-08,  4.4174e-08, -4.1888e-08,\n",
            "         2.5404e-08,  9.3267e-08, -9.2064e-08,  1.6366e-08,  1.8788e-08,\n",
            "         2.7346e-08, -4.7253e-08, -3.7718e-08, -1.6895e-08, -1.1443e-07,\n",
            "         1.0705e-07, -3.6900e-08, -1.6153e-07,  1.9506e-08,  1.1058e-07,\n",
            "        -1.4254e-08, -3.2310e-08,  5.6324e-09, -9.3650e-08, -3.6596e-08,\n",
            "        -3.2069e-08, -1.2266e-08, -9.0885e-10,  2.2543e-08,  1.0270e-07,\n",
            "        -6.1067e-08,  1.8860e-08, -6.4941e-08, -4.6535e-08, -3.4525e-08,\n",
            "        -2.2036e-08,  4.3240e-08,  1.1206e-08, -7.3251e-08,  2.5064e-07,\n",
            "        -3.4503e-08, -2.6953e-07, -9.4499e-08,  4.0583e-08,  7.4313e-08,\n",
            "         4.0425e-09, -2.4047e-08,  8.2252e-08, -1.6206e-08,  3.1809e-09,\n",
            "        -7.2358e-08,  6.3444e-08, -4.6674e-08,  7.9243e-08,  2.9961e-08,\n",
            "        -4.9033e-08,  3.3518e-08, -4.8311e-09, -4.5850e-08,  3.7337e-08,\n",
            "         4.1643e-08, -4.8713e-08, -7.7580e-08,  1.0458e-07,  5.9433e-08,\n",
            "        -1.2171e-07, -6.8199e-08,  7.4656e-08])\n",
            "token_encoder.transformer_encoder.layers.1.linear1.weight tensor([[ 0.0571,  0.0584,  0.0481,  ...,  0.0554, -0.0860, -0.0332],\n",
            "        [ 0.0024, -0.0642,  0.0629,  ..., -0.0878, -0.0876, -0.0085],\n",
            "        [ 0.0873, -0.0248, -0.0677,  ...,  0.0376, -0.0556, -0.0844],\n",
            "        ...,\n",
            "        [ 0.0053,  0.0725,  0.0214,  ...,  0.0507,  0.0543, -0.0073],\n",
            "        [ 0.0036, -0.0372,  0.0872,  ..., -0.0674, -0.0342, -0.0129],\n",
            "        [ 0.0791, -0.0020,  0.0156,  ..., -0.0286,  0.0857, -0.0044]])\n",
            "token_encoder.transformer_encoder.layers.1.linear1.bias tensor([ 0.0805,  0.0645,  0.0708,  0.0106, -0.0359,  0.0673, -0.0490, -0.0237,\n",
            "         0.0195, -0.0361,  0.0791,  0.0427,  0.0223, -0.0784, -0.0120, -0.0044,\n",
            "        -0.0263, -0.0268,  0.0388, -0.0349, -0.0571, -0.0779,  0.0744, -0.0014,\n",
            "        -0.0707, -0.0298, -0.0130, -0.0322, -0.0586, -0.0128,  0.0657,  0.0798,\n",
            "         0.0039, -0.0071,  0.0859, -0.0371, -0.0599,  0.0559,  0.0637, -0.0581,\n",
            "        -0.0570, -0.0676,  0.0667, -0.0303,  0.0844, -0.0602, -0.0138,  0.0791,\n",
            "        -0.0372,  0.0405, -0.0669, -0.0245, -0.0285, -0.0024, -0.0158,  0.0672,\n",
            "         0.0211, -0.0673,  0.0302,  0.0424, -0.0319, -0.0602,  0.0422,  0.0574,\n",
            "        -0.0241, -0.0672,  0.0263,  0.0002,  0.0198,  0.0877,  0.0178, -0.0661,\n",
            "        -0.0291, -0.0710,  0.0253, -0.0713, -0.0027, -0.0464,  0.0098, -0.0452,\n",
            "        -0.0769, -0.0025, -0.0241, -0.0703, -0.0825, -0.0580, -0.0321,  0.0019,\n",
            "         0.0698, -0.0119, -0.0202,  0.0221, -0.0869,  0.0477,  0.0763, -0.0352,\n",
            "        -0.0746,  0.0082,  0.0038, -0.0631, -0.0570, -0.0359,  0.0495,  0.0734,\n",
            "        -0.0126,  0.0669, -0.0752,  0.0277,  0.0752,  0.0248, -0.0117, -0.0408,\n",
            "        -0.0865, -0.0594,  0.0469,  0.0095,  0.0657, -0.0172,  0.0030, -0.0626,\n",
            "        -0.0739, -0.0876,  0.0419,  0.0131, -0.0588, -0.0035,  0.0224, -0.0343])\n",
            "token_encoder.transformer_encoder.layers.1.linear2.weight tensor([[-0.0713,  0.0368, -0.0236,  ..., -0.0532, -0.0118,  0.0241],\n",
            "        [-0.0635, -0.0315,  0.0215,  ...,  0.0819, -0.0870, -0.0466],\n",
            "        [-0.0136,  0.0712, -0.0599,  ..., -0.0559,  0.0848,  0.0543],\n",
            "        ...,\n",
            "        [-0.0010,  0.0134, -0.0321,  ..., -0.0444, -0.0406, -0.0521],\n",
            "        [ 0.0315,  0.0460,  0.0526,  ...,  0.0047,  0.0208,  0.0053],\n",
            "        [-0.0515, -0.0722, -0.0596,  ..., -0.0849, -0.0783,  0.0570]])\n",
            "token_encoder.transformer_encoder.layers.1.linear2.bias tensor([-0.0820, -0.0015,  0.0034,  0.0136, -0.0244,  0.0604,  0.0073,  0.0686,\n",
            "         0.0831,  0.0744,  0.0771,  0.0610, -0.0682,  0.0684,  0.0080, -0.0440,\n",
            "        -0.0761, -0.0401, -0.0584,  0.0392, -0.0703, -0.0450, -0.0306, -0.0610,\n",
            "         0.0640, -0.0075, -0.0770,  0.0671, -0.0113, -0.0350, -0.0757, -0.0784,\n",
            "         0.0458,  0.0095,  0.0776, -0.0811, -0.0071,  0.0665,  0.0655, -0.0298,\n",
            "        -0.0187, -0.0357, -0.0604,  0.0664, -0.0678,  0.0085,  0.0139,  0.0693,\n",
            "         0.0421,  0.0077, -0.0842, -0.0052, -0.0207,  0.0685,  0.0018, -0.0827,\n",
            "        -0.0042,  0.0858, -0.0600,  0.0434,  0.0680,  0.0452,  0.0031,  0.0642,\n",
            "         0.0361,  0.0078, -0.0651,  0.0498, -0.0326, -0.0095, -0.0605, -0.0508,\n",
            "         0.0326, -0.0715,  0.0446,  0.0345, -0.0012, -0.0703, -0.0687, -0.0438,\n",
            "         0.0846,  0.0561, -0.0330, -0.0171,  0.0344, -0.0697, -0.0590,  0.0646,\n",
            "         0.0735,  0.0047, -0.0521,  0.0486, -0.0863,  0.0244, -0.0167,  0.0291,\n",
            "         0.0435, -0.0818, -0.0091,  0.0860, -0.0300, -0.0855, -0.0519, -0.0436,\n",
            "         0.0156,  0.0218,  0.0883, -0.0369,  0.0432,  0.0854, -0.0689, -0.0499,\n",
            "        -0.0711, -0.0312, -0.0014,  0.0186, -0.0610, -0.0336, -0.0861, -0.0834,\n",
            "        -0.0072,  0.0451, -0.0667,  0.0381, -0.0458, -0.0283,  0.0339, -0.0330])\n",
            "token_encoder.transformer_encoder.layers.1.norm1.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.1.norm1.bias tensor([-1.2802e-07, -6.0862e-08,  3.2881e-08, -1.1998e-07, -4.8225e-09,\n",
            "        -5.1263e-08,  5.1819e-08, -9.8530e-09,  6.8870e-08,  5.0893e-08,\n",
            "         7.1032e-08,  9.7688e-08,  4.5670e-10, -3.0951e-08,  8.8170e-09,\n",
            "        -1.6817e-08, -7.6515e-09, -2.4587e-08, -4.2842e-09, -1.4462e-07,\n",
            "         7.9711e-08,  1.6496e-07, -2.2847e-08, -2.4635e-08,  1.4684e-07,\n",
            "        -3.3059e-09,  1.0756e-08, -8.4347e-08,  1.9477e-07,  2.9849e-08,\n",
            "        -1.2859e-09,  2.1084e-08,  4.5370e-08,  4.3519e-08,  4.3639e-08,\n",
            "        -3.8167e-08, -6.0988e-08, -9.0350e-09,  3.2997e-08, -6.6755e-08,\n",
            "        -1.9391e-07,  6.3391e-08, -4.8635e-08,  8.7618e-08, -6.2358e-08,\n",
            "        -2.7966e-08,  8.4494e-08, -5.3121e-08, -6.4946e-08,  4.4973e-08,\n",
            "        -7.5773e-09,  1.2439e-07,  4.3499e-08,  1.7372e-08, -4.7183e-08,\n",
            "         1.8640e-08,  1.0394e-07, -9.3985e-09,  4.6287e-08, -3.1704e-08,\n",
            "        -1.7264e-08, -7.4634e-08, -2.1092e-09,  5.1724e-08, -4.4884e-08,\n",
            "         4.0183e-10,  4.8859e-08, -6.0333e-08,  1.2453e-09,  2.3822e-08,\n",
            "         5.3540e-08, -6.5569e-08, -4.5178e-08, -2.0028e-08, -4.5148e-08,\n",
            "         1.3361e-07, -7.8107e-08, -6.6911e-08, -2.3879e-08,  9.9751e-08,\n",
            "         1.8233e-08, -3.2801e-08, -4.2968e-08,  9.8749e-09,  3.8723e-08,\n",
            "        -3.4046e-08,  7.7809e-08,  1.5019e-08,  4.5428e-08,  1.1856e-07,\n",
            "        -8.4364e-08,  2.0952e-08,  3.9874e-08,  1.8982e-08, -4.5004e-08,\n",
            "         3.9803e-08,  2.5684e-08,  3.8008e-08, -3.2671e-08,  1.1680e-07,\n",
            "        -2.3520e-08, -1.0260e-07, -9.7035e-08,  3.5641e-08, -1.5330e-08,\n",
            "        -5.5525e-08, -1.1843e-08,  6.0563e-08,  1.7434e-08, -3.8345e-08,\n",
            "        -5.5933e-08,  2.6510e-08,  1.5253e-09,  8.5726e-08,  5.3115e-08,\n",
            "        -5.4790e-08,  6.8271e-08,  1.7861e-08, -1.0873e-07,  2.5999e-08,\n",
            "         1.8543e-09, -7.4784e-08, -7.6976e-08,  7.6376e-08, -2.3605e-08,\n",
            "         7.9936e-09, -7.9296e-08,  5.1565e-10])\n",
            "token_encoder.transformer_encoder.layers.1.norm2.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.1.norm2.bias tensor([-1.1214e-07, -4.0787e-08,  4.1821e-08, -1.2398e-07,  1.0996e-08,\n",
            "        -5.1134e-08,  7.2494e-08, -5.8741e-08,  1.6383e-08,  6.4880e-08,\n",
            "         4.6519e-08,  9.4225e-08, -1.0349e-08,  1.9119e-09, -5.5860e-09,\n",
            "        -4.0709e-08,  5.0936e-08, -4.7618e-08, -8.2884e-10, -1.5111e-07,\n",
            "         6.3176e-08,  1.4342e-07, -4.8200e-08,  2.5226e-08,  1.3915e-07,\n",
            "         4.9868e-08,  2.9569e-08, -1.3022e-08,  1.7905e-07,  3.9083e-09,\n",
            "        -1.2499e-08,  6.5764e-08,  6.1132e-08,  4.7234e-08,  5.6361e-08,\n",
            "        -4.0575e-08, -6.3821e-08, -8.7889e-09,  1.3125e-08, -8.2456e-08,\n",
            "        -1.9991e-07,  6.3503e-08, -3.6022e-08,  1.0662e-07, -6.3278e-08,\n",
            "        -1.0168e-08,  6.5177e-08,  2.7161e-09, -5.2159e-08,  2.8172e-08,\n",
            "         5.0298e-09,  1.3044e-07,  4.8879e-08,  1.4056e-08, -8.9121e-08,\n",
            "        -3.6938e-09,  1.4992e-07, -1.5407e-08,  9.0868e-08, -1.3030e-08,\n",
            "        -3.1645e-08, -4.5132e-08, -1.7112e-09,  3.6829e-08, -4.4177e-09,\n",
            "         3.1452e-08,  6.5043e-08, -4.8078e-08, -3.3093e-08, -5.0313e-09,\n",
            "         2.2560e-08, -1.6409e-08, -7.2256e-08, -3.1179e-09,  6.7821e-09,\n",
            "         1.2585e-07, -1.2333e-07, -4.6426e-08,  1.7531e-08,  1.3343e-07,\n",
            "        -7.5154e-09, -1.7675e-08, -6.5627e-08, -1.8440e-08, -2.9923e-09,\n",
            "        -2.0783e-08,  8.8928e-08,  6.2414e-09,  4.5194e-08,  8.6244e-08,\n",
            "        -6.1819e-08,  2.3380e-08, -3.1080e-09,  2.2272e-08, -4.7820e-09,\n",
            "         2.8295e-08,  4.5285e-08,  3.0523e-08,  2.8675e-08,  2.5793e-08,\n",
            "        -3.6910e-08, -1.2764e-07, -9.0366e-08,  7.3416e-09, -3.7478e-09,\n",
            "        -4.5895e-08, -5.2667e-09,  7.8917e-08,  2.1557e-08, -9.0314e-08,\n",
            "        -3.9897e-08,  2.6901e-08, -3.5216e-08,  1.1094e-07,  5.4462e-08,\n",
            "        -6.6912e-08,  1.3834e-07,  5.6496e-09, -1.0039e-07,  5.0415e-08,\n",
            "         1.0117e-08, -2.9870e-08, -8.2155e-08,  6.1817e-08, -3.4543e-08,\n",
            "         5.4889e-08, -5.1027e-08, -2.2101e-09])\n",
            "token_encoder.transformer_encoder.layers.2.self_attn.in_proj_weight tensor([[-0.0206, -0.0443,  0.0245,  ...,  0.0695,  0.0129, -0.0172],\n",
            "        [-0.0673,  0.0118,  0.0623,  ..., -0.0257, -0.0630,  0.0006],\n",
            "        [-0.0822, -0.0750,  0.0442,  ...,  0.0833,  0.0506,  0.0207],\n",
            "        ...,\n",
            "        [-0.0057,  0.0468, -0.0918,  ...,  0.0195, -0.1040, -0.0061],\n",
            "        [ 0.0214,  0.0100, -0.0558,  ...,  0.0089, -0.0197, -0.0070],\n",
            "        [-0.0933,  0.0894,  0.0328,  ..., -0.0678,  0.0126, -0.1011]])\n",
            "token_encoder.transformer_encoder.layers.2.self_attn.in_proj_bias tensor([-1.1849e-08, -1.9309e-09, -2.0321e-09, -8.2927e-09, -5.5206e-09,\n",
            "         7.2346e-11,  8.6237e-09, -1.9634e-09,  6.9981e-09,  4.1940e-09,\n",
            "         6.6056e-09,  2.8677e-09,  4.2842e-09,  1.2600e-08, -4.5411e-09,\n",
            "         6.5091e-10, -4.5558e-09,  1.0468e-08, -2.5512e-09,  1.1385e-09,\n",
            "        -2.2827e-09,  1.0455e-08, -8.6610e-10, -9.7986e-09, -1.2825e-08,\n",
            "        -1.2316e-08, -1.0711e-08,  1.1666e-08,  1.4163e-08,  2.8230e-09,\n",
            "        -9.9402e-09, -9.4306e-09,  3.5688e-09, -2.4792e-09,  8.6867e-09,\n",
            "         3.3803e-08,  5.8205e-09, -9.0201e-09,  8.6992e-10, -3.6216e-09,\n",
            "         7.5725e-09,  1.5191e-08,  5.9789e-09, -2.1217e-08,  2.2232e-09,\n",
            "        -7.9492e-09, -1.7490e-10, -1.4048e-08,  3.6222e-08, -1.0269e-08,\n",
            "         1.6176e-09, -1.1434e-09, -6.1073e-09,  8.9916e-10,  1.2161e-08,\n",
            "         2.5956e-09,  5.7604e-09, -1.0098e-08, -8.7735e-09, -8.0021e-09,\n",
            "        -7.3218e-09, -4.4158e-09,  2.7863e-08,  3.0302e-08, -8.7039e-09,\n",
            "        -1.8629e-09, -3.2898e-09, -9.5561e-09, -7.7149e-09,  1.3129e-08,\n",
            "         1.0286e-09, -1.9388e-09, -9.1719e-09,  6.3409e-09,  1.3520e-08,\n",
            "         7.7957e-10,  2.2468e-08, -1.4724e-08, -1.2984e-08, -3.0407e-09,\n",
            "         1.0372e-08, -4.1109e-09,  1.2145e-09,  2.9365e-10, -2.1476e-08,\n",
            "         9.6530e-09, -1.0096e-08, -3.3277e-09,  5.6143e-09, -3.0840e-09,\n",
            "        -1.4705e-09,  2.8754e-09, -3.5624e-09, -4.1403e-09,  6.0248e-09,\n",
            "        -1.0618e-08, -4.4814e-09,  8.4252e-09,  5.7585e-09, -1.2223e-09,\n",
            "        -7.8893e-10,  7.4140e-09, -1.6487e-10,  3.1730e-10, -3.7142e-09,\n",
            "        -1.2660e-08,  1.9775e-08, -2.3067e-09,  6.4152e-10,  2.3662e-09,\n",
            "        -1.3185e-08, -1.0797e-09, -2.1018e-08, -6.9544e-09,  1.2837e-08,\n",
            "         2.3870e-09, -2.3952e-09, -2.4116e-09,  5.3493e-09, -5.7793e-09,\n",
            "         4.5074e-09,  5.9450e-09,  2.9606e-09,  1.2055e-09,  4.6369e-09,\n",
            "        -4.0544e-09, -4.6086e-09, -1.8460e-09,  4.8580e-16, -1.4959e-15,\n",
            "         6.0237e-18,  2.3114e-15, -1.4181e-15, -6.7748e-16,  9.3005e-16,\n",
            "        -3.5954e-16, -4.3370e-16,  1.9233e-15, -1.1374e-15, -1.8794e-15,\n",
            "        -3.2015e-15,  9.9831e-16,  5.2896e-16,  2.1738e-15, -8.8168e-16,\n",
            "        -1.6107e-15,  2.4773e-15,  1.2730e-15, -1.7093e-15, -1.3566e-15,\n",
            "         3.2077e-16,  2.0059e-15,  1.5440e-15, -1.1932e-15,  4.0626e-16,\n",
            "         9.1415e-16, -2.2275e-15, -3.3695e-16,  1.0024e-15, -1.9353e-15,\n",
            "         2.5630e-15, -3.7375e-16,  1.7507e-15,  2.8586e-16,  4.0224e-17,\n",
            "         1.1896e-15, -3.4948e-17, -5.9048e-16, -4.9458e-16, -2.3003e-15,\n",
            "        -1.2448e-15,  3.9709e-16, -3.4116e-16,  1.1123e-15, -1.1526e-15,\n",
            "         9.2717e-16,  6.9296e-16, -1.8116e-15, -2.1087e-15,  2.7031e-16,\n",
            "         1.8201e-15,  1.8091e-15,  2.1678e-15,  3.7067e-16,  2.4388e-15,\n",
            "         6.5815e-16,  3.7561e-16, -1.5176e-15,  3.9375e-16, -7.2496e-16,\n",
            "        -1.4318e-15,  2.1065e-15,  6.4584e-16,  3.6323e-15, -1.0799e-15,\n",
            "         9.4091e-16, -1.5458e-16, -6.9723e-16,  1.7295e-15,  2.0376e-15,\n",
            "         1.0002e-15, -2.0509e-15,  1.8637e-15,  2.2401e-15,  4.3761e-16,\n",
            "         1.1132e-16, -1.1101e-15,  2.2035e-16,  2.6836e-15, -1.4418e-15,\n",
            "         3.6332e-16, -3.6891e-15,  9.6950e-16, -4.9062e-16,  1.2008e-15,\n",
            "         6.7320e-16,  1.2196e-17, -2.3599e-15, -3.1330e-15, -2.4503e-15,\n",
            "         1.0889e-15,  1.0570e-15, -1.4954e-16,  2.1373e-15,  2.1782e-15,\n",
            "        -2.1828e-15,  9.8990e-16,  6.3232e-16,  1.2151e-15,  5.3179e-16,\n",
            "        -1.2608e-15,  2.9837e-16, -1.9872e-16,  8.9702e-16, -3.7934e-15,\n",
            "        -2.3685e-15,  6.3512e-16,  2.5661e-15, -1.2615e-15, -1.2050e-15,\n",
            "        -5.5107e-16,  4.5268e-15,  4.3777e-16,  2.2125e-15, -1.4258e-15,\n",
            "        -1.4081e-15, -6.6690e-16,  2.0743e-15,  1.8677e-15, -1.2145e-15,\n",
            "         1.7183e-16, -1.4139e-15,  2.2499e-15,  1.4323e-16,  1.0941e-15,\n",
            "         2.6076e-15,  1.5934e-07,  5.4736e-08,  6.4278e-08,  5.8348e-08,\n",
            "         1.7003e-07,  1.5403e-08,  1.4503e-08, -9.2204e-08,  9.2140e-08,\n",
            "         1.0297e-08, -2.9250e-08, -3.8509e-08, -2.2880e-08, -2.1497e-08,\n",
            "         4.3524e-08, -2.5648e-08,  6.2107e-08,  3.1120e-08,  2.5568e-08,\n",
            "        -4.6911e-08,  2.1039e-08, -3.4890e-08,  2.9271e-08, -1.5297e-08,\n",
            "         8.0326e-08,  1.0670e-08, -3.3021e-09,  2.2136e-08, -6.7152e-08,\n",
            "         6.3233e-08,  9.9882e-09, -2.8517e-08, -1.4347e-08,  1.1892e-08,\n",
            "        -5.7411e-08, -1.2811e-09, -2.2667e-08,  2.7860e-08, -5.3455e-08,\n",
            "         6.3137e-08,  5.9489e-08, -3.5932e-08,  1.6223e-08,  1.0826e-08,\n",
            "         4.9169e-08,  7.7027e-08,  4.9007e-08,  7.7771e-09, -6.4615e-08,\n",
            "        -4.5512e-09, -5.0003e-08,  4.4061e-08,  4.6880e-09, -1.3881e-08,\n",
            "         1.2667e-08,  2.4642e-08,  5.1815e-08, -8.6799e-08, -4.7950e-08,\n",
            "         3.8719e-09,  1.0629e-08,  9.2647e-08,  3.2653e-08,  4.2620e-08,\n",
            "         4.2234e-08, -5.5139e-08,  4.2499e-09, -1.2633e-07, -6.1903e-08,\n",
            "         3.3501e-08, -9.1761e-08, -8.7323e-08, -5.3006e-08,  4.1223e-08,\n",
            "         3.6551e-08, -8.1795e-09, -1.1197e-08,  3.1092e-09, -1.8734e-08,\n",
            "         4.4793e-08, -2.4648e-08,  4.9844e-09,  5.2772e-08, -4.8143e-08,\n",
            "         6.4712e-08, -2.0440e-08,  1.8535e-08,  6.2454e-08, -1.0812e-08,\n",
            "         1.2739e-08, -7.6729e-08,  4.4440e-08, -4.8741e-08, -7.7793e-08,\n",
            "        -7.8214e-09,  3.9079e-08,  1.2375e-08,  3.5143e-08, -7.9101e-09,\n",
            "        -2.0982e-08,  2.9154e-10,  1.3005e-08, -1.8141e-08,  3.7655e-08,\n",
            "         2.3737e-08, -2.7748e-09,  5.4634e-08, -5.3777e-08, -6.3754e-08,\n",
            "        -7.6513e-08,  1.7846e-08, -1.0619e-07, -2.8096e-08, -5.6943e-08,\n",
            "         2.5876e-08, -1.2483e-08, -5.4608e-08,  1.4692e-08, -1.9491e-08,\n",
            "         5.6950e-08,  2.3349e-08,  5.0380e-08,  3.3581e-08, -6.4643e-08,\n",
            "        -7.3652e-08,  3.2191e-08, -1.7510e-08,  5.5846e-08])\n",
            "token_encoder.transformer_encoder.layers.2.self_attn.out_proj.weight tensor([[-0.0486, -0.0551, -0.0124,  ..., -0.0738, -0.0202, -0.0112],\n",
            "        [ 0.0414, -0.0782,  0.0360,  ..., -0.0850,  0.0135, -0.0172],\n",
            "        [ 0.0421,  0.0650, -0.0834,  ...,  0.0044, -0.0079,  0.0845],\n",
            "        ...,\n",
            "        [ 0.0634,  0.0509,  0.0373,  ...,  0.0335, -0.0538,  0.0432],\n",
            "        [-0.0754,  0.0440,  0.0274,  ..., -0.0472, -0.0735, -0.0036],\n",
            "        [-0.0016,  0.0141,  0.0085,  ...,  0.0873,  0.0173, -0.0135]])\n",
            "token_encoder.transformer_encoder.layers.2.self_attn.out_proj.bias tensor([-1.1663e-07, -3.2355e-08,  1.5438e-07, -1.0480e-07, -5.5468e-08,\n",
            "         2.9635e-08,  8.7588e-08, -9.9175e-08,  5.2118e-08,  4.8915e-08,\n",
            "         1.5578e-07,  1.2745e-07, -4.0608e-08,  1.3791e-07,  1.1751e-08,\n",
            "        -4.5672e-08,  3.7241e-08,  2.2091e-08, -1.6138e-08, -2.8579e-08,\n",
            "        -5.3007e-09,  1.9597e-08, -4.0947e-09,  2.3823e-08,  4.0187e-08,\n",
            "         1.6023e-08, -2.9838e-08, -4.1636e-09,  1.4561e-07,  7.5038e-08,\n",
            "        -9.4037e-08,  5.1167e-08,  8.1824e-08,  1.6397e-08,  4.4804e-08,\n",
            "         1.7451e-08,  5.4512e-08, -1.0731e-07,  5.3585e-08, -1.5083e-07,\n",
            "        -1.6900e-07,  9.5236e-08, -3.7063e-08,  8.7946e-09, -6.6033e-08,\n",
            "        -7.8714e-08, -6.1688e-08,  1.2649e-08, -2.0182e-09,  2.6325e-08,\n",
            "        -1.5896e-08,  2.3368e-08,  7.2963e-08, -7.7972e-08,  6.7087e-08,\n",
            "         1.9636e-08,  4.6736e-08, -5.4947e-09,  2.0925e-08,  2.1331e-08,\n",
            "        -7.2630e-08,  1.1052e-08, -1.9545e-08, -2.8510e-08,  6.4326e-08,\n",
            "        -3.5742e-08, -4.4330e-09,  1.4327e-08,  2.1812e-08,  4.1540e-08,\n",
            "        -1.9954e-08, -1.5707e-09, -3.9678e-08,  9.6944e-08,  1.3881e-08,\n",
            "         4.3261e-08, -3.0580e-08, -9.6596e-08,  3.4588e-08,  7.1396e-08,\n",
            "        -2.7012e-08,  1.8836e-08, -1.0420e-07,  5.1032e-08, -8.7305e-08,\n",
            "         2.1440e-09,  1.9934e-08,  6.8129e-08,  8.0116e-08,  5.1186e-08,\n",
            "        -1.3878e-08, -8.3549e-09, -6.0126e-08,  5.3539e-09,  6.3022e-08,\n",
            "        -2.4672e-08,  1.3169e-09,  4.3895e-08, -1.0454e-08,  2.5465e-08,\n",
            "        -3.3807e-10, -6.8020e-08, -9.6212e-09,  1.0867e-08,  1.0953e-07,\n",
            "        -3.8008e-09,  1.7490e-08,  3.8661e-08, -1.7401e-08, -5.8259e-08,\n",
            "         1.7850e-08,  1.3472e-07, -8.2254e-08,  6.3231e-08, -1.9204e-08,\n",
            "        -8.8855e-08,  7.2174e-08,  6.8873e-09, -8.6782e-08,  2.5100e-08,\n",
            "         2.3955e-08, -3.5560e-08, -4.8172e-08,  3.3142e-08,  3.9402e-08,\n",
            "        -7.5315e-08, -7.1014e-08, -1.9847e-08])\n",
            "token_encoder.transformer_encoder.layers.2.linear1.weight tensor([[ 0.0571,  0.0584,  0.0481,  ...,  0.0554, -0.0860, -0.0332],\n",
            "        [ 0.0024, -0.0642,  0.0629,  ..., -0.0878, -0.0876, -0.0085],\n",
            "        [ 0.0873, -0.0248, -0.0677,  ...,  0.0376, -0.0556, -0.0844],\n",
            "        ...,\n",
            "        [ 0.0053,  0.0725,  0.0214,  ...,  0.0507,  0.0543, -0.0073],\n",
            "        [ 0.0036, -0.0372,  0.0872,  ..., -0.0674, -0.0342, -0.0129],\n",
            "        [ 0.0791, -0.0020,  0.0156,  ..., -0.0286,  0.0857, -0.0044]])\n",
            "token_encoder.transformer_encoder.layers.2.linear1.bias tensor([ 0.0805,  0.0645,  0.0708,  0.0106, -0.0359,  0.0673, -0.0490, -0.0237,\n",
            "         0.0195, -0.0361,  0.0791,  0.0427,  0.0223, -0.0784, -0.0120, -0.0044,\n",
            "        -0.0263, -0.0268,  0.0388, -0.0349, -0.0571, -0.0779,  0.0744, -0.0014,\n",
            "        -0.0707, -0.0298, -0.0130, -0.0322, -0.0586, -0.0128,  0.0657,  0.0798,\n",
            "         0.0039, -0.0071,  0.0859, -0.0371, -0.0599,  0.0559,  0.0637, -0.0581,\n",
            "        -0.0570, -0.0676,  0.0667, -0.0303,  0.0844, -0.0602, -0.0138,  0.0791,\n",
            "        -0.0372,  0.0405, -0.0669, -0.0245, -0.0285, -0.0024, -0.0158,  0.0672,\n",
            "         0.0211, -0.0673,  0.0302,  0.0424, -0.0319, -0.0602,  0.0422,  0.0574,\n",
            "        -0.0241, -0.0672,  0.0263,  0.0002,  0.0198,  0.0877,  0.0178, -0.0661,\n",
            "        -0.0291, -0.0710,  0.0253, -0.0713, -0.0027, -0.0464,  0.0098, -0.0452,\n",
            "        -0.0769, -0.0025, -0.0241, -0.0703, -0.0825, -0.0580, -0.0321,  0.0019,\n",
            "         0.0698, -0.0119, -0.0202,  0.0221, -0.0869,  0.0477,  0.0763, -0.0352,\n",
            "        -0.0746,  0.0082,  0.0038, -0.0631, -0.0570, -0.0359,  0.0495,  0.0734,\n",
            "        -0.0126,  0.0669, -0.0752,  0.0277,  0.0752,  0.0248, -0.0117, -0.0408,\n",
            "        -0.0865, -0.0594,  0.0469,  0.0095,  0.0657, -0.0172,  0.0030, -0.0626,\n",
            "        -0.0739, -0.0876,  0.0419,  0.0131, -0.0588, -0.0035,  0.0224, -0.0343])\n",
            "token_encoder.transformer_encoder.layers.2.linear2.weight tensor([[-0.0713,  0.0368, -0.0236,  ..., -0.0532, -0.0118,  0.0241],\n",
            "        [-0.0635, -0.0315,  0.0215,  ...,  0.0819, -0.0870, -0.0466],\n",
            "        [-0.0136,  0.0712, -0.0599,  ..., -0.0559,  0.0848,  0.0543],\n",
            "        ...,\n",
            "        [-0.0010,  0.0134, -0.0321,  ..., -0.0444, -0.0406, -0.0521],\n",
            "        [ 0.0315,  0.0460,  0.0526,  ...,  0.0047,  0.0208,  0.0053],\n",
            "        [-0.0515, -0.0722, -0.0596,  ..., -0.0849, -0.0783,  0.0570]])\n",
            "token_encoder.transformer_encoder.layers.2.linear2.bias tensor([-0.0820, -0.0015,  0.0034,  0.0136, -0.0244,  0.0604,  0.0073,  0.0686,\n",
            "         0.0831,  0.0744,  0.0771,  0.0610, -0.0682,  0.0684,  0.0080, -0.0440,\n",
            "        -0.0761, -0.0401, -0.0584,  0.0392, -0.0703, -0.0450, -0.0306, -0.0610,\n",
            "         0.0640, -0.0075, -0.0770,  0.0671, -0.0113, -0.0350, -0.0757, -0.0784,\n",
            "         0.0458,  0.0095,  0.0776, -0.0811, -0.0071,  0.0665,  0.0655, -0.0298,\n",
            "        -0.0187, -0.0357, -0.0604,  0.0664, -0.0678,  0.0085,  0.0139,  0.0693,\n",
            "         0.0421,  0.0077, -0.0842, -0.0052, -0.0207,  0.0685,  0.0018, -0.0827,\n",
            "        -0.0042,  0.0858, -0.0600,  0.0434,  0.0680,  0.0452,  0.0031,  0.0642,\n",
            "         0.0361,  0.0078, -0.0651,  0.0498, -0.0326, -0.0095, -0.0605, -0.0508,\n",
            "         0.0326, -0.0715,  0.0446,  0.0345, -0.0012, -0.0703, -0.0687, -0.0438,\n",
            "         0.0846,  0.0561, -0.0330, -0.0171,  0.0344, -0.0697, -0.0590,  0.0646,\n",
            "         0.0735,  0.0047, -0.0521,  0.0486, -0.0863,  0.0244, -0.0167,  0.0291,\n",
            "         0.0435, -0.0818, -0.0091,  0.0860, -0.0300, -0.0855, -0.0519, -0.0436,\n",
            "         0.0156,  0.0218,  0.0883, -0.0369,  0.0432,  0.0854, -0.0689, -0.0499,\n",
            "        -0.0711, -0.0312, -0.0014,  0.0186, -0.0610, -0.0336, -0.0861, -0.0834,\n",
            "        -0.0072,  0.0451, -0.0667,  0.0381, -0.0458, -0.0283,  0.0339, -0.0330])\n",
            "token_encoder.transformer_encoder.layers.2.norm1.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.2.norm1.bias tensor([-9.5345e-08, -2.2365e-08,  4.3853e-08, -1.3343e-07, -1.0242e-08,\n",
            "        -4.8186e-08,  9.8473e-08, -1.1413e-07,  3.5294e-09,  4.5538e-08,\n",
            "         5.4512e-08,  9.0122e-08, -8.0551e-09,  6.4051e-08, -1.4616e-08,\n",
            "        -4.4255e-08,  2.0465e-08, -6.8287e-08,  7.4238e-09, -9.3294e-08,\n",
            "         4.0936e-08,  7.3395e-08, -5.4912e-08,  3.4562e-08,  1.2070e-07,\n",
            "         2.6866e-09, -2.7316e-08, -2.6800e-08,  1.8009e-07,  4.8461e-08,\n",
            "        -9.8519e-09,  5.4403e-08,  5.0591e-08,  4.3827e-08,  4.7662e-08,\n",
            "        -5.2290e-09, -1.3679e-08, -1.2183e-07, -3.1390e-08, -1.5316e-07,\n",
            "        -2.0109e-07,  8.4718e-08,  1.0902e-08,  4.1788e-08, -4.3755e-09,\n",
            "        -5.4797e-08, -1.4061e-08,  1.1342e-08, -3.8000e-08,  5.3267e-08,\n",
            "         2.2626e-08,  1.1414e-07,  6.2197e-08, -1.5615e-08, -9.0235e-08,\n",
            "         1.1582e-08,  5.6183e-08,  2.2298e-08,  8.9974e-08,  2.4776e-08,\n",
            "        -6.9071e-08, -3.2295e-08,  3.0307e-08,  8.7369e-09,  1.5993e-08,\n",
            "        -5.3042e-08,  1.1922e-09, -5.0102e-08, -9.6344e-08, -2.8744e-08,\n",
            "         2.5274e-08, -2.6923e-09, -5.0572e-08,  4.9824e-08, -5.3267e-09,\n",
            "         7.2675e-08, -5.9553e-08, -8.9658e-08,  4.5771e-09,  8.4258e-08,\n",
            "        -4.9297e-08, -6.2957e-08, -1.0052e-07,  5.6674e-08, -1.0993e-08,\n",
            "        -5.4600e-08,  3.3546e-08,  4.8635e-08,  3.3773e-08,  3.6256e-08,\n",
            "        -9.1891e-08,  1.9270e-08, -1.8439e-09,  2.7325e-08, -1.1870e-08,\n",
            "         1.9997e-09,  5.4786e-08,  6.7349e-08, -6.7649e-08,  3.2862e-08,\n",
            "        -5.0202e-08, -1.1564e-07, -4.2014e-08,  6.1972e-08, -4.7370e-08,\n",
            "        -2.3030e-08,  2.3646e-08,  8.8068e-08,  4.1753e-09, -4.6409e-08,\n",
            "        -3.3935e-08, -8.5707e-09, -8.3111e-08,  1.3046e-07,  2.7236e-09,\n",
            "        -4.5480e-08,  1.3597e-07,  2.1864e-08, -8.7595e-08,  2.5174e-08,\n",
            "         3.8232e-08, -4.7802e-08, -4.1946e-08,  6.4058e-08, -4.4073e-08,\n",
            "         7.2714e-08, -9.9825e-08, -2.1205e-08])\n",
            "token_encoder.transformer_encoder.layers.2.norm2.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.2.norm2.bias tensor([-6.9325e-08,  1.7697e-08,  6.9593e-08, -1.1647e-07,  5.2292e-08,\n",
            "        -5.6464e-08,  7.6409e-08, -1.1805e-07, -1.3722e-09,  9.1152e-08,\n",
            "         2.1913e-08,  9.1179e-08,  1.5034e-08, -1.7112e-08, -5.7179e-09,\n",
            "        -6.9203e-08,  5.9797e-08, -5.3177e-08,  1.7637e-08, -6.6849e-08,\n",
            "         8.3432e-08,  1.1284e-07, -5.4879e-08,  1.5602e-08,  8.5306e-08,\n",
            "        -1.3524e-08, -3.3186e-08, -8.0460e-10,  2.0742e-07,  3.0709e-09,\n",
            "        -5.6608e-10,  5.7171e-08,  2.9955e-08,  6.6137e-08,  3.8792e-08,\n",
            "         7.6748e-09,  7.3866e-09, -9.1647e-08, -2.7223e-08, -1.8242e-07,\n",
            "        -2.2206e-07,  9.3562e-08, -5.3836e-09,  6.2194e-08,  1.7725e-08,\n",
            "        -4.3993e-08, -2.0066e-09,  7.0459e-08, -7.7366e-09,  2.1280e-08,\n",
            "         1.0122e-08,  1.2642e-07,  6.1106e-08,  2.8051e-08, -8.9775e-08,\n",
            "        -4.8671e-09,  5.0055e-08,  1.8034e-08,  9.7124e-08, -1.0534e-08,\n",
            "        -5.1148e-08, -4.3890e-09, -1.3329e-10,  1.2251e-08,  1.7366e-08,\n",
            "        -6.6673e-08,  5.4956e-08, -1.3186e-08, -9.0895e-08,  8.8828e-09,\n",
            "        -2.3290e-08, -4.4900e-08, -4.7821e-08,  5.7020e-08,  2.0245e-11,\n",
            "         4.5119e-08, -5.6546e-08, -6.8906e-08, -1.8795e-08,  7.0922e-08,\n",
            "        -3.5073e-08, -6.9048e-08, -9.0896e-08,  5.6644e-08,  2.2125e-08,\n",
            "        -6.7449e-08,  1.7353e-08,  3.5971e-08,  4.0304e-08,  2.1126e-08,\n",
            "        -1.1834e-07, -1.7311e-08, -1.4426e-08,  2.0706e-08,  8.3564e-09,\n",
            "         2.5855e-08,  8.3783e-08,  3.9688e-08, -4.6867e-08,  6.4334e-09,\n",
            "        -7.7487e-08, -7.0485e-08, -3.8706e-09,  9.6592e-08, -3.1343e-08,\n",
            "        -4.2364e-08,  2.4051e-08,  8.4104e-08, -2.7700e-09, -2.5509e-08,\n",
            "        -5.8686e-08, -3.1833e-08, -8.4005e-08,  1.2334e-07, -1.1550e-08,\n",
            "        -3.5566e-08,  1.0877e-07,  3.4068e-08, -9.1752e-08,  3.3605e-08,\n",
            "         7.1166e-08,  1.8666e-08, -2.6911e-08,  6.6421e-08, -8.4552e-08,\n",
            "         3.3914e-09, -3.9228e-08,  1.2586e-09])\n",
            "token_encoder.transformer_encoder.layers.3.self_attn.in_proj_weight tensor([[-0.0206, -0.0443,  0.0245,  ...,  0.0695,  0.0129, -0.0172],\n",
            "        [-0.0673,  0.0118,  0.0623,  ..., -0.0257, -0.0630,  0.0006],\n",
            "        [-0.0822, -0.0750,  0.0442,  ...,  0.0833,  0.0506,  0.0207],\n",
            "        ...,\n",
            "        [-0.0057,  0.0468, -0.0918,  ...,  0.0195, -0.1040, -0.0061],\n",
            "        [ 0.0214,  0.0100, -0.0558,  ...,  0.0089, -0.0197, -0.0070],\n",
            "        [-0.0933,  0.0894,  0.0328,  ..., -0.0678,  0.0126, -0.1011]])\n",
            "token_encoder.transformer_encoder.layers.3.self_attn.in_proj_bias tensor([-7.2404e-10, -2.7288e-09,  9.0377e-09, -1.2270e-08, -3.8099e-09,\n",
            "         1.8930e-09,  8.1045e-09,  2.2708e-09,  1.0890e-09,  4.4034e-09,\n",
            "         4.0327e-09,  2.3365e-09,  5.9997e-09, -1.1006e-08,  6.7760e-09,\n",
            "        -8.0367e-09, -3.8895e-09, -6.6621e-09,  2.1551e-09, -1.2175e-08,\n",
            "         1.1314e-08, -1.3010e-09, -9.1308e-09, -3.3794e-09, -7.1918e-09,\n",
            "        -1.2638e-08,  1.7838e-09, -8.3814e-11,  1.3678e-09,  1.0996e-09,\n",
            "         3.2389e-09,  1.0011e-08, -6.7709e-09,  2.2706e-09,  2.4117e-08,\n",
            "         3.3971e-08,  1.5652e-09, -7.6618e-09, -1.0392e-08, -4.4874e-09,\n",
            "        -1.1225e-08, -6.8348e-09, -1.0551e-09,  7.5106e-10,  5.7883e-09,\n",
            "         1.0594e-08, -1.2503e-08, -1.3827e-10,  1.2057e-08, -2.3121e-09,\n",
            "        -1.7866e-08, -1.1469e-08,  1.5507e-08,  3.5070e-09,  3.1072e-08,\n",
            "         3.7507e-09,  1.2185e-08, -1.1127e-08,  1.4918e-08, -1.7700e-08,\n",
            "         5.5721e-09,  7.9945e-10,  1.8128e-08,  1.7820e-08, -1.0732e-08,\n",
            "         4.7197e-09, -1.4806e-08, -6.0303e-09, -6.8219e-09,  9.6696e-09,\n",
            "         8.3318e-09, -2.2100e-08, -1.4608e-08, -1.0114e-08, -1.3659e-08,\n",
            "         3.0915e-09,  1.2221e-08,  4.9434e-09,  7.0148e-09,  2.0936e-08,\n",
            "        -1.1295e-08,  1.4898e-08, -2.7906e-09,  3.9891e-09, -4.2920e-09,\n",
            "        -4.7184e-09,  6.7473e-10,  2.0653e-09,  2.9500e-09, -1.3433e-08,\n",
            "         1.7484e-08, -5.3707e-09,  4.6015e-09,  1.1006e-08, -9.9933e-10,\n",
            "        -9.4575e-10, -1.2552e-08,  8.4346e-09, -1.6570e-09,  1.6901e-08,\n",
            "         1.0270e-08,  7.2120e-09,  3.1146e-09,  1.9268e-10, -2.7003e-08,\n",
            "        -4.1013e-09, -2.8240e-09, -5.4365e-09,  2.2833e-09, -3.1775e-09,\n",
            "        -2.1174e-09, -1.1691e-09, -1.3946e-08, -1.3060e-09,  2.8797e-09,\n",
            "        -6.0885e-09,  1.0945e-08,  1.0146e-08,  9.9916e-10, -5.1065e-09,\n",
            "        -3.6825e-09,  4.4779e-09, -5.0907e-09, -3.7931e-09,  4.7670e-09,\n",
            "         1.1634e-08, -4.7749e-09, -6.2906e-09,  2.2607e-15,  1.6239e-15,\n",
            "        -4.8858e-18,  3.5006e-16,  1.3393e-16, -2.0553e-16, -8.5203e-16,\n",
            "         2.2266e-15, -9.5689e-16, -1.1624e-15,  1.0558e-15,  4.1467e-15,\n",
            "         1.1753e-15, -9.0239e-16, -1.8357e-16, -6.8970e-16, -1.7397e-16,\n",
            "         1.9851e-15, -8.7223e-16, -5.7766e-17,  1.3205e-17,  1.1390e-15,\n",
            "         6.2458e-16, -5.2019e-16, -5.7040e-17,  3.0651e-15,  1.3188e-15,\n",
            "        -1.9366e-16, -9.7524e-16,  1.3254e-15,  2.3510e-15, -9.3902e-16,\n",
            "        -7.8622e-16,  1.5138e-15,  4.4714e-18, -9.7925e-16, -1.4434e-15,\n",
            "         1.2866e-15, -4.6703e-16,  2.3750e-15,  1.4135e-16, -3.4815e-16,\n",
            "         2.5588e-16, -1.6525e-15, -5.2678e-15, -1.9386e-15,  1.3619e-15,\n",
            "        -5.1489e-16,  1.8019e-16, -5.5317e-16,  4.5998e-16, -3.4237e-17,\n",
            "        -1.4960e-15, -1.5694e-15,  7.2747e-16,  1.4386e-15, -1.5393e-15,\n",
            "         2.6905e-15, -1.0591e-15,  1.7148e-15, -1.2990e-15,  3.6176e-16,\n",
            "         1.0556e-15, -2.1474e-15, -2.3089e-15, -5.6740e-15,  1.3827e-15,\n",
            "         1.6768e-15, -2.3454e-17, -9.8473e-16,  6.2212e-16, -2.6490e-15,\n",
            "        -3.7084e-15, -1.9252e-16, -2.9741e-16, -1.5140e-15,  1.1763e-16,\n",
            "         3.5954e-16,  1.0851e-15,  9.8868e-16,  7.4021e-16,  1.8975e-15,\n",
            "         2.9674e-16,  5.5965e-16, -1.9453e-15, -5.8471e-16,  9.8005e-16,\n",
            "         1.3656e-15, -7.5735e-16, -5.8696e-16, -1.4316e-15, -9.8631e-16,\n",
            "         4.4446e-16,  2.7440e-16,  1.0957e-15, -3.2013e-16, -5.1131e-16,\n",
            "        -6.4814e-16, -2.4179e-16, -2.3188e-15,  1.4406e-16,  1.5804e-15,\n",
            "         1.2454e-15,  8.3636e-16,  2.5586e-15, -6.0823e-16,  2.6166e-16,\n",
            "        -4.7566e-16,  1.5516e-15,  8.7425e-16,  1.1896e-15, -6.2406e-16,\n",
            "         5.9464e-16, -1.8574e-15, -1.2771e-15,  5.8119e-15, -8.5049e-16,\n",
            "         1.0610e-15, -6.9944e-16, -1.6205e-15, -3.3824e-15,  2.7537e-15,\n",
            "         1.5363e-15,  4.0347e-16, -1.7254e-16, -1.2603e-15, -2.3028e-15,\n",
            "        -1.4995e-15,  3.7529e-08, -4.7330e-09, -5.7058e-08, -1.4391e-08,\n",
            "         7.5144e-08, -6.8662e-08, -6.1452e-08, -5.8285e-08,  5.4767e-08,\n",
            "         1.9136e-08, -1.0410e-08,  5.0040e-08, -2.1611e-08, -5.5468e-08,\n",
            "         7.5761e-08,  4.6943e-08,  9.2519e-08,  4.0512e-09, -3.5415e-08,\n",
            "        -4.5602e-08, -5.2071e-08, -2.2267e-08, -7.2039e-08,  2.7904e-08,\n",
            "         4.5083e-08, -7.6138e-10, -1.7460e-08,  6.5171e-08, -4.7886e-08,\n",
            "         3.1018e-08, -3.2760e-08, -1.4813e-08,  2.2883e-08,  4.5926e-08,\n",
            "         5.7932e-08,  2.3450e-08,  3.9780e-08, -1.1375e-08,  1.1350e-08,\n",
            "        -6.0894e-09, -1.6473e-08, -4.0444e-09,  2.7990e-08,  4.5299e-09,\n",
            "         6.0547e-08, -8.9954e-09, -7.3142e-09,  6.9498e-09, -1.9074e-09,\n",
            "        -1.1385e-08, -4.1066e-08,  3.4729e-08, -1.9350e-08, -4.6431e-08,\n",
            "         1.8844e-08,  4.6693e-08,  5.7334e-08,  4.7989e-08, -4.2868e-08,\n",
            "        -1.3092e-08, -8.8644e-09,  2.8713e-08,  7.1672e-08, -2.4725e-08,\n",
            "         1.3616e-09,  4.0341e-08, -5.4935e-08,  2.8557e-08, -9.8255e-08,\n",
            "         3.4943e-08, -3.2492e-09,  6.6295e-08, -7.2854e-09,  7.9006e-09,\n",
            "         3.7623e-08,  4.2041e-08, -2.7865e-08,  2.8969e-08, -5.3995e-08,\n",
            "        -4.1489e-08, -4.4916e-08, -4.9996e-08, -2.6544e-08, -2.6093e-08,\n",
            "         6.4388e-08,  2.7883e-09, -8.9404e-09,  1.4183e-08,  1.8241e-08,\n",
            "         4.1962e-08, -1.0922e-07,  3.3596e-08,  3.2983e-08,  8.1507e-09,\n",
            "         5.2958e-09,  1.6785e-08, -4.6730e-08,  5.5889e-09, -4.0838e-08,\n",
            "         5.3818e-09, -5.8920e-08,  1.8150e-08,  5.2070e-08,  4.5783e-08,\n",
            "         2.0400e-08, -6.7314e-08, -1.4201e-08,  2.3221e-08, -7.0782e-08,\n",
            "        -1.6919e-08, -4.8950e-08, -4.1074e-08,  6.8086e-09, -4.5467e-08,\n",
            "         5.0559e-08, -6.5988e-08, -9.8712e-09,  1.8837e-08,  8.6953e-09,\n",
            "         3.1669e-08,  2.6542e-08,  1.1321e-08,  5.9056e-08, -3.4195e-08,\n",
            "         3.0364e-08,  5.5847e-08, -6.0556e-08,  6.5365e-08])\n",
            "token_encoder.transformer_encoder.layers.3.self_attn.out_proj.weight tensor([[-0.0486, -0.0551, -0.0124,  ..., -0.0738, -0.0202, -0.0112],\n",
            "        [ 0.0414, -0.0782,  0.0360,  ..., -0.0850,  0.0135, -0.0172],\n",
            "        [ 0.0421,  0.0650, -0.0834,  ...,  0.0044, -0.0079,  0.0845],\n",
            "        ...,\n",
            "        [ 0.0634,  0.0509,  0.0373,  ...,  0.0335, -0.0538,  0.0432],\n",
            "        [-0.0754,  0.0440,  0.0274,  ..., -0.0472, -0.0735, -0.0036],\n",
            "        [-0.0016,  0.0141,  0.0085,  ...,  0.0873,  0.0173, -0.0135]])\n",
            "token_encoder.transformer_encoder.layers.3.self_attn.out_proj.bias tensor([-6.1821e-08,  5.9404e-09,  3.8425e-08, -4.8420e-08,  2.3139e-08,\n",
            "        -4.5226e-09,  2.6795e-08, -1.3009e-07, -3.6743e-08, -1.2939e-08,\n",
            "        -3.8065e-08,  4.2518e-08, -1.9029e-08, -9.1946e-08,  8.9537e-08,\n",
            "        -7.9678e-08,  3.1138e-08,  7.8396e-09, -8.9289e-09,  1.0397e-08,\n",
            "         3.3866e-08,  2.5665e-08, -3.8523e-08,  4.5885e-08,  4.1811e-08,\n",
            "         1.4340e-08,  4.2587e-08, -9.3131e-10,  1.1417e-07,  7.5369e-08,\n",
            "        -8.0223e-09,  7.3250e-09,  1.8307e-08,  1.3434e-07, -3.5730e-08,\n",
            "         7.3216e-09,  1.0384e-07, -1.1911e-07, -1.0179e-09, -1.1422e-07,\n",
            "        -1.0103e-07,  1.2092e-07,  4.3216e-08,  5.2872e-08,  7.9436e-08,\n",
            "        -5.0214e-08, -3.6154e-08,  8.4387e-08,  1.2067e-08, -1.1476e-07,\n",
            "         2.7523e-08,  2.0260e-07, -3.7085e-09,  9.9755e-08, -7.4806e-08,\n",
            "         2.2250e-08,  6.3307e-08, -6.5927e-09,  7.0094e-08,  4.7074e-08,\n",
            "        -6.1829e-08, -8.8176e-08,  5.1050e-08, -9.0667e-09,  2.9017e-08,\n",
            "        -1.8376e-08,  3.8620e-08, -8.0627e-10, -9.1381e-08, -4.8568e-08,\n",
            "        -4.2437e-08,  1.1036e-08,  1.6914e-08,  7.9061e-08,  4.3847e-08,\n",
            "        -4.1525e-08, -3.0775e-08, -5.9646e-08, -4.9530e-09, -1.4145e-08,\n",
            "         2.1937e-08, -9.1008e-08, -4.5481e-08,  1.2111e-08,  2.9301e-08,\n",
            "        -1.6313e-07, -8.6070e-08, -7.7287e-08,  8.5923e-08, -2.7733e-08,\n",
            "        -5.1067e-08, -9.6623e-08,  5.6187e-08, -2.4822e-08,  6.9764e-08,\n",
            "         8.8775e-09,  6.6439e-09, -6.4525e-08,  1.2789e-08,  1.1366e-07,\n",
            "        -3.6308e-08, -1.0921e-07,  2.5098e-08,  3.3747e-08,  3.2340e-08,\n",
            "        -5.3205e-08, -7.7608e-08,  1.7940e-08,  8.9142e-09,  5.2761e-08,\n",
            "        -7.7026e-08, -6.5346e-08, -2.9371e-08,  1.4151e-07, -3.3211e-08,\n",
            "        -6.1654e-08,  1.1284e-07,  3.5854e-08, -1.4347e-07,  6.4304e-08,\n",
            "         6.9599e-08, -5.9157e-08,  1.1407e-08,  6.9977e-08, -7.0836e-08,\n",
            "        -2.2868e-07, -4.0149e-08, -6.0179e-08])\n",
            "token_encoder.transformer_encoder.layers.3.linear1.weight tensor([[ 0.0571,  0.0584,  0.0481,  ...,  0.0554, -0.0860, -0.0332],\n",
            "        [ 0.0024, -0.0642,  0.0629,  ..., -0.0878, -0.0876, -0.0085],\n",
            "        [ 0.0873, -0.0248, -0.0677,  ...,  0.0376, -0.0556, -0.0844],\n",
            "        ...,\n",
            "        [ 0.0053,  0.0725,  0.0214,  ...,  0.0507,  0.0543, -0.0073],\n",
            "        [ 0.0036, -0.0372,  0.0872,  ..., -0.0674, -0.0342, -0.0129],\n",
            "        [ 0.0791, -0.0020,  0.0156,  ..., -0.0286,  0.0857, -0.0044]])\n",
            "token_encoder.transformer_encoder.layers.3.linear1.bias tensor([ 0.0805,  0.0645,  0.0708,  0.0106, -0.0359,  0.0673, -0.0490, -0.0237,\n",
            "         0.0195, -0.0361,  0.0791,  0.0427,  0.0223, -0.0784, -0.0120, -0.0044,\n",
            "        -0.0263, -0.0268,  0.0388, -0.0349, -0.0571, -0.0779,  0.0744, -0.0014,\n",
            "        -0.0707, -0.0298, -0.0130, -0.0322, -0.0586, -0.0128,  0.0657,  0.0798,\n",
            "         0.0039, -0.0071,  0.0859, -0.0371, -0.0599,  0.0559,  0.0637, -0.0581,\n",
            "        -0.0570, -0.0676,  0.0667, -0.0303,  0.0844, -0.0602, -0.0138,  0.0791,\n",
            "        -0.0372,  0.0405, -0.0669, -0.0245, -0.0285, -0.0024, -0.0158,  0.0672,\n",
            "         0.0211, -0.0673,  0.0302,  0.0424, -0.0319, -0.0602,  0.0422,  0.0574,\n",
            "        -0.0241, -0.0672,  0.0263,  0.0002,  0.0198,  0.0877,  0.0178, -0.0661,\n",
            "        -0.0291, -0.0710,  0.0253, -0.0713, -0.0027, -0.0464,  0.0098, -0.0452,\n",
            "        -0.0769, -0.0025, -0.0241, -0.0703, -0.0825, -0.0580, -0.0321,  0.0019,\n",
            "         0.0698, -0.0119, -0.0202,  0.0221, -0.0869,  0.0477,  0.0763, -0.0352,\n",
            "        -0.0746,  0.0082,  0.0038, -0.0631, -0.0570, -0.0359,  0.0495,  0.0734,\n",
            "        -0.0126,  0.0669, -0.0752,  0.0277,  0.0752,  0.0248, -0.0117, -0.0408,\n",
            "        -0.0865, -0.0594,  0.0469,  0.0095,  0.0657, -0.0172,  0.0030, -0.0626,\n",
            "        -0.0739, -0.0876,  0.0419,  0.0131, -0.0588, -0.0035,  0.0224, -0.0343])\n",
            "token_encoder.transformer_encoder.layers.3.linear2.weight tensor([[-0.0713,  0.0368, -0.0236,  ..., -0.0532, -0.0118,  0.0241],\n",
            "        [-0.0635, -0.0315,  0.0215,  ...,  0.0819, -0.0870, -0.0466],\n",
            "        [-0.0136,  0.0712, -0.0599,  ..., -0.0559,  0.0848,  0.0543],\n",
            "        ...,\n",
            "        [-0.0010,  0.0134, -0.0321,  ..., -0.0444, -0.0406, -0.0521],\n",
            "        [ 0.0315,  0.0460,  0.0526,  ...,  0.0047,  0.0208,  0.0053],\n",
            "        [-0.0515, -0.0722, -0.0596,  ..., -0.0849, -0.0783,  0.0570]])\n",
            "token_encoder.transformer_encoder.layers.3.linear2.bias tensor([-0.0820, -0.0015,  0.0034,  0.0136, -0.0244,  0.0604,  0.0073,  0.0686,\n",
            "         0.0831,  0.0744,  0.0771,  0.0610, -0.0682,  0.0684,  0.0080, -0.0440,\n",
            "        -0.0761, -0.0401, -0.0584,  0.0392, -0.0703, -0.0450, -0.0306, -0.0610,\n",
            "         0.0640, -0.0075, -0.0770,  0.0671, -0.0113, -0.0350, -0.0757, -0.0784,\n",
            "         0.0458,  0.0095,  0.0776, -0.0811, -0.0071,  0.0665,  0.0655, -0.0298,\n",
            "        -0.0187, -0.0357, -0.0604,  0.0664, -0.0678,  0.0085,  0.0139,  0.0693,\n",
            "         0.0421,  0.0077, -0.0842, -0.0052, -0.0207,  0.0685,  0.0018, -0.0827,\n",
            "        -0.0042,  0.0858, -0.0600,  0.0434,  0.0680,  0.0452,  0.0031,  0.0642,\n",
            "         0.0361,  0.0078, -0.0651,  0.0498, -0.0326, -0.0095, -0.0605, -0.0508,\n",
            "         0.0326, -0.0715,  0.0446,  0.0345, -0.0012, -0.0703, -0.0687, -0.0438,\n",
            "         0.0846,  0.0561, -0.0330, -0.0171,  0.0344, -0.0697, -0.0590,  0.0646,\n",
            "         0.0735,  0.0047, -0.0521,  0.0486, -0.0863,  0.0244, -0.0167,  0.0291,\n",
            "         0.0435, -0.0818, -0.0091,  0.0860, -0.0300, -0.0855, -0.0519, -0.0436,\n",
            "         0.0156,  0.0218,  0.0883, -0.0369,  0.0432,  0.0854, -0.0689, -0.0499,\n",
            "        -0.0711, -0.0312, -0.0014,  0.0186, -0.0610, -0.0336, -0.0861, -0.0834,\n",
            "        -0.0072,  0.0451, -0.0667,  0.0381, -0.0458, -0.0283,  0.0339, -0.0330])\n",
            "token_encoder.transformer_encoder.layers.3.norm1.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.3.norm1.bias tensor([-1.0528e-07,  5.9443e-08,  9.7930e-08, -8.2700e-08,  3.6396e-08,\n",
            "        -3.9908e-08,  6.2730e-08, -1.1611e-07,  2.1499e-08,  9.7158e-08,\n",
            "        -4.0306e-08,  5.8744e-08,  2.0341e-08, -6.2454e-08, -2.2213e-08,\n",
            "        -6.6970e-08,  3.4589e-08, -1.9197e-08, -8.4448e-09, -1.5785e-08,\n",
            "         1.0713e-08,  9.3639e-08, -6.5448e-08,  2.4492e-08,  4.9265e-08,\n",
            "         8.1287e-09, -1.8826e-08, -2.2060e-08,  1.8371e-07,  7.2882e-09,\n",
            "         4.0015e-08,  3.7754e-08, -2.1620e-08,  7.0565e-08,  6.6714e-09,\n",
            "         7.7459e-09, -2.1949e-10, -1.4774e-07, -2.9703e-08, -2.2386e-07,\n",
            "        -1.8190e-07,  1.0510e-07,  3.2007e-08,  3.3966e-08,  6.4260e-08,\n",
            "        -3.8496e-08, -2.0284e-08,  8.7990e-08,  1.1596e-08,  3.2110e-08,\n",
            "         1.4054e-09,  1.8518e-07,  7.7342e-08,  2.3588e-08, -7.5282e-08,\n",
            "        -5.1705e-08,  7.5968e-08, -3.7224e-10,  1.3970e-07,  1.7045e-08,\n",
            "        -5.4640e-08,  2.5892e-08, -1.2484e-08,  1.4843e-08,  6.1238e-08,\n",
            "        -5.5279e-08,  8.7589e-08, -9.1874e-09, -7.7983e-08, -1.8749e-08,\n",
            "        -3.9309e-08, -7.8091e-08, -2.1903e-08,  9.0322e-08,  2.8864e-08,\n",
            "         1.3527e-08,  4.4380e-09, -9.9583e-08, -8.8222e-09,  5.7123e-08,\n",
            "         8.7927e-09, -2.8094e-08, -3.1416e-08,  6.4610e-08,  2.2386e-08,\n",
            "        -6.4100e-08, -2.2150e-08,  2.5306e-08,  6.2842e-08, -1.4094e-08,\n",
            "        -8.1129e-08, -2.7351e-08, -2.4625e-08,  2.7843e-08,  1.2404e-08,\n",
            "         1.9687e-08,  1.1792e-07,  1.1997e-09, -2.9647e-08,  3.6350e-08,\n",
            "        -2.5361e-08, -1.3375e-07,  1.1393e-08,  6.0963e-08, -5.6105e-08,\n",
            "        -8.3844e-08, -5.1000e-08,  6.4531e-08, -4.9785e-08, -5.2234e-10,\n",
            "        -1.0400e-07, -3.2796e-08, -1.2122e-07,  1.2532e-07, -3.8883e-08,\n",
            "        -2.0665e-08,  1.4353e-07,  5.0907e-08, -1.2686e-07,  5.3324e-08,\n",
            "         9.1773e-08, -5.1572e-09,  2.9557e-08,  7.6121e-08, -9.8651e-08,\n",
            "         5.5638e-08, -3.4830e-08,  1.2159e-08])\n",
            "token_encoder.transformer_encoder.layers.3.norm2.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.3.norm2.bias tensor([-1.1785e-07,  3.7879e-08,  1.0592e-07, -5.3112e-08, -2.0421e-08,\n",
            "        -1.7170e-08, -6.5651e-09, -1.2517e-07,  3.5987e-08,  7.1044e-08,\n",
            "        -2.4497e-08,  5.0008e-08, -4.0558e-08, -6.4518e-08, -1.1110e-09,\n",
            "        -8.0565e-09,  3.3321e-08, -5.7340e-08,  5.1903e-09,  3.7511e-10,\n",
            "        -1.8739e-08,  9.3337e-08, -9.4440e-08,  1.0873e-08,  3.6076e-08,\n",
            "        -3.4298e-08, -4.1370e-08, -2.1881e-08,  1.6789e-07,  2.2293e-08,\n",
            "        -1.7104e-10,  7.5307e-08,  3.7981e-08,  5.8849e-08,  7.5722e-08,\n",
            "         2.8713e-09, -4.5797e-09, -9.4013e-08, -2.3333e-09, -1.9011e-07,\n",
            "        -1.8278e-07,  8.5023e-08,  4.9652e-08,  1.7444e-08,  5.5388e-08,\n",
            "         1.2013e-08,  2.7456e-08,  5.9894e-08,  7.6709e-09,  7.6928e-09,\n",
            "        -3.5443e-08,  1.5808e-07,  7.4156e-08,  2.8660e-08, -2.9896e-08,\n",
            "        -1.0230e-07,  4.8400e-08, -4.0719e-08,  1.0853e-07,  2.3225e-08,\n",
            "        -1.3315e-08,  4.3086e-08, -7.7277e-09,  6.0200e-08,  2.9688e-08,\n",
            "        -3.6954e-08,  4.8229e-08,  2.9589e-08, -6.2426e-08,  7.8629e-10,\n",
            "        -4.0958e-08, -2.0249e-08,  3.6582e-08,  3.9050e-08,  2.2062e-08,\n",
            "         2.0543e-09,  2.1250e-08, -1.0191e-07, -3.6886e-08,  4.6070e-08,\n",
            "         4.6780e-08, -5.4965e-08, -2.4898e-09,  4.5164e-08,  7.8624e-08,\n",
            "        -7.4132e-08, -2.6443e-08,  3.5927e-08,  6.1077e-08,  2.3825e-08,\n",
            "        -7.0334e-08, -3.3520e-08, -2.5999e-08,  1.5397e-08,  1.5829e-08,\n",
            "         2.5952e-08,  1.5591e-07,  1.9630e-08, -4.1441e-08, -2.3980e-09,\n",
            "        -6.5150e-08, -1.2321e-07,  1.9368e-08,  2.7466e-08, -4.3402e-08,\n",
            "        -6.9133e-08, -1.7881e-08,  4.1329e-08, -3.0338e-08,  6.7743e-09,\n",
            "        -1.2809e-07, -1.3460e-08, -1.0554e-07,  1.4934e-07, -2.8367e-08,\n",
            "        -5.6695e-08,  1.8553e-07,  1.7989e-08, -1.2122e-07,  8.0101e-08,\n",
            "         8.5245e-08,  2.5374e-08,  3.4291e-08,  3.6426e-08, -1.0084e-07,\n",
            "         7.7993e-08,  1.3649e-08,  3.8537e-08])\n",
            "token_encoder.transformer_encoder.layers.4.self_attn.in_proj_weight tensor([[-0.0206, -0.0443,  0.0245,  ...,  0.0695,  0.0129, -0.0172],\n",
            "        [-0.0673,  0.0118,  0.0623,  ..., -0.0257, -0.0630,  0.0006],\n",
            "        [-0.0822, -0.0750,  0.0442,  ...,  0.0833,  0.0506,  0.0207],\n",
            "        ...,\n",
            "        [-0.0057,  0.0468, -0.0918,  ...,  0.0195, -0.1040, -0.0061],\n",
            "        [ 0.0214,  0.0100, -0.0558,  ...,  0.0089, -0.0197, -0.0070],\n",
            "        [-0.0933,  0.0894,  0.0328,  ..., -0.0678,  0.0126, -0.1011]])\n",
            "token_encoder.transformer_encoder.layers.4.self_attn.in_proj_bias tensor([ 2.6520e-09,  1.4446e-08,  3.7528e-09,  1.1990e-09,  3.1743e-09,\n",
            "         2.6031e-09, -2.9002e-09,  5.3397e-09,  1.9974e-08, -7.6554e-09,\n",
            "        -8.6172e-09, -9.5149e-09, -6.7513e-09, -9.6933e-09,  4.4873e-09,\n",
            "         5.3919e-09, -6.6040e-09, -2.1665e-08, -4.8176e-09,  2.7346e-09,\n",
            "        -4.7869e-10,  1.3422e-08, -3.8014e-09, -9.1307e-09, -2.1113e-09,\n",
            "        -1.8865e-08, -1.3236e-08, -2.2706e-08,  9.5632e-09,  1.1290e-08,\n",
            "         9.0470e-09,  1.3023e-08,  1.0668e-08, -3.7783e-09,  2.5532e-08,\n",
            "         2.5025e-08, -7.9822e-09,  1.7872e-08, -2.4051e-08, -5.4571e-09,\n",
            "         1.2595e-08, -1.8348e-08, -1.6839e-08, -1.8534e-08, -2.4489e-09,\n",
            "        -1.3923e-08,  2.5470e-09,  1.0519e-08,  1.6820e-08,  5.4920e-09,\n",
            "        -1.1848e-09,  6.2411e-09, -5.7420e-09,  1.4367e-09,  1.7058e-08,\n",
            "         7.8694e-09,  3.6807e-09, -2.3302e-09,  1.1631e-08, -1.6982e-08,\n",
            "        -1.0414e-08,  4.0646e-09,  9.8019e-09,  1.3029e-09, -1.2834e-08,\n",
            "         9.0525e-09,  1.1103e-08,  4.3202e-09, -3.6195e-09,  1.8146e-09,\n",
            "         1.5338e-08, -2.3222e-09, -5.0769e-09, -5.6052e-10,  1.6504e-09,\n",
            "         2.7037e-09, -3.3637e-09,  1.9224e-08,  2.1538e-08,  3.2825e-09,\n",
            "        -7.0009e-10,  1.3310e-08, -1.0337e-08, -4.7930e-09,  1.0153e-08,\n",
            "         5.5394e-09,  3.4859e-09, -1.1201e-08,  1.7780e-09, -1.2513e-08,\n",
            "         2.2482e-09, -6.3486e-09,  4.5838e-09, -6.8368e-10, -7.7880e-09,\n",
            "         2.7706e-09, -2.6849e-09,  1.0681e-08, -6.8051e-10, -6.9969e-09,\n",
            "        -6.2024e-09,  3.6479e-09, -2.4046e-09, -7.3243e-09, -6.8334e-09,\n",
            "        -2.9245e-09, -1.9188e-09,  3.4865e-09,  6.8676e-09,  5.1378e-09,\n",
            "         2.2263e-09,  2.0605e-09, -7.2177e-09, -6.9707e-09,  7.0221e-09,\n",
            "        -3.6220e-09,  2.5528e-09, -1.3656e-09,  2.5259e-09, -1.3455e-08,\n",
            "         4.4686e-09, -4.2800e-09, -4.7108e-09, -9.8957e-10,  1.2388e-08,\n",
            "         1.6732e-09, -3.8524e-09,  6.3306e-10,  2.8103e-15, -2.2882e-15,\n",
            "         1.3063e-15,  4.6896e-15, -3.0310e-16,  7.3383e-16, -1.3406e-15,\n",
            "         1.1129e-15,  2.3752e-15, -5.6873e-16,  4.8521e-16,  1.3731e-15,\n",
            "         1.4646e-15, -2.8597e-16,  1.6379e-16, -2.4821e-16, -1.5297e-15,\n",
            "        -3.5153e-16, -1.2162e-15,  1.1448e-15,  1.5819e-16,  1.5041e-15,\n",
            "        -1.2980e-15, -6.5576e-16,  2.4390e-15, -1.2253e-15, -1.4458e-16,\n",
            "        -1.5646e-15,  3.3389e-15, -6.3250e-16, -5.5915e-16, -2.2551e-15,\n",
            "         7.5390e-16,  1.3085e-15,  2.1310e-16,  1.6650e-15,  2.9008e-17,\n",
            "         4.1022e-16, -8.9633e-16, -4.1357e-16,  1.2888e-15, -1.6702e-15,\n",
            "         2.4141e-16, -1.0591e-15, -7.3307e-16,  8.8650e-16,  9.7330e-16,\n",
            "         3.5769e-16,  1.0301e-15,  8.7297e-16,  1.4185e-16, -2.4790e-16,\n",
            "         3.3298e-15,  6.2332e-17,  3.9440e-16, -1.0876e-15, -9.0069e-16,\n",
            "         7.5695e-16, -1.4476e-16, -1.9554e-16, -6.2619e-16, -3.6400e-16,\n",
            "        -8.2244e-16,  8.2389e-16, -1.0017e-15,  4.3204e-15,  6.5146e-16,\n",
            "         4.1319e-16, -9.7736e-16,  9.3764e-16,  2.0768e-16,  2.6000e-15,\n",
            "         2.2159e-15, -1.9653e-15, -8.8795e-16,  2.8852e-16,  2.7199e-15,\n",
            "         2.6407e-15, -1.5018e-15,  4.7138e-16,  5.8027e-16,  1.6458e-15,\n",
            "        -1.6206e-15,  1.1561e-15,  6.3988e-16,  1.0404e-15,  6.1200e-16,\n",
            "        -3.3573e-16,  1.2547e-15,  7.4369e-16,  1.2431e-15,  1.0674e-15,\n",
            "        -1.0675e-15, -1.2319e-15,  8.3293e-16,  1.6663e-16,  1.8620e-16,\n",
            "        -3.9805e-15,  2.0908e-15,  2.0200e-15,  1.9185e-15,  1.6047e-15,\n",
            "         8.5021e-16,  4.2573e-16, -5.5693e-16,  6.4874e-16, -4.5807e-16,\n",
            "         1.5919e-15, -2.2267e-15, -1.2213e-15,  2.2860e-15, -2.0136e-15,\n",
            "         9.4655e-16, -5.9717e-17,  2.8307e-15, -4.0524e-15,  9.2101e-16,\n",
            "         3.3302e-16,  1.9103e-15, -9.8792e-16, -1.1368e-15, -2.3463e-16,\n",
            "         1.6276e-15, -1.4191e-15, -9.7357e-16,  1.3262e-15, -1.8304e-15,\n",
            "         4.1574e-16, -2.5456e-08,  4.4865e-08, -7.4392e-09, -1.7964e-08,\n",
            "        -1.7123e-08,  1.5179e-08,  7.5527e-09,  1.7895e-08, -2.1338e-08,\n",
            "        -3.8585e-08,  1.1334e-08, -2.6605e-08,  6.4632e-08, -2.1347e-08,\n",
            "         5.9040e-08, -5.0272e-10, -5.3817e-08,  5.8966e-09,  1.5800e-08,\n",
            "        -5.3817e-09, -2.5062e-08, -1.6229e-08, -1.2693e-08, -1.3507e-08,\n",
            "        -8.1384e-09, -3.3898e-08,  2.1226e-08, -4.2016e-08, -3.1419e-08,\n",
            "        -1.7235e-08,  1.6070e-08, -1.3510e-08, -7.5295e-08,  4.7307e-08,\n",
            "        -1.1553e-07,  2.1325e-08, -4.2721e-08, -2.5084e-08,  2.9212e-08,\n",
            "         6.3822e-08, -1.7296e-08,  8.0655e-08,  3.3929e-08, -6.2076e-08,\n",
            "        -8.0805e-08,  1.1033e-08, -8.7693e-08, -9.2277e-08, -2.6046e-08,\n",
            "        -4.2531e-08, -4.4384e-08,  3.5386e-08, -6.0014e-08, -4.2870e-08,\n",
            "         1.5748e-08,  8.8592e-09,  1.5337e-08, -4.6412e-08,  1.7019e-08,\n",
            "         3.9256e-08,  1.9410e-08,  7.6296e-08,  6.3956e-08,  3.2428e-08,\n",
            "         1.1749e-08,  1.9589e-08,  9.4518e-08,  1.7849e-09, -1.2475e-08,\n",
            "         2.9340e-08, -4.3502e-08, -2.7157e-08, -5.4881e-08,  2.2870e-08,\n",
            "         7.4104e-08, -5.0047e-08, -2.1402e-08,  1.5227e-08,  1.3305e-08,\n",
            "        -1.8468e-08, -3.4604e-08,  5.3245e-09,  2.4810e-08, -6.4131e-08,\n",
            "         2.6536e-08, -6.8349e-08, -1.9771e-08,  3.4191e-08, -4.6311e-08,\n",
            "         7.9641e-08, -4.9151e-08, -6.3292e-08,  2.2731e-08,  2.8870e-08,\n",
            "         2.3084e-08,  8.7580e-09,  5.4772e-09,  3.5854e-09, -1.1203e-07,\n",
            "        -2.6617e-08, -1.2022e-07, -5.7783e-08,  2.6168e-08, -3.5282e-08,\n",
            "         2.4444e-08, -4.6102e-09, -1.2202e-08,  4.9448e-08, -1.7915e-08,\n",
            "        -7.8097e-08, -7.9367e-08,  2.7262e-08,  1.0442e-08,  4.0642e-08,\n",
            "        -1.4496e-08,  1.9112e-08, -1.1234e-08,  9.4799e-09, -1.8478e-08,\n",
            "         6.4485e-08,  3.2077e-08,  2.9518e-08,  7.5779e-08, -1.5432e-07,\n",
            "        -7.2097e-08, -1.0682e-07, -5.0882e-08,  1.4977e-07])\n",
            "token_encoder.transformer_encoder.layers.4.self_attn.out_proj.weight tensor([[-0.0486, -0.0551, -0.0124,  ..., -0.0738, -0.0202, -0.0112],\n",
            "        [ 0.0414, -0.0782,  0.0360,  ..., -0.0850,  0.0135, -0.0172],\n",
            "        [ 0.0421,  0.0650, -0.0834,  ...,  0.0044, -0.0079,  0.0845],\n",
            "        ...,\n",
            "        [ 0.0634,  0.0509,  0.0373,  ...,  0.0335, -0.0538,  0.0432],\n",
            "        [-0.0754,  0.0440,  0.0274,  ..., -0.0472, -0.0735, -0.0036],\n",
            "        [-0.0016,  0.0141,  0.0085,  ...,  0.0873,  0.0173, -0.0135]])\n",
            "token_encoder.transformer_encoder.layers.4.self_attn.out_proj.bias tensor([-7.3455e-08,  6.5910e-10,  5.7331e-08, -8.6804e-08, -2.0232e-08,\n",
            "        -3.4009e-08,  7.7127e-08, -1.6985e-07,  5.1604e-08,  2.1791e-08,\n",
            "        -6.8223e-08,  1.3735e-08,  6.2648e-08, -2.8231e-08, -1.4731e-08,\n",
            "         7.1056e-09, -1.3194e-08, -4.6072e-08, -3.2436e-08, -5.8175e-08,\n",
            "        -3.7223e-08,  4.9439e-08, -1.2770e-07,  7.5093e-08,  4.9345e-08,\n",
            "        -2.9145e-08, -2.6821e-08, -3.5909e-08,  1.4906e-07, -7.0127e-08,\n",
            "        -2.5351e-10,  8.4944e-09,  1.7413e-09,  7.1528e-08,  3.8354e-08,\n",
            "         1.4986e-09, -1.4408e-08, -7.4210e-08,  2.6431e-08, -1.9909e-08,\n",
            "        -2.1054e-07,  5.5478e-08, -7.4802e-08,  1.9150e-08,  4.8117e-08,\n",
            "        -3.9023e-09,  1.1187e-07,  1.4099e-08,  2.1654e-07, -5.0242e-08,\n",
            "        -7.5590e-09,  4.9021e-08,  2.0674e-08, -9.0032e-08, -9.9169e-08,\n",
            "         6.5678e-09,  9.2419e-08,  4.6611e-08,  1.1517e-07, -5.1071e-08,\n",
            "        -7.9327e-09,  6.1242e-08,  4.1684e-08, -6.8014e-08,  5.7651e-08,\n",
            "        -9.3441e-08, -2.3512e-08,  3.1970e-08, -1.8303e-07, -3.2965e-09,\n",
            "        -4.9199e-08, -9.9983e-08,  3.1323e-09,  4.1829e-08,  1.2870e-08,\n",
            "        -1.3021e-07,  5.7146e-09, -4.6046e-08,  3.9967e-08,  1.4700e-08,\n",
            "        -1.7621e-08, -1.6426e-08,  6.4245e-08, -2.1086e-08,  1.9632e-08,\n",
            "        -2.0663e-07, -5.1804e-08,  5.7407e-08,  4.1511e-08, -1.1467e-08,\n",
            "        -1.0939e-08, -9.2477e-08, -1.2720e-07, -3.5864e-08,  3.7217e-08,\n",
            "        -2.0607e-08, -2.0391e-08, -1.4294e-08, -1.3320e-07, -5.7738e-08,\n",
            "        -3.2360e-08, -6.9241e-08,  6.2151e-08,  9.1030e-08,  4.8609e-08,\n",
            "         2.8788e-09, -2.5268e-08, -1.2124e-09, -7.5005e-08,  4.1061e-08,\n",
            "        -1.3497e-07, -3.5352e-08, -5.5651e-09,  6.4353e-08,  5.2424e-08,\n",
            "        -7.3518e-08,  5.9759e-08,  5.8932e-08, -2.6214e-08,  3.9160e-08,\n",
            "         5.3807e-08, -4.9809e-09,  9.1410e-08,  5.7209e-08, -5.5984e-08,\n",
            "         1.7961e-07,  9.3372e-09,  4.5508e-08])\n",
            "token_encoder.transformer_encoder.layers.4.linear1.weight tensor([[ 0.0571,  0.0584,  0.0481,  ...,  0.0554, -0.0860, -0.0332],\n",
            "        [ 0.0024, -0.0642,  0.0629,  ..., -0.0878, -0.0876, -0.0085],\n",
            "        [ 0.0873, -0.0248, -0.0677,  ...,  0.0376, -0.0556, -0.0844],\n",
            "        ...,\n",
            "        [ 0.0053,  0.0725,  0.0214,  ...,  0.0507,  0.0543, -0.0073],\n",
            "        [ 0.0036, -0.0372,  0.0872,  ..., -0.0674, -0.0342, -0.0129],\n",
            "        [ 0.0791, -0.0020,  0.0156,  ..., -0.0286,  0.0857, -0.0044]])\n",
            "token_encoder.transformer_encoder.layers.4.linear1.bias tensor([ 0.0805,  0.0645,  0.0708,  0.0106, -0.0359,  0.0673, -0.0490, -0.0237,\n",
            "         0.0195, -0.0361,  0.0791,  0.0427,  0.0223, -0.0784, -0.0120, -0.0044,\n",
            "        -0.0263, -0.0268,  0.0388, -0.0349, -0.0571, -0.0779,  0.0744, -0.0014,\n",
            "        -0.0707, -0.0298, -0.0130, -0.0322, -0.0586, -0.0128,  0.0657,  0.0798,\n",
            "         0.0039, -0.0071,  0.0859, -0.0371, -0.0599,  0.0559,  0.0637, -0.0581,\n",
            "        -0.0570, -0.0676,  0.0667, -0.0303,  0.0844, -0.0602, -0.0138,  0.0791,\n",
            "        -0.0372,  0.0405, -0.0669, -0.0245, -0.0285, -0.0024, -0.0158,  0.0672,\n",
            "         0.0211, -0.0673,  0.0302,  0.0424, -0.0319, -0.0602,  0.0422,  0.0574,\n",
            "        -0.0241, -0.0672,  0.0263,  0.0002,  0.0198,  0.0877,  0.0178, -0.0661,\n",
            "        -0.0291, -0.0710,  0.0253, -0.0713, -0.0027, -0.0464,  0.0098, -0.0452,\n",
            "        -0.0769, -0.0025, -0.0241, -0.0703, -0.0825, -0.0580, -0.0321,  0.0019,\n",
            "         0.0698, -0.0119, -0.0202,  0.0221, -0.0869,  0.0477,  0.0763, -0.0352,\n",
            "        -0.0746,  0.0082,  0.0038, -0.0631, -0.0570, -0.0359,  0.0495,  0.0734,\n",
            "        -0.0126,  0.0669, -0.0752,  0.0277,  0.0752,  0.0248, -0.0117, -0.0408,\n",
            "        -0.0865, -0.0594,  0.0469,  0.0095,  0.0657, -0.0172,  0.0030, -0.0626,\n",
            "        -0.0739, -0.0876,  0.0419,  0.0131, -0.0588, -0.0035,  0.0224, -0.0343])\n",
            "token_encoder.transformer_encoder.layers.4.linear2.weight tensor([[-0.0713,  0.0368, -0.0236,  ..., -0.0532, -0.0118,  0.0241],\n",
            "        [-0.0635, -0.0315,  0.0215,  ...,  0.0819, -0.0870, -0.0466],\n",
            "        [-0.0136,  0.0712, -0.0599,  ..., -0.0559,  0.0848,  0.0543],\n",
            "        ...,\n",
            "        [-0.0010,  0.0134, -0.0321,  ..., -0.0444, -0.0406, -0.0521],\n",
            "        [ 0.0315,  0.0460,  0.0526,  ...,  0.0047,  0.0208,  0.0053],\n",
            "        [-0.0515, -0.0722, -0.0596,  ..., -0.0849, -0.0783,  0.0570]])\n",
            "token_encoder.transformer_encoder.layers.4.linear2.bias tensor([-0.0820, -0.0015,  0.0034,  0.0136, -0.0244,  0.0604,  0.0073,  0.0686,\n",
            "         0.0831,  0.0744,  0.0771,  0.0610, -0.0682,  0.0684,  0.0080, -0.0440,\n",
            "        -0.0761, -0.0401, -0.0584,  0.0392, -0.0703, -0.0450, -0.0306, -0.0610,\n",
            "         0.0640, -0.0075, -0.0770,  0.0671, -0.0113, -0.0350, -0.0757, -0.0784,\n",
            "         0.0458,  0.0095,  0.0776, -0.0811, -0.0071,  0.0665,  0.0655, -0.0298,\n",
            "        -0.0187, -0.0357, -0.0604,  0.0664, -0.0678,  0.0085,  0.0139,  0.0693,\n",
            "         0.0421,  0.0077, -0.0842, -0.0052, -0.0207,  0.0685,  0.0018, -0.0827,\n",
            "        -0.0042,  0.0858, -0.0600,  0.0434,  0.0680,  0.0452,  0.0031,  0.0642,\n",
            "         0.0361,  0.0078, -0.0651,  0.0498, -0.0326, -0.0095, -0.0605, -0.0508,\n",
            "         0.0326, -0.0715,  0.0446,  0.0345, -0.0012, -0.0703, -0.0687, -0.0438,\n",
            "         0.0846,  0.0561, -0.0330, -0.0171,  0.0344, -0.0697, -0.0590,  0.0646,\n",
            "         0.0735,  0.0047, -0.0521,  0.0486, -0.0863,  0.0244, -0.0167,  0.0291,\n",
            "         0.0435, -0.0818, -0.0091,  0.0860, -0.0300, -0.0855, -0.0519, -0.0436,\n",
            "         0.0156,  0.0218,  0.0883, -0.0369,  0.0432,  0.0854, -0.0689, -0.0499,\n",
            "        -0.0711, -0.0312, -0.0014,  0.0186, -0.0610, -0.0336, -0.0861, -0.0834,\n",
            "        -0.0072,  0.0451, -0.0667,  0.0381, -0.0458, -0.0283,  0.0339, -0.0330])\n",
            "token_encoder.transformer_encoder.layers.4.norm1.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.4.norm1.bias tensor([-8.2497e-08, -1.0580e-08,  3.4228e-08, -9.3111e-08, -2.9712e-08,\n",
            "        -2.8095e-08,  1.0237e-08, -1.1502e-07,  7.0545e-08,  4.9282e-08,\n",
            "        -6.3514e-08,  3.2818e-08, -2.8547e-08, -2.9460e-08, -4.8092e-08,\n",
            "        -3.2728e-08,  3.1104e-09, -8.3920e-08, -3.2767e-08, -4.8916e-08,\n",
            "        -1.6698e-08,  6.3214e-08, -5.1032e-08,  2.7224e-08,  6.3502e-08,\n",
            "        -9.9195e-08, -2.6849e-08,  2.2598e-09,  1.5692e-07, -9.6719e-09,\n",
            "        -2.9744e-09,  2.3476e-08,  4.2034e-08,  5.9702e-08,  4.5414e-08,\n",
            "         7.4250e-09,  1.1275e-08, -8.0811e-08, -2.7943e-08, -1.3103e-07,\n",
            "        -1.0743e-07,  4.6655e-08, -9.5708e-10,  1.3401e-08,  2.0325e-08,\n",
            "         1.4033e-08,  1.7119e-08,  2.5719e-08,  2.5470e-08,  1.7256e-08,\n",
            "        -1.3907e-08,  8.4980e-08,  7.9751e-08,  1.7617e-08, -1.6932e-08,\n",
            "        -5.6996e-08,  4.1401e-08,  1.8869e-08,  9.9320e-08, -3.2169e-08,\n",
            "        -1.7703e-08,  1.8054e-09,  1.0109e-08,  3.8199e-08,  6.5585e-08,\n",
            "        -9.3175e-08,  3.5179e-09,  4.2075e-08, -1.6952e-08,  3.1360e-08,\n",
            "        -6.7609e-08, -5.0472e-08, -5.1759e-08,  3.4249e-08,  1.0245e-08,\n",
            "        -3.9070e-08,  1.8662e-08, -9.8388e-08, -2.3658e-08,  7.8720e-08,\n",
            "        -4.5090e-09, -3.0372e-08,  3.1409e-09,  6.4956e-08,  2.6795e-08,\n",
            "        -8.4955e-08, -8.8833e-09,  5.4779e-08,  5.3004e-08,  5.1642e-09,\n",
            "        -6.1972e-08, -6.5988e-08, -6.3603e-08,  2.5264e-08,  5.0512e-09,\n",
            "        -2.3478e-08,  1.2790e-07,  3.6491e-08, -1.5553e-08,  1.2518e-08,\n",
            "        -1.5071e-08, -5.5487e-08,  2.8482e-08,  9.8326e-08, -3.8547e-08,\n",
            "        -4.1787e-08, -3.1973e-08, -5.7866e-08, -5.0119e-09,  5.7957e-08,\n",
            "        -1.5013e-07, -4.7197e-08, -8.8998e-08,  8.9391e-08,  2.4912e-08,\n",
            "        -7.1952e-08,  1.0499e-07,  5.3956e-08, -8.2754e-08,  5.7517e-08,\n",
            "         7.4225e-08, -3.2154e-08,  3.6204e-08,  4.5396e-08, -8.7994e-08,\n",
            "         5.4110e-08,  2.1823e-08,  8.2899e-08])\n",
            "token_encoder.transformer_encoder.layers.4.norm2.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.4.norm2.bias tensor([-6.4705e-08, -1.6942e-08,  2.7356e-08, -7.1443e-08, -3.6665e-08,\n",
            "        -4.4941e-08, -8.4689e-09, -1.0086e-07,  4.1501e-08,  1.1035e-08,\n",
            "        -2.1889e-08,  3.2415e-08, -3.1698e-08, -2.3409e-08, -1.7869e-08,\n",
            "        -2.2005e-08,  6.4891e-09, -8.4863e-08, -3.1997e-08, -3.2876e-08,\n",
            "        -1.1097e-08,  7.5212e-08, -5.2303e-08, -3.1979e-08,  5.2871e-08,\n",
            "        -4.9066e-08, -4.6946e-09,  7.2715e-09,  1.2746e-07, -4.9672e-08,\n",
            "        -6.3099e-08,  3.4608e-08,  8.2284e-08,  4.2822e-09,  6.3311e-08,\n",
            "        -9.3892e-09,  1.0537e-08, -3.1450e-08, -3.6565e-08, -7.2262e-08,\n",
            "        -1.1587e-07,  4.5269e-08, -3.0176e-08,  4.6349e-08,  4.5590e-08,\n",
            "         1.8377e-08,  1.4193e-08,  4.5166e-08,  9.0380e-10,  2.7031e-08,\n",
            "        -6.4192e-09,  5.4178e-08,  4.3746e-08,  4.0319e-08, -3.3304e-08,\n",
            "        -5.3721e-08, -6.8455e-10, -2.2963e-08,  7.9422e-08, -4.0722e-08,\n",
            "         2.8796e-08, -2.8617e-08,  4.0873e-08,  2.1563e-08,  2.0903e-08,\n",
            "        -6.7315e-08, -2.8227e-09,  2.9822e-08, -5.1958e-08,  4.8060e-08,\n",
            "        -7.5390e-08, -7.5192e-09, -4.7733e-08,  3.2937e-08, -1.6504e-08,\n",
            "        -3.4546e-08,  1.0138e-08, -5.8614e-08, -1.4750e-08,  6.9536e-08,\n",
            "         2.3191e-08, -1.6942e-08, -3.7373e-08, -6.6139e-09,  6.4544e-08,\n",
            "        -8.3983e-08, -2.1255e-08,  7.4990e-08,  3.8237e-08,  3.1619e-08,\n",
            "        -7.0931e-08, -2.2997e-08, -6.0920e-08, -8.3344e-09,  2.5993e-08,\n",
            "         3.2024e-08,  1.4671e-07,  2.7262e-08, -2.6232e-08, -1.6737e-08,\n",
            "        -1.5051e-08, -7.3107e-08,  4.5858e-08,  7.2899e-08, -2.0464e-08,\n",
            "        -1.7533e-08, -4.8908e-08, -7.4284e-08,  1.2436e-08,  7.9077e-08,\n",
            "        -1.2760e-07, -1.7040e-08, -7.7243e-08,  4.9690e-08, -4.9590e-09,\n",
            "        -6.9735e-08,  1.1169e-07,  8.0722e-09, -6.4913e-08,  1.5201e-08,\n",
            "         7.1091e-08, -4.5169e-09,  4.3241e-08,  1.6414e-08, -8.6135e-08,\n",
            "         4.4802e-08,  1.7550e-08,  5.0989e-08])\n",
            "token_encoder.transformer_encoder.layers.5.self_attn.in_proj_weight tensor([[-0.0206, -0.0443,  0.0245,  ...,  0.0695,  0.0129, -0.0172],\n",
            "        [-0.0673,  0.0118,  0.0623,  ..., -0.0257, -0.0630,  0.0006],\n",
            "        [-0.0822, -0.0750,  0.0442,  ...,  0.0833,  0.0506,  0.0207],\n",
            "        ...,\n",
            "        [-0.0057,  0.0468, -0.0918,  ...,  0.0195, -0.1040, -0.0061],\n",
            "        [ 0.0214,  0.0100, -0.0558,  ...,  0.0089, -0.0197, -0.0070],\n",
            "        [-0.0933,  0.0894,  0.0328,  ..., -0.0678,  0.0126, -0.1011]])\n",
            "token_encoder.transformer_encoder.layers.5.self_attn.in_proj_bias tensor([ 6.2630e-09, -4.5516e-10,  1.0362e-08,  9.1543e-09, -8.1872e-09,\n",
            "         7.2652e-09,  1.2004e-08, -7.3925e-09, -3.8769e-09,  7.2214e-09,\n",
            "         2.1319e-08,  1.9468e-09, -2.2039e-09,  2.8491e-09,  4.2698e-09,\n",
            "         1.4021e-08,  1.1583e-08, -2.0885e-08,  6.7455e-09, -1.2010e-08,\n",
            "        -8.3349e-09,  2.8888e-08, -9.7410e-09, -1.1752e-09,  2.1369e-08,\n",
            "        -3.7118e-08, -6.4473e-09, -7.8776e-09, -3.1121e-09,  1.1721e-09,\n",
            "         4.8179e-09, -1.1061e-08,  6.7472e-09, -3.2964e-09,  4.7038e-09,\n",
            "         2.3565e-09,  3.9692e-10,  1.9888e-09, -9.5512e-09,  6.3519e-09,\n",
            "        -2.1390e-08, -6.1927e-09, -9.6984e-09, -1.3446e-08,  8.9288e-09,\n",
            "        -1.4531e-08,  1.2279e-08,  1.1596e-08,  4.1583e-09,  1.1761e-08,\n",
            "         6.6980e-09,  1.6198e-09, -7.6659e-09,  6.9491e-09,  7.8901e-09,\n",
            "         2.5674e-10,  1.8399e-09, -1.1222e-08, -5.2254e-10, -3.7351e-09,\n",
            "         4.8241e-09,  1.1039e-08,  1.1961e-10, -6.2363e-09, -1.4876e-08,\n",
            "         1.0940e-08, -9.6026e-09,  6.1052e-10,  1.1842e-08,  4.4838e-09,\n",
            "         3.4305e-09,  6.6262e-09, -2.2580e-08, -4.9182e-09,  9.6456e-09,\n",
            "        -3.9517e-09, -1.3137e-08, -3.1681e-09, -9.9230e-09, -1.2775e-08,\n",
            "         5.3095e-09,  1.2730e-08, -4.7183e-09, -1.9610e-08,  2.1166e-08,\n",
            "        -8.2176e-09,  7.2223e-09, -2.0778e-08, -1.0698e-08,  7.1127e-09,\n",
            "        -6.0033e-09, -9.2845e-09,  2.5766e-09, -4.7457e-09, -6.7293e-09,\n",
            "         2.3712e-08, -2.3756e-09, -1.1289e-08,  1.2889e-08,  5.4144e-11,\n",
            "        -1.3662e-08, -7.4777e-09,  2.3479e-09,  1.1687e-08, -1.7805e-09,\n",
            "         9.2075e-10, -2.0789e-09, -1.3547e-08, -6.6612e-09, -7.3285e-09,\n",
            "         1.4006e-10,  5.3371e-09, -1.2336e-08, -3.1755e-09, -4.2787e-09,\n",
            "        -4.5900e-10, -1.0176e-08,  5.4415e-09,  6.8129e-09,  4.5203e-09,\n",
            "        -8.2800e-09, -3.1336e-09,  6.9179e-09,  2.8825e-09,  1.7968e-09,\n",
            "         1.1156e-09, -3.0084e-10,  6.4534e-09, -1.7842e-15,  1.1352e-15,\n",
            "         9.9383e-16, -3.3455e-15, -4.5724e-16, -8.8313e-16, -2.2940e-15,\n",
            "        -9.4265e-16, -2.0151e-15,  1.5830e-16, -6.0278e-16, -5.5656e-16,\n",
            "        -2.2505e-15,  4.9898e-16,  1.7386e-15,  2.4424e-15,  2.0683e-15,\n",
            "         2.3559e-16,  3.0672e-15,  9.9660e-16, -9.6889e-16,  1.8541e-15,\n",
            "        -2.2280e-15, -1.8114e-15,  1.2768e-15,  6.7046e-16, -2.2928e-15,\n",
            "        -8.4462e-18,  2.5276e-15, -3.4509e-15, -8.1190e-16,  4.5375e-15,\n",
            "         2.0996e-15, -1.0783e-14,  1.2625e-15,  8.3561e-16,  7.2380e-16,\n",
            "        -1.3488e-17,  2.1549e-15,  7.9895e-16,  1.1847e-15, -8.0247e-17,\n",
            "        -2.5873e-15, -5.4187e-16, -3.1443e-15,  1.4729e-15, -2.0294e-15,\n",
            "        -3.2667e-15,  1.1065e-16, -2.3139e-15,  2.0375e-15, -4.3834e-16,\n",
            "         1.7183e-15,  4.6723e-16,  1.3314e-15,  3.6777e-16,  3.4883e-16,\n",
            "        -3.8182e-16,  1.2559e-15,  3.0272e-16, -1.3611e-15,  1.8417e-15,\n",
            "         7.6114e-16, -1.3942e-15, -1.4247e-15,  2.3047e-15,  7.6866e-16,\n",
            "        -6.2912e-16, -2.0364e-15,  1.5326e-15, -6.6013e-16, -1.9985e-15,\n",
            "         1.0417e-15, -6.5762e-15, -9.4349e-16, -7.2276e-16,  1.1793e-15,\n",
            "         2.9614e-15, -7.4021e-16,  2.0055e-15, -2.5474e-15,  3.4285e-15,\n",
            "        -3.4926e-15, -8.7861e-16,  3.1752e-15,  7.0152e-16,  7.6615e-16,\n",
            "        -2.6130e-15,  1.0923e-15, -9.9470e-16,  3.0962e-15,  1.0460e-15,\n",
            "         4.0386e-16,  2.1320e-15,  1.0522e-15, -3.8526e-16, -1.9006e-17,\n",
            "        -1.8368e-16,  3.1120e-15, -9.3151e-16, -1.1641e-15, -8.1738e-16,\n",
            "        -1.1742e-16, -1.1235e-15, -1.9693e-15,  2.5457e-15,  1.0666e-15,\n",
            "         1.0052e-15,  1.1003e-16, -1.4127e-15, -2.2840e-15, -1.3036e-16,\n",
            "         1.5279e-15, -6.1851e-16, -8.8821e-16,  9.6657e-16,  3.1521e-16,\n",
            "         4.1268e-16, -1.5844e-15,  3.1904e-16,  6.1213e-16, -8.1951e-16,\n",
            "        -1.0114e-15,  7.0086e-16, -2.1808e-15, -1.1186e-15, -1.2921e-16,\n",
            "         2.2740e-16, -4.9463e-08,  7.6306e-08, -1.3380e-08, -6.5502e-08,\n",
            "         5.9714e-08, -1.5291e-08, -5.1111e-08,  5.7849e-08, -3.7463e-08,\n",
            "         1.7542e-10,  5.4054e-08,  2.2298e-08,  1.5228e-08,  3.8002e-08,\n",
            "         7.0277e-08,  3.4587e-08,  3.1703e-08,  2.9774e-08,  5.3614e-08,\n",
            "         1.9482e-08, -2.0295e-08, -3.7679e-08, -4.5228e-08,  2.6472e-08,\n",
            "         4.6244e-08,  1.7805e-08,  7.6538e-08, -1.6770e-08, -1.5993e-08,\n",
            "         5.4930e-08,  5.2974e-09, -7.9025e-09,  4.9935e-08,  3.4296e-08,\n",
            "        -2.7211e-08, -2.1967e-08,  1.1753e-08, -6.6350e-08, -1.8131e-08,\n",
            "         6.7852e-08,  4.0243e-08, -4.2740e-09,  6.6770e-08,  6.2385e-08,\n",
            "         2.9660e-08, -1.6118e-08, -2.9262e-08,  4.1869e-08, -4.4400e-08,\n",
            "        -7.8381e-08,  1.1083e-08,  9.4641e-08,  1.0503e-09,  6.9624e-09,\n",
            "        -4.3095e-08,  1.4327e-08,  8.7345e-08, -2.7234e-08, -6.4505e-09,\n",
            "         5.6788e-08,  8.2767e-08, -7.2827e-09, -2.4736e-09, -7.6945e-08,\n",
            "         1.1993e-08,  6.7015e-08, -7.1918e-09,  1.2898e-08,  6.1771e-08,\n",
            "         1.3955e-08, -2.9735e-08,  5.9321e-08, -4.4609e-08,  2.5954e-08,\n",
            "         3.8326e-08, -4.9402e-08, -1.4196e-08, -2.2604e-09, -3.6164e-09,\n",
            "        -4.2357e-08, -2.5994e-08, -4.3283e-09, -1.7294e-08, -8.6982e-08,\n",
            "         3.4079e-08, -2.0747e-08, -4.3189e-08, -1.0088e-08, -6.1165e-09,\n",
            "         8.1068e-08, -9.7030e-08, -1.2321e-08, -4.0712e-10, -4.4740e-08,\n",
            "        -2.9623e-08,  1.7824e-08,  3.1275e-09,  1.2782e-08, -3.3243e-08,\n",
            "        -1.5334e-08, -3.6029e-08,  3.0623e-08,  1.5427e-08, -2.7129e-08,\n",
            "         5.2059e-08, -2.2362e-08,  5.2610e-08,  6.8935e-08, -3.6508e-08,\n",
            "        -5.8404e-08, -8.0045e-08,  4.3417e-08, -5.9246e-08,  3.3881e-08,\n",
            "         2.5863e-08,  1.5988e-08, -5.4615e-08,  3.4316e-08, -5.4468e-08,\n",
            "        -3.7204e-08,  5.7801e-08,  9.8432e-09,  2.0319e-08, -1.4154e-08,\n",
            "        -3.7675e-08,  4.2984e-08,  3.3557e-08,  7.4841e-08])\n",
            "token_encoder.transformer_encoder.layers.5.self_attn.out_proj.weight tensor([[-0.0486, -0.0551, -0.0124,  ..., -0.0738, -0.0202, -0.0112],\n",
            "        [ 0.0414, -0.0782,  0.0360,  ..., -0.0850,  0.0135, -0.0172],\n",
            "        [ 0.0421,  0.0650, -0.0834,  ...,  0.0044, -0.0079,  0.0845],\n",
            "        ...,\n",
            "        [ 0.0634,  0.0509,  0.0373,  ...,  0.0335, -0.0538,  0.0432],\n",
            "        [-0.0754,  0.0440,  0.0274,  ..., -0.0472, -0.0735, -0.0036],\n",
            "        [-0.0016,  0.0141,  0.0085,  ...,  0.0873,  0.0173, -0.0135]])\n",
            "token_encoder.transformer_encoder.layers.5.self_attn.out_proj.bias tensor([ 1.1459e-08, -2.8508e-08,  1.2628e-07, -2.5430e-08, -4.3476e-08,\n",
            "         1.0330e-08,  2.9134e-08, -7.2354e-08,  1.0412e-08,  3.4661e-08,\n",
            "        -1.4712e-07,  2.0660e-08,  3.2020e-08, -4.8442e-09,  1.9211e-08,\n",
            "        -5.4977e-08, -5.9568e-08,  4.8121e-08,  2.4052e-08, -8.3995e-09,\n",
            "        -3.0352e-08, -3.1595e-08,  4.3531e-08,  7.2865e-08,  1.5681e-08,\n",
            "        -1.8121e-07, -2.7541e-09, -2.3239e-08,  4.9676e-08, -3.1254e-08,\n",
            "         6.2358e-09,  7.3520e-08,  8.3024e-08,  5.4608e-08,  1.0377e-07,\n",
            "        -2.0241e-08, -1.8766e-08, -1.4656e-08,  1.4447e-08,  4.0362e-09,\n",
            "        -9.7305e-08,  4.2869e-08,  4.1238e-09,  2.0338e-09,  1.3285e-08,\n",
            "         2.9561e-08,  6.0921e-08,  1.2829e-08, -7.9772e-08, -1.4276e-08,\n",
            "         1.0173e-07, -3.1396e-08,  5.8864e-08,  1.1465e-07, -1.1031e-08,\n",
            "         2.1076e-07, -7.3341e-08,  5.0467e-09,  5.8655e-08, -5.8330e-08,\n",
            "        -1.3524e-08,  1.2121e-08,  3.9313e-09,  8.9764e-08,  7.9230e-08,\n",
            "         1.5440e-08, -1.8739e-08, -1.1550e-07, -7.5825e-09,  5.4819e-08,\n",
            "        -1.1057e-08, -3.4836e-08,  2.9224e-09, -1.0166e-08,  2.0419e-09,\n",
            "        -1.1142e-07,  8.7908e-09, -3.3860e-09, -1.7380e-08,  8.4580e-08,\n",
            "        -1.2620e-08,  2.3989e-08,  2.7048e-09,  5.0944e-08, -1.9173e-08,\n",
            "        -8.5891e-08,  5.1287e-08,  4.5829e-08,  4.6727e-08,  7.1646e-08,\n",
            "        -1.0513e-08, -1.9768e-08, -6.2928e-08,  7.5835e-08, -3.2540e-08,\n",
            "         1.5832e-08,  5.7856e-08,  3.1757e-08, -2.4055e-10,  1.8525e-07,\n",
            "         5.0801e-08, -1.6328e-08,  3.1181e-08,  8.7933e-08,  5.5414e-08,\n",
            "        -1.9741e-08, -2.8140e-08,  1.5344e-09, -1.8267e-07,  3.9605e-09,\n",
            "        -3.3911e-08,  1.0684e-07,  1.1174e-08,  2.9020e-08, -4.2338e-08,\n",
            "        -4.3316e-08, -4.7539e-08,  1.8978e-09, -4.6178e-08, -2.8674e-08,\n",
            "         3.9740e-08, -2.0292e-07, -1.8217e-08,  1.2705e-07, -8.5646e-08,\n",
            "         1.1949e-08,  3.5018e-09,  2.8947e-08])\n",
            "token_encoder.transformer_encoder.layers.5.linear1.weight tensor([[ 0.0571,  0.0584,  0.0481,  ...,  0.0554, -0.0860, -0.0332],\n",
            "        [ 0.0024, -0.0642,  0.0629,  ..., -0.0878, -0.0876, -0.0085],\n",
            "        [ 0.0873, -0.0248, -0.0677,  ...,  0.0376, -0.0556, -0.0844],\n",
            "        ...,\n",
            "        [ 0.0053,  0.0725,  0.0214,  ...,  0.0507,  0.0543, -0.0073],\n",
            "        [ 0.0036, -0.0372,  0.0872,  ..., -0.0674, -0.0342, -0.0129],\n",
            "        [ 0.0791, -0.0020,  0.0156,  ..., -0.0286,  0.0857, -0.0044]])\n",
            "token_encoder.transformer_encoder.layers.5.linear1.bias tensor([ 0.0805,  0.0645,  0.0708,  0.0106, -0.0359,  0.0673, -0.0490, -0.0237,\n",
            "         0.0195, -0.0361,  0.0791,  0.0427,  0.0223, -0.0784, -0.0120, -0.0044,\n",
            "        -0.0263, -0.0268,  0.0388, -0.0349, -0.0571, -0.0779,  0.0744, -0.0014,\n",
            "        -0.0707, -0.0298, -0.0130, -0.0322, -0.0586, -0.0128,  0.0657,  0.0798,\n",
            "         0.0039, -0.0071,  0.0859, -0.0371, -0.0599,  0.0559,  0.0637, -0.0581,\n",
            "        -0.0570, -0.0676,  0.0667, -0.0303,  0.0844, -0.0602, -0.0138,  0.0791,\n",
            "        -0.0372,  0.0405, -0.0669, -0.0245, -0.0285, -0.0024, -0.0158,  0.0672,\n",
            "         0.0211, -0.0673,  0.0302,  0.0424, -0.0319, -0.0602,  0.0422,  0.0574,\n",
            "        -0.0241, -0.0672,  0.0263,  0.0002,  0.0198,  0.0877,  0.0178, -0.0661,\n",
            "        -0.0291, -0.0710,  0.0253, -0.0713, -0.0027, -0.0464,  0.0098, -0.0452,\n",
            "        -0.0769, -0.0025, -0.0241, -0.0703, -0.0825, -0.0580, -0.0321,  0.0019,\n",
            "         0.0698, -0.0119, -0.0202,  0.0221, -0.0869,  0.0477,  0.0763, -0.0352,\n",
            "        -0.0746,  0.0082,  0.0038, -0.0631, -0.0570, -0.0359,  0.0495,  0.0734,\n",
            "        -0.0126,  0.0669, -0.0752,  0.0277,  0.0752,  0.0248, -0.0117, -0.0408,\n",
            "        -0.0865, -0.0594,  0.0469,  0.0095,  0.0657, -0.0172,  0.0030, -0.0626,\n",
            "        -0.0739, -0.0876,  0.0419,  0.0131, -0.0588, -0.0035,  0.0224, -0.0343])\n",
            "token_encoder.transformer_encoder.layers.5.linear2.weight tensor([[-0.0713,  0.0368, -0.0236,  ..., -0.0532, -0.0118,  0.0241],\n",
            "        [-0.0635, -0.0315,  0.0215,  ...,  0.0819, -0.0870, -0.0466],\n",
            "        [-0.0136,  0.0712, -0.0599,  ..., -0.0559,  0.0848,  0.0543],\n",
            "        ...,\n",
            "        [-0.0010,  0.0134, -0.0321,  ..., -0.0444, -0.0406, -0.0521],\n",
            "        [ 0.0315,  0.0460,  0.0526,  ...,  0.0047,  0.0208,  0.0053],\n",
            "        [-0.0515, -0.0722, -0.0596,  ..., -0.0849, -0.0783,  0.0570]])\n",
            "token_encoder.transformer_encoder.layers.5.linear2.bias tensor([-0.0820, -0.0015,  0.0034,  0.0136, -0.0244,  0.0604,  0.0073,  0.0686,\n",
            "         0.0831,  0.0744,  0.0771,  0.0610, -0.0682,  0.0684,  0.0080, -0.0440,\n",
            "        -0.0761, -0.0401, -0.0584,  0.0392, -0.0703, -0.0450, -0.0306, -0.0610,\n",
            "         0.0640, -0.0075, -0.0770,  0.0671, -0.0113, -0.0350, -0.0757, -0.0784,\n",
            "         0.0458,  0.0095,  0.0776, -0.0811, -0.0071,  0.0665,  0.0655, -0.0298,\n",
            "        -0.0187, -0.0357, -0.0604,  0.0664, -0.0678,  0.0085,  0.0139,  0.0693,\n",
            "         0.0421,  0.0077, -0.0842, -0.0052, -0.0207,  0.0685,  0.0018, -0.0827,\n",
            "        -0.0042,  0.0858, -0.0600,  0.0434,  0.0680,  0.0452,  0.0031,  0.0642,\n",
            "         0.0361,  0.0078, -0.0651,  0.0498, -0.0326, -0.0095, -0.0605, -0.0508,\n",
            "         0.0326, -0.0715,  0.0446,  0.0345, -0.0012, -0.0703, -0.0687, -0.0438,\n",
            "         0.0846,  0.0561, -0.0330, -0.0171,  0.0344, -0.0697, -0.0590,  0.0646,\n",
            "         0.0735,  0.0047, -0.0521,  0.0486, -0.0863,  0.0244, -0.0167,  0.0291,\n",
            "         0.0435, -0.0818, -0.0091,  0.0860, -0.0300, -0.0855, -0.0519, -0.0436,\n",
            "         0.0156,  0.0218,  0.0883, -0.0369,  0.0432,  0.0854, -0.0689, -0.0499,\n",
            "        -0.0711, -0.0312, -0.0014,  0.0186, -0.0610, -0.0336, -0.0861, -0.0834,\n",
            "        -0.0072,  0.0451, -0.0667,  0.0381, -0.0458, -0.0283,  0.0339, -0.0330])\n",
            "token_encoder.transformer_encoder.layers.5.norm1.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.5.norm1.bias tensor([-2.2288e-08, -7.0211e-08, -1.7101e-08, -7.4011e-08, -2.0448e-08,\n",
            "        -3.1819e-08, -1.2633e-08, -6.7879e-08, -5.7472e-09, -3.2634e-08,\n",
            "        -7.4167e-08,  3.7362e-08,  2.2573e-08, -2.9532e-08,  3.6242e-08,\n",
            "        -2.6649e-08, -9.6288e-09, -1.3633e-08, -2.8426e-08, -6.2678e-09,\n",
            "        -7.5633e-09,  4.5577e-08, -4.5142e-08, -4.6080e-09,  2.3558e-10,\n",
            "        -5.7118e-08,  7.9540e-08,  9.6998e-09,  6.8770e-08,  9.3939e-09,\n",
            "         1.2149e-08, -5.4242e-09,  8.3738e-08,  8.7944e-08,  6.8632e-08,\n",
            "        -7.8647e-08, -9.7453e-09,  3.2029e-09, -3.3120e-08, -6.2234e-08,\n",
            "        -7.8097e-08,  1.8321e-08, -4.9345e-08,  9.0434e-08,  1.9590e-08,\n",
            "         2.6336e-08,  3.8417e-08,  6.8468e-08,  4.1228e-08,  3.3977e-08,\n",
            "        -9.0632e-09,  1.7524e-08,  5.0220e-08,  6.6123e-08,  3.1753e-08,\n",
            "        -3.6164e-08, -3.9547e-08,  4.1315e-08,  6.7218e-08, -3.8268e-08,\n",
            "        -1.2696e-08, -2.2957e-08,  4.4298e-08,  4.5693e-08,  4.6169e-08,\n",
            "        -9.0187e-09, -9.2344e-09, -1.8838e-08,  3.3305e-08,  3.2490e-08,\n",
            "        -4.8144e-08, -4.6868e-08, -2.5557e-08,  4.1771e-08, -2.1202e-08,\n",
            "         1.6668e-09,  1.3003e-08, -2.3377e-08,  8.5176e-09,  1.2856e-07,\n",
            "         1.2454e-08,  3.9346e-08,  1.8458e-08,  3.5725e-08,  3.1404e-08,\n",
            "        -5.6000e-08, -2.7914e-08,  6.3043e-08,  7.1254e-08,  4.0037e-08,\n",
            "        -6.0534e-08, -6.3224e-08, -2.9241e-08,  2.3795e-08,  7.5262e-09,\n",
            "         2.0016e-08,  1.1739e-07,  2.7456e-08, -2.4181e-08,  7.9575e-08,\n",
            "         5.5895e-08, -5.7103e-08,  1.4527e-08,  5.7051e-08,  1.7945e-08,\n",
            "        -1.4069e-08,  8.2285e-10, -6.7447e-08,  4.3591e-11,  7.5804e-08,\n",
            "        -6.6043e-08,  1.0594e-08, -6.8265e-08,  3.1112e-08,  6.4288e-08,\n",
            "        -3.7731e-08,  1.5382e-08,  1.5437e-08, -2.9847e-08,  2.6007e-09,\n",
            "         1.1496e-09, -1.9119e-08,  6.4917e-08,  6.1017e-08, -8.7755e-08,\n",
            "         1.1835e-08,  3.6788e-08,  1.5276e-08])\n",
            "token_encoder.transformer_encoder.layers.5.norm2.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.5.norm2.bias tensor([-1.0463e-08, -8.6756e-10, -9.0519e-09,  2.7893e-09, -7.4140e-09,\n",
            "        -2.1965e-08, -1.9442e-08,  9.6218e-09, -6.7998e-09, -2.5353e-08,\n",
            "         1.5820e-08,  7.1941e-10,  9.0724e-09, -2.1230e-08,  1.0991e-08,\n",
            "         2.2000e-09,  1.8562e-08, -2.2232e-08,  1.0768e-09,  1.5607e-08,\n",
            "         8.0787e-09,  2.2499e-08, -1.7859e-08,  2.2777e-08, -8.6264e-09,\n",
            "         2.2034e-08, -1.5373e-08, -6.5467e-10, -6.7635e-09,  2.0007e-08,\n",
            "         9.2841e-09, -2.6858e-08, -5.3305e-09,  3.3209e-09,  1.4576e-08,\n",
            "         1.4603e-08, -2.2500e-08, -1.2254e-08, -1.1259e-08, -1.7462e-08,\n",
            "        -9.1028e-09,  9.1851e-10,  1.1787e-08, -6.6583e-09, -2.3170e-09,\n",
            "         3.6068e-09,  8.7710e-09,  6.6442e-09,  4.4155e-08, -1.8259e-08,\n",
            "        -2.4811e-08,  1.1527e-08,  2.4508e-08,  1.0117e-08, -1.4774e-08,\n",
            "         4.3205e-08, -3.5856e-09,  1.1059e-08,  5.3270e-09,  9.6729e-09,\n",
            "         2.3573e-09,  6.6948e-09,  4.6004e-09,  1.0356e-08,  1.2910e-08,\n",
            "         2.1730e-09, -1.5232e-09,  2.2709e-08,  1.5452e-08,  7.8553e-09,\n",
            "         5.0923e-09, -4.9467e-09, -1.3294e-08, -1.8365e-09,  2.5675e-09,\n",
            "         1.1631e-08,  5.3893e-09, -3.5493e-09, -1.6310e-08,  1.1838e-08,\n",
            "         2.1866e-09, -1.5215e-08,  3.9943e-09,  1.5980e-08, -6.8899e-09,\n",
            "        -1.8930e-08, -1.6760e-08,  9.5037e-11, -1.1711e-09, -2.1769e-10,\n",
            "        -2.4732e-08, -8.2134e-09, -1.6006e-08,  2.1688e-08, -5.0391e-09,\n",
            "         5.8437e-09,  2.6854e-08,  1.9184e-09,  1.3990e-08,  1.7040e-08,\n",
            "         1.0769e-09, -3.1119e-09, -1.9155e-08, -4.9340e-09, -2.8973e-08,\n",
            "         1.9482e-09, -2.4672e-09, -1.9878e-08, -3.7672e-08, -1.6318e-09,\n",
            "         4.6294e-09, -1.2626e-08, -6.8140e-10,  3.9361e-09, -1.6878e-08,\n",
            "         9.4775e-09,  9.1824e-09, -7.3832e-09,  4.3666e-09, -1.0303e-08,\n",
            "        -2.5804e-08,  3.3941e-08, -1.2437e-08, -1.3589e-08, -9.7734e-09,\n",
            "         2.7908e-08, -7.3216e-09,  1.2100e-08])\n",
            "cnn_encoder.encoder.0.weight tensor([[[[-0.0714,  0.1093,  0.0246, -0.0477, -0.0999],\n",
            "          [ 0.0593,  0.0211,  0.0326,  0.0246, -0.0084],\n",
            "          [-0.0040, -0.0449, -0.0305,  0.0343,  0.0291],\n",
            "          [ 0.0862, -0.0679,  0.0863, -0.1113, -0.0167],\n",
            "          [ 0.0931,  0.0477,  0.0013,  0.0791, -0.0363]],\n",
            "\n",
            "         [[ 0.0978,  0.0095, -0.0134,  0.1050,  0.0890],\n",
            "          [-0.0986, -0.0537, -0.0738,  0.0898, -0.0744],\n",
            "          [ 0.0232, -0.0067,  0.0164, -0.0325,  0.0627],\n",
            "          [-0.0665, -0.0687, -0.0581, -0.0033,  0.0454],\n",
            "          [ 0.0908, -0.1136, -0.0915, -0.0944, -0.0724]],\n",
            "\n",
            "         [[ 0.1150,  0.0366, -0.0823,  0.0526, -0.0198],\n",
            "          [-0.0277, -0.0258, -0.0738, -0.0831,  0.0992],\n",
            "          [ 0.0066,  0.0107, -0.0613, -0.0532, -0.0074],\n",
            "          [-0.0320,  0.0849, -0.1084,  0.0051,  0.0866],\n",
            "          [ 0.0507,  0.0030, -0.0424,  0.0922, -0.0199]]],\n",
            "\n",
            "\n",
            "        [[[-0.0083,  0.0596,  0.0792, -0.0985, -0.0741],\n",
            "          [-0.0740, -0.0077, -0.1082, -0.0701, -0.0682],\n",
            "          [-0.0804, -0.0535,  0.0488, -0.0413, -0.0129],\n",
            "          [-0.0989, -0.0480,  0.0064, -0.0850, -0.0278],\n",
            "          [-0.0992, -0.0219,  0.0767,  0.0535, -0.0935]],\n",
            "\n",
            "         [[-0.0945, -0.0040, -0.0431, -0.0512, -0.1086],\n",
            "          [-0.0862,  0.0538,  0.0800, -0.0633, -0.0738],\n",
            "          [-0.0053,  0.0974,  0.0055, -0.0110,  0.0809],\n",
            "          [-0.1150,  0.0664, -0.0269,  0.1123,  0.0633],\n",
            "          [-0.0016,  0.0567, -0.1116, -0.0885,  0.0770]],\n",
            "\n",
            "         [[ 0.0173,  0.0085, -0.1007,  0.0480, -0.0054],\n",
            "          [-0.0165,  0.0347,  0.0929, -0.0019,  0.0444],\n",
            "          [-0.0174,  0.0667, -0.0606,  0.0300,  0.0270],\n",
            "          [ 0.1119,  0.0260,  0.0183, -0.0907, -0.0497],\n",
            "          [-0.0545,  0.0101,  0.0767, -0.1079,  0.1136]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0823, -0.0915, -0.0291,  0.0237,  0.0178],\n",
            "          [-0.0204, -0.0140,  0.0514,  0.1085, -0.0397],\n",
            "          [ 0.1109, -0.0653,  0.0271, -0.0544, -0.0520],\n",
            "          [-0.0649,  0.0247,  0.0131,  0.0693,  0.0615],\n",
            "          [ 0.0190,  0.0656, -0.0131,  0.0523,  0.0193]],\n",
            "\n",
            "         [[-0.0378,  0.0769,  0.0848, -0.0061,  0.0301],\n",
            "          [-0.0747,  0.0396, -0.0290, -0.1123, -0.0994],\n",
            "          [ 0.0623,  0.0569, -0.0179,  0.1148,  0.0861],\n",
            "          [-0.0551, -0.0070, -0.0430,  0.0103, -0.0424],\n",
            "          [-0.0439,  0.0866, -0.0597, -0.0408,  0.0719]],\n",
            "\n",
            "         [[ 0.0592,  0.0293,  0.0877, -0.0925, -0.0641],\n",
            "          [ 0.0641,  0.0181,  0.0571,  0.0503, -0.0606],\n",
            "          [ 0.0164, -0.1145, -0.0049,  0.1118, -0.0050],\n",
            "          [-0.0878, -0.0150, -0.0820,  0.0777, -0.1115],\n",
            "          [ 0.0324,  0.0524,  0.1015,  0.0220,  0.0930]]],\n",
            "\n",
            "\n",
            "        [[[-0.0278, -0.0295,  0.0585,  0.0191, -0.0598],\n",
            "          [-0.0262, -0.1139,  0.0051, -0.0312, -0.0199],\n",
            "          [ 0.1148,  0.0388, -0.0356,  0.0705,  0.0307],\n",
            "          [ 0.0001,  0.0903,  0.0921,  0.0345,  0.0822],\n",
            "          [-0.0446,  0.0701,  0.0691,  0.0766,  0.0716]],\n",
            "\n",
            "         [[-0.0067, -0.0016, -0.0074, -0.0867,  0.0710],\n",
            "          [-0.0268, -0.0164, -0.1016, -0.0901, -0.0154],\n",
            "          [ 0.0971, -0.0076,  0.0660, -0.0787,  0.0447],\n",
            "          [ 0.0975, -0.0628,  0.0274, -0.1035, -0.0467],\n",
            "          [-0.0880, -0.0064, -0.0516,  0.0873, -0.0626]],\n",
            "\n",
            "         [[ 0.0187,  0.0105,  0.0059, -0.1026,  0.0148],\n",
            "          [ 0.0531,  0.0098,  0.1070,  0.0325, -0.1066],\n",
            "          [-0.0590,  0.0477, -0.0346, -0.0094,  0.0945],\n",
            "          [ 0.0689,  0.0882,  0.0060, -0.0272, -0.0067],\n",
            "          [ 0.0393, -0.0561, -0.0977,  0.0363, -0.1041]]],\n",
            "\n",
            "\n",
            "        [[[-0.0310,  0.0350, -0.0724, -0.0763,  0.0828],\n",
            "          [-0.0323,  0.0254,  0.0609,  0.0876, -0.0303],\n",
            "          [ 0.0936, -0.0258,  0.0582, -0.0724,  0.0727],\n",
            "          [-0.0572, -0.0085, -0.0931,  0.0562, -0.0504],\n",
            "          [-0.1061,  0.0487,  0.0084,  0.0330, -0.0490]],\n",
            "\n",
            "         [[-0.0957,  0.1111, -0.0578,  0.0693, -0.0867],\n",
            "          [ 0.0391,  0.0304,  0.0146,  0.0824, -0.0546],\n",
            "          [-0.0691, -0.0391, -0.1055, -0.0542,  0.0890],\n",
            "          [ 0.0254, -0.0854, -0.0487,  0.0524,  0.0910],\n",
            "          [ 0.0620, -0.0058, -0.0776, -0.1049, -0.0834]],\n",
            "\n",
            "         [[ 0.0852,  0.0551,  0.0815,  0.0687, -0.0054],\n",
            "          [-0.0851,  0.0570, -0.0042, -0.0199,  0.1075],\n",
            "          [-0.0518,  0.0928,  0.0917,  0.0747,  0.0358],\n",
            "          [ 0.0585, -0.0934, -0.0772,  0.0598, -0.0563],\n",
            "          [-0.0329, -0.0644, -0.0829, -0.0374, -0.0855]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0779,  0.0963, -0.1019,  0.0225, -0.0596],\n",
            "          [-0.0079,  0.0134, -0.0503,  0.0405,  0.0759],\n",
            "          [-0.1098, -0.0657,  0.0496,  0.0963, -0.1097],\n",
            "          [ 0.0141, -0.0039, -0.0049,  0.0621, -0.0415],\n",
            "          [ 0.0498, -0.0902, -0.1077,  0.0817, -0.0745]],\n",
            "\n",
            "         [[-0.0131, -0.0032,  0.0411,  0.0125,  0.0877],\n",
            "          [ 0.0732, -0.0323,  0.0863,  0.0943,  0.0734],\n",
            "          [-0.0324,  0.1048, -0.0929, -0.0289,  0.0373],\n",
            "          [ 0.0618, -0.0719,  0.0555, -0.0727, -0.0145],\n",
            "          [-0.0652,  0.0591,  0.0448,  0.0317,  0.0411]],\n",
            "\n",
            "         [[ 0.1143,  0.0708, -0.1113,  0.0410,  0.0766],\n",
            "          [ 0.0072, -0.0135, -0.1083,  0.0876, -0.0753],\n",
            "          [ 0.1154, -0.0536, -0.0500,  0.0613,  0.0711],\n",
            "          [-0.1095,  0.1038,  0.0753,  0.0627, -0.0368],\n",
            "          [ 0.0096, -0.1071, -0.1150,  0.0359,  0.0062]]]])\n",
            "cnn_encoder.encoder.0.bias tensor([-0.0627, -0.0175, -0.1017,  0.0172, -0.1033, -0.0321])\n",
            "cnn_encoder.encoder.3.weight tensor([[[[ 0.0238, -0.0209, -0.0378, -0.0073,  0.0214],\n",
            "          [ 0.0374,  0.0441, -0.0020, -0.0207, -0.0703],\n",
            "          [-0.0704,  0.0301,  0.0226,  0.0762, -0.0687],\n",
            "          [ 0.0699, -0.0443, -0.0711,  0.0354,  0.0364],\n",
            "          [ 0.0487, -0.0569,  0.0276, -0.0564,  0.0185]],\n",
            "\n",
            "         [[ 0.0681, -0.0575,  0.0149, -0.0614,  0.0576],\n",
            "          [-0.0418, -0.0100, -0.0661, -0.0313,  0.0683],\n",
            "          [ 0.0723, -0.0578, -0.0787, -0.0582, -0.0067],\n",
            "          [-0.0493,  0.0157, -0.0645,  0.0436,  0.0768],\n",
            "          [-0.0801, -0.0178, -0.0583,  0.0576, -0.0688]],\n",
            "\n",
            "         [[-0.0317, -0.0480,  0.0670, -0.0678, -0.0494],\n",
            "          [ 0.0669,  0.0649,  0.0774, -0.0715, -0.0273],\n",
            "          [-0.0046,  0.0305,  0.0591,  0.0466,  0.0046],\n",
            "          [ 0.0338, -0.0468,  0.0021, -0.0397,  0.0481],\n",
            "          [-0.0812,  0.0206, -0.0216, -0.0573, -0.0614]],\n",
            "\n",
            "         [[ 0.0815, -0.0293,  0.0443, -0.0680,  0.0352],\n",
            "          [ 0.0286,  0.0349, -0.0780,  0.0566,  0.0028],\n",
            "          [-0.0122,  0.0056, -0.0012, -0.0631,  0.0366],\n",
            "          [-0.0156, -0.0663,  0.0012,  0.0614,  0.0432],\n",
            "          [-0.0478, -0.0435,  0.0049,  0.0246,  0.0559]],\n",
            "\n",
            "         [[ 0.0127, -0.0592, -0.0775, -0.0553,  0.0697],\n",
            "          [ 0.0114, -0.0388, -0.0625,  0.0069, -0.0135],\n",
            "          [-0.0206, -0.0566, -0.0404, -0.0701,  0.0290],\n",
            "          [-0.0740, -0.0227, -0.0603,  0.0672,  0.0529],\n",
            "          [ 0.0577, -0.0138,  0.0605, -0.0436,  0.0202]],\n",
            "\n",
            "         [[ 0.0730,  0.0417, -0.0752,  0.0147, -0.0545],\n",
            "          [ 0.0554, -0.0666,  0.0118,  0.0705,  0.0548],\n",
            "          [-0.0379,  0.0685, -0.0344,  0.0167, -0.0599],\n",
            "          [-0.0357, -0.0641, -0.0783, -0.0029, -0.0540],\n",
            "          [-0.0613,  0.0472, -0.0384,  0.0213,  0.0135]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0255, -0.0581,  0.0637, -0.0393,  0.0024],\n",
            "          [ 0.0556, -0.0016, -0.0737, -0.0160,  0.0175],\n",
            "          [-0.0030, -0.0272, -0.0710,  0.0189, -0.0628],\n",
            "          [-0.0420,  0.0773, -0.0257, -0.0604,  0.0578],\n",
            "          [ 0.0194,  0.0667,  0.0535, -0.0758, -0.0583]],\n",
            "\n",
            "         [[-0.0197, -0.0499, -0.0130, -0.0797, -0.0434],\n",
            "          [-0.0348, -0.0046,  0.0735, -0.0353, -0.0332],\n",
            "          [ 0.0815, -0.0034, -0.0485, -0.0282,  0.0071],\n",
            "          [ 0.0109,  0.0520,  0.0276,  0.0494, -0.0617],\n",
            "          [-0.0411, -0.0347,  0.0598,  0.0454,  0.0247]],\n",
            "\n",
            "         [[-0.0256, -0.0754,  0.0047, -0.0161, -0.0553],\n",
            "          [ 0.0355, -0.0749,  0.0719,  0.0483,  0.0176],\n",
            "          [ 0.0198,  0.0492, -0.0482,  0.0211, -0.0200],\n",
            "          [ 0.0669, -0.0236, -0.0605, -0.0701, -0.0378],\n",
            "          [-0.0473, -0.0577,  0.0106,  0.0764, -0.0103]],\n",
            "\n",
            "         [[ 0.0025, -0.0709, -0.0049,  0.0558,  0.0507],\n",
            "          [-0.0159,  0.0320,  0.0269,  0.0462,  0.0203],\n",
            "          [-0.0458,  0.0772, -0.0177,  0.0109, -0.0337],\n",
            "          [ 0.0585, -0.0282,  0.0389,  0.0271,  0.0213],\n",
            "          [ 0.0695, -0.0145, -0.0242,  0.0275,  0.0375]],\n",
            "\n",
            "         [[-0.0435, -0.0635,  0.0791, -0.0336, -0.0297],\n",
            "          [-0.0529, -0.0720, -0.0211,  0.0012, -0.0344],\n",
            "          [-0.0718, -0.0295, -0.0573, -0.0632, -0.0741],\n",
            "          [ 0.0416,  0.0605, -0.0414, -0.0247, -0.0329],\n",
            "          [-0.0506,  0.0162,  0.0226,  0.0118, -0.0359]],\n",
            "\n",
            "         [[ 0.0341,  0.0188,  0.0016, -0.0224, -0.0290],\n",
            "          [ 0.0705,  0.0706,  0.0413,  0.0108,  0.0373],\n",
            "          [-0.0787, -0.0695, -0.0321,  0.0669, -0.0070],\n",
            "          [ 0.0454,  0.0710, -0.0222,  0.0757,  0.0645],\n",
            "          [-0.0391,  0.0511,  0.0062, -0.0529, -0.0737]]],\n",
            "\n",
            "\n",
            "        [[[-0.0749,  0.0220, -0.0539, -0.0336,  0.0137],\n",
            "          [-0.0364, -0.0195, -0.0449, -0.0194, -0.0248],\n",
            "          [-0.0472, -0.0047, -0.0050,  0.0328, -0.0492],\n",
            "          [-0.0543,  0.0599,  0.0456, -0.0163,  0.0206],\n",
            "          [-0.0068, -0.0681, -0.0032,  0.0440, -0.0570]],\n",
            "\n",
            "         [[-0.0415,  0.0517, -0.0675, -0.0202,  0.0496],\n",
            "          [ 0.0458,  0.0586, -0.0609,  0.0135,  0.0604],\n",
            "          [ 0.0091,  0.0416, -0.0393, -0.0109, -0.0185],\n",
            "          [ 0.0519, -0.0473, -0.0385,  0.0331, -0.0496],\n",
            "          [ 0.0747,  0.0223, -0.0483, -0.0660,  0.0748]],\n",
            "\n",
            "         [[ 0.0034,  0.0623,  0.0640,  0.0276,  0.0075],\n",
            "          [-0.0448, -0.0191,  0.0528, -0.0752,  0.0271],\n",
            "          [ 0.0351, -0.0295, -0.0467,  0.0764,  0.0309],\n",
            "          [-0.0462, -0.0390,  0.0478,  0.0407,  0.0332],\n",
            "          [-0.0724,  0.0419, -0.0391,  0.0085, -0.0473]],\n",
            "\n",
            "         [[ 0.0221, -0.0358, -0.0649,  0.0093,  0.0166],\n",
            "          [-0.0672,  0.0710, -0.0485, -0.0660, -0.0681],\n",
            "          [-0.0749, -0.0315, -0.0493, -0.0302, -0.0325],\n",
            "          [-0.0049,  0.0053,  0.0271,  0.0587, -0.0608],\n",
            "          [ 0.0143,  0.0798,  0.0571, -0.0183, -0.0257]],\n",
            "\n",
            "         [[-0.0063,  0.0384, -0.0690,  0.0361,  0.0716],\n",
            "          [-0.0524, -0.0267, -0.0441,  0.0642,  0.0131],\n",
            "          [ 0.0527, -0.0012, -0.0115,  0.0468,  0.0146],\n",
            "          [-0.0098,  0.0217,  0.0609,  0.0558,  0.0707],\n",
            "          [-0.0463, -0.0182, -0.0355, -0.0180, -0.0460]],\n",
            "\n",
            "         [[-0.0235,  0.0813,  0.0664, -0.0254, -0.0227],\n",
            "          [ 0.0109,  0.0733,  0.0403,  0.0691, -0.0270],\n",
            "          [-0.0542, -0.0666, -0.0708, -0.0635,  0.0665],\n",
            "          [-0.0681,  0.0059,  0.0583,  0.0096,  0.0650],\n",
            "          [ 0.0754, -0.0749, -0.0195, -0.0708, -0.0450]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0133, -0.0086, -0.0120,  0.0566, -0.0087],\n",
            "          [-0.0076,  0.0338,  0.0445,  0.0076, -0.0416],\n",
            "          [ 0.0454, -0.0770, -0.0237,  0.0655, -0.0296],\n",
            "          [-0.0320,  0.0561, -0.0713, -0.0545, -0.0495],\n",
            "          [ 0.0198,  0.0490, -0.0791,  0.0499,  0.0084]],\n",
            "\n",
            "         [[ 0.0219,  0.0667, -0.0373,  0.0217,  0.0776],\n",
            "          [-0.0256,  0.0075, -0.0338, -0.0164,  0.0649],\n",
            "          [-0.0588,  0.0805,  0.0575, -0.0689, -0.0641],\n",
            "          [-0.0305, -0.0264,  0.0117,  0.0305, -0.0123],\n",
            "          [ 0.0115, -0.0728,  0.0313,  0.0622,  0.0710]],\n",
            "\n",
            "         [[-0.0216, -0.0767,  0.0369,  0.0069,  0.0084],\n",
            "          [-0.0443,  0.0545, -0.0792,  0.0195, -0.0672],\n",
            "          [-0.0681, -0.0361, -0.0743, -0.0719,  0.0688],\n",
            "          [-0.0237, -0.0800, -0.0037,  0.0312, -0.0476],\n",
            "          [ 0.0395,  0.0396, -0.0358, -0.0111, -0.0016]],\n",
            "\n",
            "         [[-0.0145,  0.0471, -0.0545, -0.0035, -0.0688],\n",
            "          [-0.0044,  0.0635,  0.0585, -0.0551, -0.0812],\n",
            "          [-0.0340,  0.0475,  0.0168,  0.0275,  0.0056],\n",
            "          [-0.0325, -0.0462,  0.0535,  0.0088, -0.0776],\n",
            "          [-0.0350,  0.0353, -0.0555,  0.0375,  0.0285]],\n",
            "\n",
            "         [[ 0.0120,  0.0800, -0.0551, -0.0306,  0.0550],\n",
            "          [ 0.0418, -0.0272, -0.0589, -0.0576,  0.0679],\n",
            "          [-0.0368,  0.0759, -0.0346,  0.0449,  0.0764],\n",
            "          [ 0.0695,  0.0669,  0.0151, -0.0733,  0.0325],\n",
            "          [-0.0460, -0.0634,  0.0458, -0.0648,  0.0318]],\n",
            "\n",
            "         [[ 0.0292,  0.0792, -0.0802, -0.0200,  0.0457],\n",
            "          [-0.0169, -0.0806,  0.0082,  0.0611, -0.0074],\n",
            "          [ 0.0623, -0.0250, -0.0381, -0.0781,  0.0125],\n",
            "          [ 0.0391,  0.0260, -0.0404, -0.0177,  0.0528],\n",
            "          [-0.0615,  0.0026,  0.0296,  0.0032, -0.0493]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0271,  0.0238,  0.0179,  0.0741,  0.0268],\n",
            "          [ 0.0272,  0.0707,  0.0771,  0.0117, -0.0261],\n",
            "          [ 0.0201, -0.0330, -0.0135,  0.0441,  0.0339],\n",
            "          [ 0.0768, -0.0419,  0.0108,  0.0760, -0.0794],\n",
            "          [-0.0647, -0.0514, -0.0309, -0.0094, -0.0205]],\n",
            "\n",
            "         [[ 0.0345, -0.0379,  0.0055, -0.0101,  0.0040],\n",
            "          [-0.0341, -0.0713, -0.0585, -0.0478,  0.0216],\n",
            "          [-0.0058, -0.0464, -0.0308, -0.0516,  0.0595],\n",
            "          [-0.0592, -0.0430,  0.0043, -0.0141, -0.0748],\n",
            "          [-0.0688, -0.0016,  0.0147, -0.0662, -0.0779]],\n",
            "\n",
            "         [[-0.0433, -0.0814, -0.0155, -0.0430, -0.0410],\n",
            "          [ 0.0217, -0.0618, -0.0220,  0.0196,  0.0374],\n",
            "          [ 0.0815, -0.0563,  0.0202,  0.0749,  0.0791],\n",
            "          [-0.0599,  0.0329,  0.0257,  0.0352,  0.0550],\n",
            "          [-0.0395,  0.0268, -0.0358, -0.0772,  0.0003]],\n",
            "\n",
            "         [[ 0.0099, -0.0495,  0.0269,  0.0674,  0.0537],\n",
            "          [ 0.0239,  0.0179, -0.0059,  0.0242, -0.0689],\n",
            "          [-0.0123, -0.0247, -0.0517, -0.0808, -0.0327],\n",
            "          [-0.0224,  0.0742,  0.0313, -0.0132,  0.0509],\n",
            "          [ 0.0101, -0.0120,  0.0075, -0.0703,  0.0123]],\n",
            "\n",
            "         [[ 0.0028, -0.0746,  0.0703,  0.0598, -0.0448],\n",
            "          [ 0.0678,  0.0307, -0.0277,  0.0244, -0.0306],\n",
            "          [ 0.0625,  0.0337, -0.0526, -0.0253, -0.0210],\n",
            "          [-0.0668,  0.0593, -0.0680, -0.0269, -0.0635],\n",
            "          [ 0.0781,  0.0598, -0.0147, -0.0090,  0.0175]],\n",
            "\n",
            "         [[-0.0751, -0.0583, -0.0059,  0.0810, -0.0777],\n",
            "          [ 0.0074,  0.0699,  0.0097,  0.0047,  0.0150],\n",
            "          [-0.0740,  0.0376, -0.0733,  0.0394,  0.0104],\n",
            "          [-0.0086,  0.0792, -0.0682,  0.0497,  0.0427],\n",
            "          [-0.0610,  0.0033, -0.0093,  0.0448,  0.0598]]],\n",
            "\n",
            "\n",
            "        [[[-0.0143, -0.0220,  0.0631,  0.0289, -0.0182],\n",
            "          [ 0.0039, -0.0651,  0.0443,  0.0501, -0.0595],\n",
            "          [-0.0536,  0.0058,  0.0480, -0.0535, -0.0277],\n",
            "          [-0.0630, -0.0001,  0.0044, -0.0197, -0.0489],\n",
            "          [-0.0247,  0.0655,  0.0142,  0.0806, -0.0624]],\n",
            "\n",
            "         [[ 0.0233,  0.0674, -0.0541, -0.0635,  0.0179],\n",
            "          [-0.0279,  0.0187,  0.0301, -0.0416,  0.0599],\n",
            "          [-0.0571,  0.0744, -0.0427,  0.0125, -0.0280],\n",
            "          [-0.0463,  0.0313, -0.0665,  0.0688,  0.0517],\n",
            "          [ 0.0530, -0.0374, -0.0553, -0.0742, -0.0364]],\n",
            "\n",
            "         [[ 0.0076,  0.0176,  0.0202,  0.0321, -0.0525],\n",
            "          [-0.0790, -0.0434,  0.0462, -0.0145, -0.0588],\n",
            "          [ 0.0266,  0.0431,  0.0603, -0.0058,  0.0698],\n",
            "          [-0.0156, -0.0282,  0.0258, -0.0633,  0.0743],\n",
            "          [ 0.0012, -0.0402,  0.0514, -0.0023,  0.0244]],\n",
            "\n",
            "         [[-0.0558,  0.0073,  0.0436,  0.0081, -0.0263],\n",
            "          [-0.0641,  0.0152, -0.0368,  0.0361, -0.0704],\n",
            "          [ 0.0138,  0.0571, -0.0677, -0.0381, -0.0114],\n",
            "          [-0.0602, -0.0717,  0.0371,  0.0580,  0.0556],\n",
            "          [ 0.0813,  0.0423, -0.0138, -0.0204,  0.0344]],\n",
            "\n",
            "         [[ 0.0405,  0.0424, -0.0653,  0.0534, -0.0207],\n",
            "          [-0.0343, -0.0685, -0.0510, -0.0246, -0.0745],\n",
            "          [-0.0243, -0.0484,  0.0722,  0.0664, -0.0018],\n",
            "          [-0.0438,  0.0436,  0.0684,  0.0245, -0.0052],\n",
            "          [-0.0780, -0.0372,  0.0605,  0.0050, -0.0761]],\n",
            "\n",
            "         [[ 0.0417, -0.0230,  0.0297,  0.0495,  0.0520],\n",
            "          [-0.0014,  0.0784,  0.0073, -0.0807, -0.0105],\n",
            "          [-0.0565,  0.0585, -0.0430, -0.0195, -0.0233],\n",
            "          [ 0.0757,  0.0249,  0.0182, -0.0594,  0.0308],\n",
            "          [-0.0059,  0.0348,  0.0762, -0.0185,  0.0497]]]])\n",
            "cnn_encoder.encoder.3.bias tensor([-0.0188, -0.0619, -0.0704, -0.0805, -0.0108, -0.0681,  0.0026, -0.0587,\n",
            "        -0.0578,  0.0802, -0.0804, -0.0399,  0.0015, -0.0718,  0.0654, -0.0544])\n",
            "cnn_encoder.encoder.7.weight tensor([[ 4.0672e-02,  2.9101e-02,  2.0612e-03,  ..., -3.6387e-02,\n",
            "         -2.6224e-02,  4.4303e-02],\n",
            "        [-1.1747e-02, -2.9515e-02, -1.5581e-03,  ..., -2.0430e-02,\n",
            "         -3.8544e-02,  1.2936e-02],\n",
            "        [-1.0737e-03,  1.8477e-02, -3.8721e-02,  ..., -3.7003e-02,\n",
            "         -3.1447e-02, -1.2528e-02],\n",
            "        ...,\n",
            "        [ 4.8838e-02,  3.2272e-02,  1.9333e-02,  ..., -4.9468e-02,\n",
            "          1.6740e-02, -1.7280e-02],\n",
            "        [ 3.8176e-02,  1.4686e-02, -3.1565e-02,  ...,  3.5029e-02,\n",
            "          4.5449e-02, -5.9605e-07],\n",
            "        [ 1.3736e-02, -1.2789e-02,  2.7286e-02,  ...,  2.5895e-02,\n",
            "          4.2269e-02, -4.1720e-02]])\n",
            "cnn_encoder.encoder.7.bias tensor([-0.0312, -0.0161, -0.0163,  0.0363,  0.0216, -0.0244, -0.0158, -0.0197,\n",
            "         0.0493, -0.0093, -0.0236, -0.0226,  0.0423,  0.0032,  0.0244, -0.0107,\n",
            "        -0.0251, -0.0457, -0.0431,  0.0369,  0.0444, -0.0089,  0.0255,  0.0202,\n",
            "        -0.0328, -0.0342, -0.0087,  0.0271, -0.0007,  0.0095,  0.0057, -0.0412,\n",
            "        -0.0151,  0.0500, -0.0395,  0.0039, -0.0099, -0.0179,  0.0274,  0.0222,\n",
            "         0.0323, -0.0015,  0.0370, -0.0060, -0.0274, -0.0406,  0.0448,  0.0103,\n",
            "        -0.0397,  0.0436,  0.0442, -0.0199, -0.0370,  0.0169,  0.0261,  0.0187,\n",
            "        -0.0005, -0.0335, -0.0234, -0.0195, -0.0262,  0.0005,  0.0294,  0.0468,\n",
            "         0.0144,  0.0447, -0.0022, -0.0148, -0.0379,  0.0085,  0.0226, -0.0185,\n",
            "         0.0024, -0.0264,  0.0493,  0.0051, -0.0283,  0.0312,  0.0422,  0.0386,\n",
            "         0.0343, -0.0339, -0.0411,  0.0454, -0.0058,  0.0275,  0.0411,  0.0378,\n",
            "        -0.0357, -0.0497, -0.0453,  0.0145, -0.0351,  0.0410,  0.0117, -0.0424,\n",
            "         0.0394, -0.0104,  0.0007, -0.0275, -0.0458,  0.0306, -0.0021,  0.0088,\n",
            "        -0.0268,  0.0185,  0.0080, -0.0158,  0.0029, -0.0432, -0.0321, -0.0087,\n",
            "        -0.0244, -0.0046, -0.0244, -0.0207, -0.0047, -0.0006,  0.0363, -0.0313,\n",
            "         0.0198, -0.0419, -0.0354,  0.0488,  0.0130, -0.0465, -0.0213, -0.0411,\n",
            "        -0.0455,  0.0448, -0.0020, -0.0375, -0.0230, -0.0063,  0.0461,  0.0060,\n",
            "         0.0096,  0.0111, -0.0475,  0.0260, -0.0105,  0.0450, -0.0350,  0.0030,\n",
            "        -0.0141, -0.0188, -0.0165,  0.0002, -0.0489, -0.0315,  0.0064,  0.0094,\n",
            "        -0.0454,  0.0493, -0.0017, -0.0415,  0.0388,  0.0176,  0.0127, -0.0169,\n",
            "        -0.0076,  0.0015, -0.0440, -0.0351,  0.0044, -0.0260,  0.0236, -0.0051,\n",
            "        -0.0128, -0.0287, -0.0449,  0.0077, -0.0211,  0.0382,  0.0270, -0.0441,\n",
            "         0.0297,  0.0460,  0.0474,  0.0114, -0.0313, -0.0219,  0.0213, -0.0037,\n",
            "        -0.0325, -0.0213,  0.0124, -0.0165,  0.0190,  0.0345,  0.0402,  0.0362,\n",
            "        -0.0012, -0.0347, -0.0413,  0.0479, -0.0385,  0.0486, -0.0196,  0.0044,\n",
            "         0.0081,  0.0222, -0.0061, -0.0258,  0.0353,  0.0316, -0.0018, -0.0358,\n",
            "         0.0185, -0.0321, -0.0466, -0.0486, -0.0153, -0.0017,  0.0127,  0.0019,\n",
            "         0.0229,  0.0317, -0.0021, -0.0140, -0.0174,  0.0499,  0.0009, -0.0411,\n",
            "         0.0133, -0.0024, -0.0291,  0.0357,  0.0303,  0.0011,  0.0233,  0.0429,\n",
            "        -0.0299,  0.0233, -0.0325, -0.0207,  0.0042, -0.0140, -0.0277,  0.0181,\n",
            "        -0.0307, -0.0352,  0.0135,  0.0199, -0.0079, -0.0174,  0.0372,  0.0085,\n",
            "        -0.0006, -0.0491,  0.0226, -0.0311, -0.0155,  0.0322, -0.0111,  0.0132])\n",
            "cnn_encoder.encoder.9.weight tensor([[-0.0573, -0.0380, -0.0546,  ..., -0.0177,  0.0509,  0.0329],\n",
            "        [ 0.0454,  0.0293,  0.0010,  ...,  0.0220,  0.0275, -0.0303],\n",
            "        [-0.0304,  0.0603,  0.0005,  ...,  0.0066,  0.0363,  0.0291],\n",
            "        ...,\n",
            "        [ 0.0552,  0.0333, -0.0109,  ..., -0.0281, -0.0133, -0.0056],\n",
            "        [ 0.0043,  0.0094,  0.0345,  ..., -0.0292, -0.0495,  0.0599],\n",
            "        [ 0.0482, -0.0096, -0.0457,  ..., -0.0083, -0.0567, -0.0582]])\n",
            "cnn_encoder.encoder.9.bias tensor([ 0.0143,  0.0057,  0.0017, -0.0212,  0.0171, -0.0590, -0.0090,  0.0604,\n",
            "        -0.0017, -0.0226, -0.0332,  0.0330, -0.0323,  0.0411,  0.0034, -0.0155,\n",
            "         0.0398,  0.0619, -0.0505,  0.0107, -0.0433,  0.0104, -0.0139, -0.0305,\n",
            "        -0.0545,  0.0617, -0.0227, -0.0074, -0.0378,  0.0351,  0.0538,  0.0003,\n",
            "        -0.0273, -0.0560, -0.0181, -0.0262, -0.0028,  0.0498,  0.0318,  0.0174,\n",
            "         0.0517,  0.0317, -0.0284, -0.0386, -0.0126, -0.0181,  0.0109, -0.0083,\n",
            "         0.0499,  0.0262, -0.0213,  0.0566,  0.0399,  0.0032,  0.0347,  0.0575,\n",
            "         0.0370, -0.0368, -0.0214,  0.0234,  0.0307,  0.0189, -0.0180, -0.0225,\n",
            "         0.0308, -0.0083,  0.0224,  0.0071, -0.0118,  0.0123,  0.0386,  0.0336,\n",
            "        -0.0187, -0.0406, -0.0350, -0.0358,  0.0084,  0.0608, -0.0128, -0.0214,\n",
            "         0.0069,  0.0531,  0.0364,  0.0108, -0.0263,  0.0618, -0.0511, -0.0352,\n",
            "        -0.0584, -0.0044, -0.0134, -0.0355,  0.0020,  0.0262,  0.0013,  0.0419,\n",
            "         0.0451, -0.0596,  0.0490,  0.0417, -0.0241, -0.0276, -0.0370,  0.0590,\n",
            "        -0.0159, -0.0126, -0.0533,  0.0034, -0.0233, -0.0010, -0.0410, -0.0494,\n",
            "         0.0547, -0.0342,  0.0497, -0.0564, -0.0423, -0.0364,  0.0075, -0.0555,\n",
            "        -0.0201, -0.0434, -0.0084, -0.0454, -0.0439,  0.0493, -0.0573,  0.0519])\n",
            "concat.weight tensor([[-0.0203, -0.0209,  0.0588,  ..., -0.0219, -0.0277, -0.0340],\n",
            "        [-0.0395, -0.0017,  0.0329,  ..., -0.0559, -0.0132, -0.0328],\n",
            "        [ 0.0350,  0.0237,  0.0312,  ..., -0.0319, -0.0078,  0.0103],\n",
            "        ...,\n",
            "        [-0.0538,  0.0025,  0.0012,  ..., -0.0579, -0.0509,  0.0036],\n",
            "        [-0.0239,  0.0621, -0.0240,  ...,  0.0024, -0.0518, -0.0619],\n",
            "        [-0.0596,  0.0133,  0.0175,  ...,  0.0102,  0.0359,  0.0087]])\n",
            "concat.bias tensor([-0.0062, -0.0217, -0.0494,  0.0360, -0.0379, -0.0168, -0.0014,  0.0173,\n",
            "         0.0499, -0.0386,  0.0496, -0.0565, -0.0127, -0.0474,  0.0101,  0.0491,\n",
            "         0.0186, -0.0355, -0.0528,  0.0509,  0.0346, -0.0129,  0.0610,  0.0233,\n",
            "         0.0478,  0.0433, -0.0281,  0.0026,  0.0417, -0.0520,  0.0518,  0.0209,\n",
            "         0.0510, -0.0049, -0.0278,  0.0120,  0.0082,  0.0341, -0.0146,  0.0496,\n",
            "        -0.0567, -0.0140, -0.0202, -0.0202, -0.0449,  0.0111,  0.0483,  0.0138,\n",
            "         0.0577, -0.0477, -0.0387,  0.0277, -0.0180,  0.0141,  0.0618,  0.0475,\n",
            "         0.0577, -0.0416, -0.0428, -0.0273,  0.0423, -0.0137, -0.0504,  0.0505,\n",
            "        -0.0275, -0.0310, -0.0280, -0.0492,  0.0158, -0.0206,  0.0102, -0.0375,\n",
            "         0.0613, -0.0194,  0.0104,  0.0114,  0.0296, -0.0395,  0.0207, -0.0236,\n",
            "        -0.0313,  0.0489,  0.0428,  0.0430, -0.0028,  0.0137, -0.0080, -0.0185,\n",
            "         0.0188, -0.0336,  0.0496,  0.0452, -0.0537,  0.0030,  0.0325, -0.0530,\n",
            "        -0.0345,  0.0521, -0.0177, -0.0159, -0.0195,  0.0548,  0.0320,  0.0599,\n",
            "        -0.0496, -0.0009,  0.0354, -0.0582,  0.0469,  0.0597, -0.0102,  0.0007,\n",
            "         0.0026, -0.0063,  0.0315, -0.0372,  0.0181,  0.0446,  0.0220,  0.0357,\n",
            "         0.0374,  0.0051, -0.0497,  0.0156, -0.0510, -0.0114,  0.0144,  0.0051])\n",
            "fc.weight tensor([[ 0.0080, -0.0757,  0.0878,  ..., -0.0620,  0.0576,  0.0373],\n",
            "        [ 0.0774,  0.0163, -0.0820,  ..., -0.0331, -0.0232, -0.0539],\n",
            "        [ 0.0625,  0.0736,  0.0790,  ...,  0.0159, -0.0651, -0.0879],\n",
            "        ...,\n",
            "        [ 0.0031, -0.0107,  0.0669,  ...,  0.0501,  0.0769, -0.0180],\n",
            "        [ 0.0831,  0.0430,  0.0188,  ...,  0.0080, -0.0652,  0.0329],\n",
            "        [ 0.0586, -0.0035, -0.0283,  ...,  0.0050,  0.0520,  0.0367]])\n",
            "fc.bias tensor([ 0.0751,  0.0507,  0.0081,  0.0458, -0.0118,  0.0641,  0.0313,  0.0180,\n",
            "        -0.0839, -0.0629, -0.0084,  0.0857, -0.0657, -0.0629,  0.0823,  0.0416,\n",
            "         0.0872, -0.0625, -0.0082,  0.0636,  0.0755, -0.0784, -0.0380, -0.0507,\n",
            "        -0.0814,  0.0696, -0.0448,  0.0727,  0.0349,  0.0719, -0.0808,  0.0005,\n",
            "         0.0227,  0.0535, -0.0625, -0.0427,  0.0362,  0.0326, -0.0642, -0.0366,\n",
            "        -0.0712,  0.0236, -0.0606,  0.0169, -0.0121, -0.0832,  0.0587, -0.0086,\n",
            "        -0.0797,  0.0153, -0.0412,  0.0763, -0.0297,  0.0830,  0.0516,  0.0279,\n",
            "         0.0768, -0.0142, -0.0533, -0.0177, -0.0216, -0.0692, -0.0120, -0.0254])\n",
            "fc2.weight tensor([[ 0.1059, -0.0310,  0.0077, -0.0945, -0.1070, -0.0982,  0.0119,  0.0787,\n",
            "          0.0425,  0.0983,  0.0880, -0.0757, -0.0299,  0.0039,  0.0210, -0.0083,\n",
            "         -0.0222, -0.0667,  0.0350, -0.0165,  0.0105, -0.0073,  0.0865,  0.0528,\n",
            "          0.1199,  0.0080,  0.1169, -0.0530,  0.0741,  0.0346,  0.0873,  0.1067,\n",
            "         -0.0065,  0.0636,  0.0777, -0.0530,  0.0345,  0.0829, -0.1168,  0.0855,\n",
            "         -0.0967, -0.0801,  0.0846, -0.0548,  0.0803, -0.0136,  0.0910,  0.0568,\n",
            "         -0.0594,  0.0595,  0.0403, -0.0273, -0.1198, -0.0651,  0.0132,  0.1146,\n",
            "         -0.1216,  0.0988, -0.0754, -0.0677, -0.1164, -0.0266, -0.1185, -0.1013]])\n",
            "fc2.bias tensor([-0.0311])\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 404,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.1567)"
            ]
          },
          "execution_count": 404,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tt = torch.tensor([[0.9531, 0.233]]).float()\n",
        "tb = torch.tensor([[1, 0]]).float()\n",
        "criterion(tt, tb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([])\n"
          ]
        }
      ],
      "source": [
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Intiate Sequence, Basically Create the transformermodel..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Training the Embedding Models**\n",
        "\n",
        "Below is the code that allows us to embed our sentence and floating parameters to a higer dimensional space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InajYBPlYpno"
      },
      "source": [
        "**MLP Encoder**\n",
        "\n",
        "Now if you want to share the same MLP encoder for all numerical inputs (regardless of whether they are radius or height measurements,  etc), then your MLP encoder would take in R^1 and output R^d. These are floating point values, for both input and output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUDrvlGoYo0Q",
        "outputId": "69090ab0-6628-4ebb-963b-ed23cd3ee8aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
            "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
            "        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
            "        [ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14]])\n",
            "tensor([[20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
            "        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
            "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
            "        [ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([11, 15,  8,  1, 18, 25, 19, 12, 16, 22,  7, 21, 10, 30,  5, 17,  9,  6,\n",
              "        31, 23,  3, 14, 24,  4, 13, 29, 27, 20, 26,  2, 28,  0])"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ff3 = np.arange(0, 10, 1)\n",
        "ff1 = np.arange(30, 40, 1)\n",
        "ff2 = np.arange(20, 30, 1)\n",
        "ff4 = np.arange(5, 15, 1)\n",
        "\n",
        "idx = torch.tensor(np.array([ff1, ff3, ff2, ff4]))\n",
        "print(idx)\n",
        "\n",
        "idx=idx[torch.randperm(idx.size()[0])]\n",
        "print(idx)\n",
        "\n",
        "torch.randperm(32)\n",
        "\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "177def0c22df55f44c7bc43ed6b35a63880eb2c6466160d1b315a26cc91306d6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
