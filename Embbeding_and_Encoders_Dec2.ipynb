{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVpB7lcsSZlZ"
      },
      "source": [
        "**Let's Figure Out how we can embed the text and floating point parameters**\n",
        "\n",
        "Embedding is the method in which a continue value or a discrete variable can be represented in a continuous vector. Embedding is a highly utilized method in machine translation and entity embedding for categorical variables. \n",
        "\n",
        "An embedding is a mapping of a discrete — categorical — variable to a vector of continuous numbers. In the context of neural networks, embeddings are low-dimensional, learned continuous vector representations of discrete variables.\n",
        "\n",
        "The primary reasons for embedding content is to the nearest neighbors within a given embedding space, as an input for a supervised task, or visualization of categories. \n",
        "\n",
        "In a nutshell, NN embeddings can easily take all 37,000 book articles on Wikipedia and represent each one using only 50 numbers in a vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCA_Vd11Xqjt"
      },
      "source": [
        "**Creating the Token Embedder**\n",
        "\n",
        "Then what I had in mind was:\n",
        "<CLS> ==> [tokenizer embedding module] ==> embedding in R^d\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 573,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[CLS] Cubic { 1.15, 6.97, 4.45 }', '[CLS] Sphere { 4.32 }', '[CLS] Sphere { 3.86 }', '[CLS] Cubic { 3.57, 4.3, 3.72 }', '[CLS] Cubic { 5.43, 1.87, 2.98 }', '[CLS] Cylinder { 2.58, 2.39 }', '[CLS] Cylinder { 4.84, 6.05 }', '[CLS] Sphere { 5.02 }', '[CLS] Sphere { 1.7 }', '[CLS] Sphere { 1.89 }']\n",
            "12800\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import random\n",
        "import json\n",
        "\n",
        "\n",
        "\n",
        "token_0 = \"[CLS]\"\n",
        "numberOfExamples = 12800\n",
        "shapes = [\"Sphere\", \"Cylinder\", \"Cubic\"]\n",
        "\n",
        "#sentence = \"[CLS] Shape { 23.2,13,14.2 }\"\n",
        "\n",
        "def createSentece(numberOfExamples):\n",
        "    shapeList = []\n",
        "\n",
        "    for i in range(numberOfExamples):\n",
        "        shape = random.choice(shapes)\n",
        "        \n",
        "        sentence = \"\"\n",
        "\n",
        "        if shape == \"Sphere\":\n",
        "            radius = np.random.uniform(.5, 7).__round__(2)\n",
        "            sentence = \"[CLS] \" + shape + \" { \" + str(radius) + \" }\"\n",
        "        elif shape == \"Cylinder\":\n",
        "            radius = np.random.uniform(.5, 7).__round__(2)\n",
        "            height = np.random.uniform(.5, 7).__round__(2)\n",
        "            sentence =  \"[CLS] \" + shape + \" { \" + str(radius) + \", \" + str(height) + \" }\" \n",
        "        elif shape == \"Cubic\":\n",
        "            length = np.random.uniform(.5, 7).__round__(2)\n",
        "            height = np.random.uniform(.5, 7).__round__(2)\n",
        "            width = np.random.uniform(.5, 7).__round__(2)\n",
        "            sentence =  \"[CLS] \" + shape + \" { \" + str(length) + \", \" + str(height) + \", \" + str(width) + \" }\"\n",
        "        else:\n",
        "            print(\"Error\")\n",
        "\n",
        "        shapeList.append(sentence)\n",
        "        #print(sentence)\n",
        "    return shapeList\n",
        "\n",
        "generatedShape = createSentece(numberOfExamples)\n",
        "#print(generatedShape)\n",
        "\n",
        "with open(\"sentences.json\", 'w') as f:\n",
        "    json.dump(generatedShape, f, indent=2) \n",
        "\n",
        "with open(\"sentences.json\", 'r') as f:\n",
        "    s = json.load(f)\n",
        "\n",
        "print(s[:10])\n",
        "print(len(s))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 574,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[CLS] Cubic { 1.15, 6.97, 4.45 }'"
            ]
          },
          "execution_count": 574,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(\"sentences.json\", 'r') as f:\n",
        "    s = json.load(f)\n",
        "    \n",
        "s[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Importing all Relevent Images and Data**\n",
        "\n",
        "This section is dedicated to importing all the images, of the dataset created in the json file above. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 583,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 0 directories and 12800 images in '/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD/renders'.\n",
            "Random image path: /Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD/renders/12236_300.png\n",
            "Image class: renders\n",
            "Image height: 500\n",
            "Image width: 500\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "#image_path = Path(\"/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD/renders\")\n",
        "\n",
        "image_path = Path(\"/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD\")\n",
        "train_dir = image_path / \"renders\"\n",
        "\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Walks through dir_path returning its contents.\n",
        "  Args:\n",
        "    dir_path (str or pathlib.Path): target directory\n",
        "  \n",
        "  Returns:\n",
        "    A print out of:\n",
        "      number of subdiretories in dir_path\n",
        "      number of images (files) in each subdirectory\n",
        "      name of each subdirectory\n",
        "  \"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
        "    \n",
        "walk_through_dir(train_dir)\n",
        "\n",
        "import random\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "# Set seed\n",
        "random.seed(42) # <- try changing this and see what happens\n",
        "\n",
        "# 1. Get all image paths (* means \"any combination\")\n",
        "image_path_list = list(train_dir.glob(\"*.png\"))\n",
        "train_image_list, valid_image_list = image_path_list[:int(0.8*len(image_path_list))], image_path_list[int(0.8*len(image_path_list)):] \n",
        "\n",
        "\n",
        "\n",
        "# 2. Get random image path\n",
        "random_image_path = random.choice(image_path_list)\n",
        "\n",
        "# 3. Get image class from path name (the image class is the name of the directory where the image is stored)\n",
        "image_class = random_image_path.parent.stem\n",
        "\n",
        "# 4. Open image\n",
        "img = Image.open(random_image_path)\n",
        "\n",
        "# 5. Print metadata\n",
        "print(f\"Random image path: {random_image_path}\")\n",
        "print(f\"Image class: {image_class}\")\n",
        "print(f\"Image height: {img.height}\") \n",
        "print(f\"Image width: {img.width}\")\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Turn the image into an array\n",
        "img_as_array = np.asarray(img)\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    # Resize the images to 64x64\n",
        "    transforms.Resize(size=(32, 32)),\n",
        "    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 \n",
        "])\n",
        "\n",
        "\n",
        "def plot_transformed_images(image_paths, transform, n=3, seed=42):\n",
        "    \"\"\"Plots a series of random images from image_paths.\n",
        "\n",
        "    Will open n image paths from image_paths, transform them\n",
        "    with transform and plot them side by side.\n",
        "\n",
        "    Args:\n",
        "        image_paths (list): List of target image paths. \n",
        "        transform (PyTorch Transforms): Transforms to apply to images.\n",
        "        n (int, optional): Number of images to plot. Defaults to 3.\n",
        "        seed (int, optional): Random seed for the random generator. Defaults to 42.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    random_image_paths = random.sample(image_paths, k=n)\n",
        "    for image_path in random_image_paths:\n",
        "        with Image.open(image_path) as f:\n",
        "            fig, ax = plt.subplots(1, 2)\n",
        "            ax[0].imshow(f) \n",
        "            ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
        "            ax[0].axis(\"off\")\n",
        "\n",
        "            # Transform and plot image\n",
        "            # Note: permute() will change shape of image to suit matplotlib \n",
        "            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])\n",
        "            transformed_image = transform(f).permute(1, 2, 0) \n",
        "            ax[1].imshow(transformed_image) \n",
        "            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
        "            ax[1].axis(\"off\")\n",
        "\n",
        "            \n",
        "\n",
        "plot_transformed_images(train_image_list, \n",
        "                        transform=data_transform, \n",
        "                        n=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Loading the Images using the dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 584,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD\n"
          ]
        }
      ],
      "source": [
        "# Use ImageFolder to create dataset(s)\n",
        "from torchvision import datasets\n",
        "image_path = Path(\"/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/\")\n",
        "train_dir = image_path / \"NLP_NERF_CAD\"\n",
        "\n",
        "\n",
        "\n",
        "print(train_dir)\n",
        "# Batch size will now be 32, try changing the batch_size parameter above and see what happens\n",
        "totalImgs = numberOfExamples\n",
        "\n",
        "img_data = datasets.ImageFolder(root=image_path, # target folder of images\n",
        "                                  transform=data_transform, # transforms to perform on data (images)\n",
        "                                  target_transform=None) # transforms to perform on labels (if necessary)\n",
        "\n",
        "\n",
        "img_dataloader = DataLoader(dataset=img_data, \n",
        "                              batch_size=numberOfExamples, # how many samples per batch?\n",
        "                              num_workers=1, # how many subprocesses to use for data loading? (higher = more)\n",
        "                              shuffle=False) # shuffle the data?\n",
        "\n",
        "\n",
        "img = next(iter(img_dataloader))[0]\n",
        "# I need to get total img dataset size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 585,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([12800, 3, 32, 32])"
            ]
          },
          "execution_count": 585,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#img[0].shape\n",
        "#img_data.shape\n",
        "img.shape\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 586,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7faf0bc57040>"
            ]
          },
          "execution_count": 586,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(img[0].permute(1, 2, 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnVjX2uszakz"
      },
      "source": [
        "**Creating a Tokenizer and LxD Matrix for Transformers**\n",
        "\n",
        "Tokenization — this preprocessing step means transforming unstructured Natural Language input in something better structured (in computer terms). The main idea is to break the textual input into fragments that contain granular, yet useful data — these are called Tokens. \n",
        "\n",
        "Following the tokenization process and the MLP encoding into (1,10) vectors. We have to create a LxD matrix to pass into the nn.transformer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exzDP7mL17A_",
        "outputId": "19de4b99-03e9-4c99-8a68-b83b84464d48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "([1.0, 4.0, 6.0, 23.2, 13.0, 14.2, 7.0], [1, 1, 1, 0, 0, 0, 1])\n"
          ]
        }
      ],
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.nn import Embedding\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "\n",
        "dictionary = \"\"\"[SEP] [CLS] Cylinder Sphere Cubic [SEP] { } ,\"\"\"\n",
        "sentence = \"[CLS] Cubic { 23.2,13,14.2 }\"\n",
        "tokens = dictionary.split()\n",
        "d = 10\n",
        "\n",
        "\n",
        "def processText(text):\n",
        "  text = text.replace('{', '{ ')\n",
        "  text = text.replace('}', '} ')\n",
        "  updatedText = text.replace(',', ' ').split(' ')\n",
        "  updatedText = ' '.join(updatedText).split()\n",
        "  return updatedText\n",
        "\n",
        "class token:\n",
        "  def __init__(self, tokens):\n",
        "    self.tokens = tokens.split()\n",
        "    self.embedding = nn.Embedding(50, d) \n",
        "    \n",
        "  def encode(self, sentence):\n",
        "\n",
        "    split = processText(sentence)\n",
        "    encoded = []\n",
        "    \n",
        "    for word in split:\n",
        "      if word in self.tokens:\n",
        "        encoded.append(self.tokens.index(word))\n",
        "      else:\n",
        "        encoded.append(word)\n",
        "\n",
        "    return encoded\n",
        "\n",
        "  def decode(self, encoded):\n",
        "    decoded = []\n",
        "    #print(encoded)\n",
        "    for i in encoded:\n",
        "      \n",
        "      if type(i) == str:\n",
        "        decoded.append(float(i))\n",
        "      else:\n",
        "        decoded.append(self.tokens[i])\n",
        "    return decoded\n",
        "\n",
        "\n",
        "  def tensorEncoded(self, encoded):\n",
        "    newList = []\n",
        "    tensorList = []\n",
        "    for i in encoded:\n",
        "      newList.append(float(i))\n",
        "\n",
        "    for i in newList:\n",
        "      tensorList.append(torch.tensor([i]))\n",
        "\n",
        "    return tensorList\n",
        "  \n",
        "  def npEncode(self, sentence):\n",
        "    newList = []\n",
        "    maskList = []\n",
        "    encoded = self.encode(sentence)\n",
        "\n",
        "    for i in encoded:\n",
        "\n",
        "      newList.append(float(i))\n",
        "      if (encoded.index(i) < 3) or (encoded.index(i) == len(encoded) - 1):\n",
        "        maskList.append(1)\n",
        "      else:\n",
        "        maskList.append(0)\n",
        "\n",
        "    \n",
        "    if len(newList) < 7:\n",
        "      for i in range(7-len(newList)):\n",
        "        newList.append(0.0)\n",
        "        maskList.append(0)\n",
        "\n",
        "    return newList, maskList\n",
        "\n",
        "  def tensorList(self, encoded):\n",
        "    array = []\n",
        "    for i in encoded:\n",
        "      array.append(np.array(i)[0])\n",
        "\n",
        "    return(array)\n",
        "\n",
        "def createDataSet(text):\n",
        "  dataSet = []\n",
        "  for i in text:\n",
        "    dataSet.append(tokens.encodeD(i))\n",
        "  dataSet = torch.stack(dataSet)\n",
        "  return dataSet\n",
        "\n",
        "def createData(text):\n",
        "  dataSet = []\n",
        "  masks = []\n",
        "  for i in text:\n",
        "    dataSet.append(tokens.npEncode(i)[0])\n",
        "    masks.append(tokens.npEncode(i)[1])\n",
        "  \n",
        "  return np.array(dataSet), np.array(masks)\n",
        "\n",
        "\n",
        "\n",
        "tokens = token(dictionary)\n",
        "encoded = tokens.encode(sentence)\n",
        "decoded = tokens.decode(encoded)\n",
        "tokens = token(dictionary)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x = tokens.npEncode(sentence)\n",
        "print(x)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Creating a Custom Embedding, Transformer, and Classifier Module**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 690,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import Tuple\n",
        "bttp = 32\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset\n",
        "\n",
        "\n",
        "\n",
        "class customEmbedding(nn.Module):\n",
        "    def __init__(self, len_vocab=10, embedding_dimension=128):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(len_vocab, embedding_dimension)\n",
        "        self.linear = nn.Linear(1, embedding_dimension)\n",
        "\n",
        "    def forward(self, tokens, discrete_mask):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            Embed the tokens through a 1 layer MLP, and through the nn.Embedding layer\n",
        "            tokens: (batch_size, seq_len)\n",
        "            discrete_mask: (batch_size, seq_len)\n",
        "        Output:\n",
        "            embeddings: (batch_size, seq_len, d)\n",
        "        \"\"\"\n",
        "\n",
        "        tokens = tokens.to(torch.float32)\n",
        "        discrete_mask = discrete_mask.to(torch.float32)\n",
        "\n",
        "        # Mask the tokens to remove float values that may be larger than the number of embeddings\n",
        "        token_mask = torch.mul(tokens.to(torch.int64), discrete_mask.to(torch.int64))\n",
        "        embeddings = self.embedding(token_mask)\n",
        "\n",
        "        # Use the size of the tokens to get the batch size dim\n",
        "        batch_size = tokens.size(0)\n",
        "\n",
        "        # Embed the Sentence as if it were a continuous value\n",
        "        token_reshaped = tokens.view(batch_size, 7, 1) # (batch_size, seq_len, 1) basically update the shape of the tensor\n",
        "        linear_embeddings = self.linear(token_reshaped)\n",
        "\n",
        "        # Create the continuous mask, and expand it to match the embedding dimension\n",
        "        discrete_mask = discrete_mask.unsqueeze(-1)\n",
        "        discrete_mask = discrete_mask.expand_as(embeddings)\n",
        "        discrete_mask_inv = 1 - discrete_mask\n",
        "\n",
        "        embeded = embeddings * discrete_mask + linear_embeddings * discrete_mask_inv\n",
        "        return embeded\n",
        "        \n",
        "# custom convolutional neural network to embed the 32x32 images into a 1 x 10d vector\n",
        "class customCNN(nn.Module):\n",
        "    def __init__(self, embedding_dim: int):\n",
        "\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 6, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(6, 16, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(16 * 5 * 5, 2*embedding_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(embedding_dim*2, embedding_dim),\n",
        "            \n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
        "                 nlayers: int, dropout: float = 0.5):\n",
        "        super().__init__()\n",
        "        self.model_type = 'Transformer'\n",
        "        self.embeder = customEmbedding(len_vocab=10, embedding_dimension=128)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    \n",
        "    def encoder(self, src: Tensor, msk_list: Tensor, src_mask: Tensor) -> Tensor:\n",
        "\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src: Tensor, shape [seq_len, batch_size]\n",
        "            src_mask: Tensor, shape [seq_len, seq_len]\n",
        "\n",
        "        Returns:\n",
        "            output is encoded tensor \n",
        "        \"\"\"\n",
        "\n",
        "        src =  self.embeder(src, msk_list) * math.sqrt(self.d_model) #self.encoder(src) *\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        #print(output[0])\n",
        "        return output\n",
        "\n",
        "\n",
        "    def forward(self, src: Tensor, msk_list: Tensor, src_mask: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src: Tensor, shape [seq_len, batch_size]\n",
        "            src_mask: Tensor, shape [seq_len, seq_len]\n",
        "\n",
        "        Returns:\n",
        "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
        "        \"\"\"\n",
        "        \n",
        "        output = self.encoder(src, msk_list, src_mask)\n",
        "        \n",
        "        \n",
        "        return output\n",
        "\n",
        "\n",
        "# Create a Custom MLP that takes in the output of the CNN and outputs a 1 x 10d vector, and use a cross entropy loss to determine if it can correctly choose the correct class\n",
        "class customMLP(nn.Module):\n",
        "    def __init__(self, ntoken=10, d_model=128, nhead=8, d_hid=128, nlayers=6, dropout=0.5): # add in all the parameters that you want to pass in\n",
        "        super().__init__()\n",
        "        \n",
        "\n",
        "        # Pass the sentence through the embedder which goes through the custom transformer layer\n",
        "        self.token_encoder = TransformerModel(ntoken=10, d_model=128, nhead=8, d_hid=128, nlayers=6, dropout=0.5) #TransformerModel(src, src_mask)\n",
        "        # Encode the images using the customCNN\n",
        "        self.cnn_encoder = customCNN(embedding_dim=d_model) #customCNN(images)\n",
        "        # Concatenate the two vectors together, the first vector is the sentence, the second vector is the image. the sentence has the dimensions of\n",
        "        # BatchSize x LenghtOfSentence x EmbeddingDimension, and the image has the dimensions of BatchSize x 1 x EmbeddingDimension\n",
        "        self.concat = nn.Linear(2*d_model, d_model)\n",
        "\n",
        "        # Pass the concatenated vector through a softmax layer to get the final output\n",
        "        # Linear and Softmax layer for the final output\n",
        "        self.sigmoid = nn.Sigmoid() \n",
        "        self.fc = nn.Linear(d_model, round(d_model/2))\n",
        "        self.fc2 = nn.Linear(round(d_model/2), 1)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "\n",
        "    def forward(self, src, msk_list, src_mask, images):\n",
        "        # Pass the sentence through the embedder which goes through the custom transformer layer\n",
        "        token_output = self.token_encoder(src, msk_list, src_mask)   # (b, L, d)\n",
        "        # Encode the images using the customCNN\n",
        "        image_output = self.cnn_encoder(images)\n",
        "\n",
        "        token_output = token_output[:, 0 , :] # (b, d)\n",
        "        # Concatenate the two vectors together\n",
        "        concat_output = self.concat(torch.cat((token_output, image_output), 1)) # (b, 2d) -> (b, d)\n",
        "        # Pass the concatenated vector through a softmax layer to get the final output\n",
        "        output1 = self.fc(concat_output) # (b, embedding_dim)\n",
        "        #output1 = self.relu(output1)\n",
        "        output2 = self.fc2(output1) # (b, 1)\n",
        "        # maybe add a second hidden laer\n",
        "        output = self.sigmoid(output2)\n",
        "        #score = self.fc(output) # `score` is the output of the MLP (b, 1)\n",
        "\n",
        "        return output\n",
        "        \n",
        "\n",
        "\n",
        "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
        "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
        "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.0000, 4.0000, 6.0000, 3.4400, 2.4400, 2.4700, 7.0000],\n",
            "        [1.0000, 2.0000, 6.0000, 2.0800, 1.6200, 7.0000, 0.0000]],\n",
            "       dtype=torch.float64) tensor([[1, 1, 1, 0, 0, 0, 1],\n",
            "        [1, 1, 1, 0, 0, 1, 0]])\n"
          ]
        }
      ],
      "source": [
        "sentence_set = createSentece(64)\n",
        "data, masks  = createData(s)\n",
        "\n",
        "tensor_data = torch.tensor(data)\n",
        "tensor_masks = torch.tensor(masks)\n",
        "\n",
        "dataset = TensorDataset(tensor_data, tensor_masks)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "d = dataset[0:2][0]\n",
        "m = dataset[0:2][1]\n",
        "model = customEmbedding()\n",
        "output = model(d, m)\n",
        "output.shape\n",
        "print(d,m)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 7, 128])\n"
          ]
        }
      ],
      "source": [
        "encoder_layer = nn.TransformerEncoderLayer(d_model=128, nhead=8)\n",
        "bsize = 2\n",
        "src = torch.rand(10, 32, 512)\n",
        "out = encoder_layer(output)\n",
        "out.shape\n",
        "\n",
        "msk = generate_square_subsequent_mask(2)\n",
        "tm = TransformerModel(ntoken=10, d_model=128, nhead=8, d_hid=128, nlayers=6, dropout=0.5)\n",
        "model = customCNN(embedding_dim=128)\n",
        "\n",
        "print(tm(d, m, msk).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.4197],\n",
            "        [0.4328]], grad_fn=<SigmoidBackward0>)\n",
            "tensor([[0.4197, 0.4197],\n",
            "        [0.4328, 0.4328]], grad_fn=<CatBackward0>)\n",
            "tensor([[1., 1.],\n",
            "        [0., 0.]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 32])"
            ]
          },
          "execution_count": 228,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "mlp_model = customMLP(ntoken=10, d_model=128, nhead=8, d_hid=128, nlayers=6, dropout=0.5)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(mlp_model.parameters(), lr=0.001, momentum=0.9)\n",
        "out2 = mlp_model(d, m, msk, img[0][:2])\n",
        "out2.shape\n",
        "print(out2)\n",
        "\n",
        "# convert to torch to float\n",
        "#img = torch.tensor(img).float()\n",
        "output = torch.cat((out2, out2), 1).float()\n",
        "gt = torch.tensor([[1], [0]]).float()\n",
        "\n",
        "\n",
        "trn = gt.expand(output.shape) # ground truth tensor of 1, 0 expanded to fit the concatenated output for the given batch size\n",
        "print(output)\n",
        "print(trn)\n",
        "loss = nn.BCELoss()\n",
        "output = loss(output, trn)\n",
        "output\n",
        "\n",
        "\n",
        "load_eval_batches = DataLoader(data_complete, batch_size=32, shuffle=False)\n",
        "\n",
        "setset = img[0]\n",
        "setset[0,1].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 619,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS] Cubic { 1.15, 6.97, 4.45 }\n",
            "torch.Size([12800, 7])\n",
            "torch.Size([12800, 7])\n",
            "torch.Size([12800, 3, 32, 32])\n",
            "tensor([ 0.0114, -0.0434,  0.0605,  0.0547, -0.0048,  0.0248,  0.0367,  0.0152,\n",
            "         0.0217,  0.0662,  0.0068,  0.0030, -0.0548, -0.0537, -0.0110,  0.0524,\n",
            "         0.0300,  0.0188,  0.0378, -0.0313, -0.0015, -0.0187,  0.0122, -0.0362,\n",
            "         0.0759,  0.0713, -0.0154,  0.0304, -0.0504,  0.0623,  0.0196, -0.0166,\n",
            "        -0.0377,  0.0117,  0.0342,  0.0411,  0.0167, -0.0202,  0.0074, -0.0054,\n",
            "        -0.0519,  0.0482,  0.0240,  0.0056, -0.0390, -0.0016,  0.0134, -0.0085,\n",
            "        -0.0601,  0.0355,  0.0251, -0.0196,  0.0308, -0.0107, -0.0487, -0.0319,\n",
            "         0.0097,  0.0394,  0.0256,  0.0347, -0.0559,  0.0348, -0.0019,  0.0707,\n",
            "        -0.0212, -0.0160, -0.0281,  0.0402,  0.0545, -0.0216, -0.0440, -0.0692,\n",
            "        -0.0200,  0.0300, -0.0398, -0.0016, -0.0602,  0.0228,  0.0180,  0.0261,\n",
            "        -0.0433, -0.0594,  0.0466, -0.0163, -0.0033,  0.0482, -0.0253, -0.0592,\n",
            "         0.0005,  0.0145,  0.0069,  0.0111,  0.0521, -0.0473,  0.0256,  0.0354,\n",
            "        -0.0012,  0.0231, -0.0668,  0.0033, -0.0343,  0.0246,  0.0481, -0.0099,\n",
            "         0.0468,  0.0018,  0.0484, -0.0227, -0.0400,  0.0361, -0.0035, -0.0191,\n",
            "         0.0387,  0.0325,  0.0022, -0.0339,  0.0207, -0.0282,  0.0136, -0.0318,\n",
            "        -0.0078,  0.0494,  0.0243,  0.0030, -0.0295,  0.0468, -0.0091, -0.0645],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 0.0110, -0.0477,  0.0586,  0.0494, -0.0129,  0.0285,  0.0323,  0.0101,\n",
            "         0.0147,  0.0684,  0.0144, -0.0009, -0.0601, -0.0537, -0.0176,  0.0436,\n",
            "         0.0351,  0.0135,  0.0382, -0.0316,  0.0047, -0.0200,  0.0170, -0.0419,\n",
            "         0.0779,  0.0772, -0.0179,  0.0349, -0.0448,  0.0537,  0.0213, -0.0125,\n",
            "        -0.0324,  0.0128,  0.0311,  0.0482,  0.0101, -0.0219,  0.0043, -0.0110,\n",
            "        -0.0479,  0.0494,  0.0206,  0.0108, -0.0389,  0.0006,  0.0149, -0.0078,\n",
            "        -0.0541,  0.0378,  0.0141, -0.0185,  0.0278, -0.0180, -0.0453, -0.0370,\n",
            "         0.0149,  0.0395,  0.0340,  0.0361, -0.0542,  0.0431, -0.0030,  0.0754,\n",
            "        -0.0211, -0.0144, -0.0297,  0.0414,  0.0492, -0.0235, -0.0439, -0.0737,\n",
            "        -0.0165,  0.0335, -0.0423,  0.0058, -0.0574,  0.0224,  0.0137,  0.0250,\n",
            "        -0.0397, -0.0531,  0.0474, -0.0164, -0.0051,  0.0505, -0.0296, -0.0622,\n",
            "         0.0075,  0.0092,  0.0145,  0.0115,  0.0477, -0.0452,  0.0241,  0.0306,\n",
            "         0.0029,  0.0134, -0.0686, -0.0033, -0.0353,  0.0290,  0.0596, -0.0048,\n",
            "         0.0476,  0.0010,  0.0526, -0.0201, -0.0382,  0.0332, -0.0080, -0.0176,\n",
            "         0.0298,  0.0216, -0.0032, -0.0351,  0.0203, -0.0270,  0.0080, -0.0319,\n",
            "        -0.0056,  0.0510,  0.0208,  0.0086, -0.0319,  0.0536,  0.0026, -0.0650],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(s[0])\n",
        "data, masks  = createData(s)\n",
        "tensor_data = torch.tensor(data)\n",
        "tensor_masks = torch.tensor(masks)\n",
        "\n",
        "\n",
        "# Basically every batch can be divided like this...\n",
        "print(tensor_data.shape)\n",
        "print(tensor_masks.shape)\n",
        "print(img.shape)\n",
        "\n",
        "\n",
        "data_complete = TensorDataset(tensor_data, tensor_masks, img) # torch.Size([b, 7]), torch.Size([b, 7]), torch.Size([b, 3, 32, 32])\n",
        "load_batches = DataLoader(data_complete, batch_size=32, shuffle=False)\n",
        "train_data = next(iter(load_batches))\n",
        "\n",
        "sentenceD = train_data[0] # (b, L)\n",
        "sentenceMskD = train_data[1] # (b, L)\n",
        "imgD = train_data[2] # (b, 3, 32, 32)\n",
        "\n",
        "sentenceD.shape\n",
        "len(load_batches)\n",
        "cnn = customCNN(embedding_dim=128)\n",
        "print(cnn((imgD))[0])\n",
        "print(cnn((imgD))[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.0738, grad_fn=<BinaryCrossEntropyBackward0>)"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m = nn.Sigmoid()\n",
        "loss = nn.BCELoss()\n",
        "input = torch.randn(3, requires_grad=True)\n",
        "target = torch.empty(3).random_(2)\n",
        "output = loss(m(input), target)\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Positional Encoding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Create the Training for the CNN and Transformer Similarity**\n",
        "\n",
        "Unlike a typical transformer, we ourselves, encode the tokens of the sentence, allowing us to encode both words and floating points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 699,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "nm = customMLP(ntoken=10, d_model=128, nhead=8, d_hid=128, nlayers=6, dropout=0.5)\n",
        "lr=0.00005 # learning rate\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(mlp.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.8)\n",
        "bptt = 32 # batch size for training of 32\n",
        "transformer_msk = generate_square_subsequent_mask(bptt)\n",
        "\n",
        "def train(model: nn.Module) -> None:\n",
        "      model.train()  # turn on train mode\n",
        "      total_loss = 0.\n",
        "      num_batches = len(load_batches)\n",
        "       # zero out the gradients\n",
        "\n",
        "      for i, batch in enumerate(load_batches):\n",
        "\n",
        "            # Get the model's output for the tensor with the correct image and an incorrect image\n",
        "            # (batch_size x 2) Concatenated output of the two images, to compare to the ground truth Should be a 2d tensor 1,0 at convg.\n",
        "            # input (l, I_v) -> scalar output [x] -> batch_size x 1\n",
        "            src = batch[0] # (b, L)\n",
        "            msk = batch[1] # (b, L)\n",
        "            img_c = batch[2] # (b, 3, 32, 32)\n",
        "            img_f = img_c[(randomShuffle(bptt))] # shuffle the images to get a false image\n",
        "\n",
        "            output_ic = model(src, msk, transformer_msk, img_c).float() # (b, 1)\n",
        "            output_if = model(src, msk, transformer_msk, img_f).float() # (b, 1)\n",
        "            output = torch.cat((output_ic, output_if), 1) # (2 x b) \n",
        "\n",
        "            # Put output_ground and false into one tensor continaing the other two tensors\n",
        "            # Tensor of labels to the corect size. Batch_size x 2 Ex when bttp=2: [[1, 1], [0, 0]]\n",
        "            target_1, target_0 = torch.tensor([[1]]).float(), torch.tensor([[0]]).float()\n",
        "            target_1 = target_1.expand(output_ic.shape)  # (2 x b)\n",
        "            target_0 = target_0.expand(output_if.shape)  # (2 x b)\n",
        "            target = torch.cat((target_1, target_0), 1) # (2 x b)\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            if i % bptt == 0:\n",
        "                lr = scheduler.get_last_lr()[0]\n",
        "                print(f'| epoch {epoch:3d} | {int(i):3d} / {num_batches:3d} batches | '\n",
        "                        f'lr {lr:.10f} | '\n",
        "                        f'loss {total_loss:5.2f} |')\n",
        "                total_loss = 0  # reset the loss\n",
        "\n",
        "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
        "    model.eval()  # turn on evaluation mode\n",
        "    total_loss = 0.\n",
        "    src_mask = generate_square_subsequent_mask(bptt)\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(load_eval_batches):\n",
        "            \n",
        "            src = batch[0] # (b, L)\n",
        "            msk = batch[1] # (b, L)\n",
        "            img_c = batch[2] # (b, 3, 32, 32)\n",
        "            img_f = img_c[torch.tensor(randomShuffle(bptt))] # shuffle the images to get a false image\n",
        "\n",
        "            output_ic = model(src, msk, transformer_msk, img_c).float() # (b, 1)\n",
        "            output_if = model(src, msk, transformer_msk, img_f).float() # (b, 1)\n",
        "            data = torch.cat((output_ic, output_if), 1) # (2 x b) \n",
        "            \n",
        "            target = torch.tensor([[1], [0]]).float()\n",
        "            target = target.expand(output.shape)  # (2 x b)\n",
        "            \n",
        "            # Calculate the loss using BCE loss, optimizer step \n",
        "            total_loss += criterion(data, target)\n",
        "\n",
        "    return total_loss / (len(eval_data) - 1)\n",
        "\n",
        "# Shuffle Image Data for false image match to the correct text, returns a list of the shuffled indexes unlike the original\n",
        "# tensor=tensor[torch.tensor(randomShuffle(bttp))] \n",
        "\n",
        "def randomShuffle(batchSize):\n",
        "    original = np.arange(batchSize)\n",
        "    shuffled = np.arange(batchSize)\n",
        "    np.random.shuffle(shuffled)\n",
        "\n",
        "    dif = np.absolute(original - shuffled)\n",
        "    \n",
        "    if np.any(dif == 0):\n",
        "        shuffled = randomShuffle(batchSize)\n",
        "    \n",
        "    return shuffled\n",
        "\n",
        "\n",
        "# check = (img_c-img_f)\n",
        "# if torch.count_nonzero(check) <= 0:\n",
        "#     print(torch.count_nonzero(check))\n",
        "#     print(\"Images are supposedly the same\")\n",
        "#     break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Train the Model**\n",
        "\n",
        "During this step we have to train the model to ensure our decoder can effectively account for the position of each word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 700,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   0 |   0 / 400 batches | lr 0.0000500000 | loss  0.70 |\n",
            "| epoch   0 |  32 / 400 batches | lr 0.0000500000 | loss 22.34 |\n",
            "| epoch   0 |  64 / 400 batches | lr 0.0000500000 | loss 22.32 |\n",
            "| epoch   0 |  96 / 400 batches | lr 0.0000500000 | loss 22.35 |\n",
            "| epoch   0 | 128 / 400 batches | lr 0.0000500000 | loss 22.26 |\n",
            "| epoch   0 | 160 / 400 batches | lr 0.0000500000 | loss 22.26 |\n",
            "| epoch   0 | 192 / 400 batches | lr 0.0000500000 | loss 22.29 |\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train(nm)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n",
            "\u001b[1;32m/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb Cell 25\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m img_c \u001b[39m=\u001b[39m batch[\u001b[39m2\u001b[39m] \u001b[39m# (b, 3, 32, 32)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m img_f \u001b[39m=\u001b[39m img_c[(randomShuffle(bptt))] \u001b[39m# shuffle the images to get a false image\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m output_ic \u001b[39m=\u001b[39m model(src, msk, transformer_msk, img_c)\u001b[39m.\u001b[39mfloat() \u001b[39m# (b, 1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m output_if \u001b[39m=\u001b[39m model(src, msk, transformer_msk, img_f)\u001b[39m.\u001b[39mfloat() \u001b[39m# (b, 1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((output_ic, output_if), \u001b[39m1\u001b[39m) \u001b[39m# (2 x b) \u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32m/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb Cell 25\u001b[0m in \u001b[0;36mcustomMLP.forward\u001b[0;34m(self, src, msk_list, src_mask, images)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=168'>169</a>\u001b[0m token_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken_encoder(src, msk_list, src_mask)   \u001b[39m# (b, L, d)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=169'>170</a>\u001b[0m \u001b[39m# Encode the images using the customCNN\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=170'>171</a>\u001b[0m image_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcnn_encoder(images)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=172'>173</a>\u001b[0m token_output \u001b[39m=\u001b[39m token_output[:, \u001b[39m0\u001b[39m , :] \u001b[39m# (b, d)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=173'>174</a>\u001b[0m \u001b[39m# Concatenate the two vectors together\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32m/Users/omoruyiatekha/Documents/GitHub/Referential Language for CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb Cell 25\u001b[0m in \u001b[0;36mcustomCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omoruyiatekha/Documents/GitHub/Referential%20Language%20for%20CAD/NLP_NERF_CAD/Embbeding_and_Encoders_Dec2.ipynb#X46sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train(nm)\n",
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train(mlp)\n",
        "    #scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 555,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "token_encoder.embeder.embedding.weight tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0005, -0.0006, -0.0023,  ..., -0.0008, -0.0027,  0.0002],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
            "token_encoder.embeder.linear.weight tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]])\n",
            "token_encoder.embeder.linear.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "token_encoder.transformer_encoder.layers.0.self_attn.in_proj_weight tensor([[-0.0206, -0.0443,  0.0245,  ...,  0.0695,  0.0129, -0.0172],\n",
            "        [-0.0673,  0.0118,  0.0623,  ..., -0.0257, -0.0630,  0.0006],\n",
            "        [-0.0822, -0.0750,  0.0442,  ...,  0.0833,  0.0506,  0.0207],\n",
            "        ...,\n",
            "        [-0.0057,  0.0468, -0.0918,  ...,  0.0195, -0.1040, -0.0061],\n",
            "        [ 0.0214,  0.0100, -0.0558,  ...,  0.0089, -0.0197, -0.0070],\n",
            "        [-0.0933,  0.0894,  0.0328,  ..., -0.0678,  0.0126, -0.1011]])\n",
            "token_encoder.transformer_encoder.layers.0.self_attn.in_proj_bias tensor([ 5.4049e-11,  1.3548e-11,  1.8138e-10,  2.2153e-11,  1.0949e-11,\n",
            "        -1.4763e-11, -7.9987e-11,  3.9713e-11, -5.6131e-11, -5.4875e-11,\n",
            "         5.9858e-11,  5.9166e-11,  1.3010e-10, -1.7475e-10, -4.1302e-12,\n",
            "         3.9823e-12, -8.4711e-11, -6.4263e-11,  7.4553e-11,  1.6445e-11,\n",
            "         1.0316e-10,  1.0758e-11, -9.9333e-11,  1.1739e-10,  1.4495e-10,\n",
            "         2.4956e-12,  9.2561e-11, -9.8233e-11,  3.8872e-11,  8.9069e-12,\n",
            "         3.0602e-11,  5.6301e-11, -3.9807e-12,  7.0268e-11,  1.5038e-11,\n",
            "         1.0925e-10, -5.9800e-11,  1.4457e-11, -7.8848e-11, -7.4713e-12,\n",
            "         2.1938e-12, -7.6961e-11, -1.3134e-10,  8.2678e-11,  6.0222e-11,\n",
            "        -6.5189e-11,  4.3553e-11,  4.4470e-11,  2.0942e-10,  6.7203e-11,\n",
            "         5.6710e-11, -1.2826e-10,  1.7847e-11,  7.9555e-11, -1.2638e-11,\n",
            "        -4.0361e-11,  9.2473e-11,  1.4811e-11, -7.9880e-11,  9.5747e-11,\n",
            "        -4.6132e-11, -2.2866e-11, -4.4953e-11, -7.6669e-11,  8.7147e-11,\n",
            "         4.6949e-11, -1.2391e-11, -1.1706e-10,  7.2775e-11, -4.2101e-11,\n",
            "        -9.0197e-12, -4.5236e-11,  1.5983e-10,  6.7187e-11,  6.0786e-11,\n",
            "         6.7592e-11,  1.6696e-10, -1.0004e-10,  1.1331e-10, -1.8783e-10,\n",
            "         9.3181e-12, -5.5761e-11,  2.3167e-11, -5.9429e-11, -5.7696e-11,\n",
            "        -4.8142e-11,  1.0139e-11,  9.1224e-11,  1.1298e-10,  7.1792e-12,\n",
            "         9.5703e-11,  6.8027e-12, -4.4287e-12,  7.2701e-11,  1.2964e-11,\n",
            "         1.0480e-10, -3.8916e-11, -4.4707e-11, -7.3568e-11,  1.0810e-10,\n",
            "         6.2545e-11,  7.0157e-11, -1.2200e-10, -2.6309e-12, -9.9692e-11,\n",
            "        -4.8081e-11,  2.4731e-11,  9.2225e-11, -8.3990e-11,  3.7759e-11,\n",
            "         5.7126e-11, -6.0551e-11,  1.1912e-10,  2.2486e-10,  6.6189e-11,\n",
            "         5.6223e-11,  8.3040e-11, -1.0114e-10, -2.0764e-11, -8.8580e-11,\n",
            "        -1.3830e-10,  1.1666e-10, -3.3295e-11, -1.1728e-10, -7.9141e-11,\n",
            "         6.2896e-11, -1.2588e-10, -1.4692e-10,  9.9452e-18, -1.0946e-17,\n",
            "        -1.4293e-17,  9.3555e-18, -8.8361e-18,  3.9785e-18,  2.4963e-17,\n",
            "        -1.6813e-17, -7.0706e-18, -7.3105e-18, -3.3814e-19,  2.9825e-18,\n",
            "        -3.2925e-17,  1.0095e-17, -2.2916e-17,  3.8708e-18, -1.9960e-19,\n",
            "        -1.7711e-18,  6.4563e-18,  8.5365e-19,  8.2433e-19,  3.3674e-18,\n",
            "         1.2844e-17,  2.8213e-18, -5.5854e-18, -5.6964e-18,  5.8729e-18,\n",
            "        -9.1978e-18, -1.8581e-17,  3.9932e-18,  1.2117e-17, -6.2716e-18,\n",
            "         7.5432e-18, -1.4971e-17, -2.6216e-17, -1.2514e-19, -9.4858e-18,\n",
            "        -1.5952e-17,  6.7778e-18,  3.3285e-18, -4.1859e-18, -1.6826e-17,\n",
            "         1.6497e-17,  6.9899e-19,  6.7760e-18,  3.9725e-18, -9.7761e-18,\n",
            "        -8.6446e-18,  4.8167e-18, -2.1539e-17,  1.9280e-17,  3.9449e-17,\n",
            "         1.1175e-17, -1.0821e-17, -1.8260e-17,  1.0610e-17, -4.8687e-18,\n",
            "        -2.3195e-17,  3.0582e-17, -1.6369e-17,  1.2204e-17,  4.0427e-18,\n",
            "         1.3074e-17,  3.1755e-20, -1.4911e-17,  5.6540e-18,  1.7552e-17,\n",
            "         1.0129e-17,  8.2405e-18, -1.4965e-17,  1.5060e-18,  3.0870e-18,\n",
            "         1.7040e-17,  1.3834e-17,  1.1104e-17, -2.4959e-17, -3.6605e-18,\n",
            "         1.5930e-17, -2.3016e-18, -1.6977e-17,  1.7151e-17, -2.7194e-17,\n",
            "        -5.8004e-18, -3.6069e-17,  2.4707e-17, -2.2915e-20,  3.8897e-18,\n",
            "        -1.3032e-17, -5.5367e-18, -7.5428e-17, -4.1943e-17, -2.1729e-18,\n",
            "        -2.9783e-17,  6.3892e-17, -5.1287e-18, -5.4796e-18,  4.6454e-18,\n",
            "        -2.4093e-17, -3.4839e-18,  2.0707e-17,  1.0819e-17,  8.3289e-18,\n",
            "        -1.7548e-17, -1.2428e-17,  1.8162e-17, -1.4575e-17,  1.7397e-17,\n",
            "         1.0151e-17, -1.7793e-17, -1.9224e-17,  2.5931e-18, -4.1472e-18,\n",
            "         1.6725e-17, -1.1433e-17,  1.0170e-17,  6.4763e-19,  6.6926e-18,\n",
            "        -3.0211e-17,  1.3668e-17, -2.7775e-17,  1.4069e-17, -3.1633e-18,\n",
            "        -4.1406e-19,  1.0209e-17,  1.6458e-17,  3.1032e-18,  5.6974e-18,\n",
            "        -1.5354e-17,  8.7001e-05,  1.0873e-04,  1.1964e-04,  8.3576e-05,\n",
            "         2.7055e-05, -9.1123e-05, -5.8928e-05,  2.2379e-05,  7.2495e-05,\n",
            "         4.0821e-05, -9.9053e-05, -1.0681e-04,  2.2301e-05, -1.2273e-04,\n",
            "        -4.3088e-05,  3.8940e-05,  1.4739e-04, -4.2946e-05, -1.8540e-04,\n",
            "         3.1090e-05,  6.3270e-05, -2.4813e-04,  1.6830e-04, -1.9962e-04,\n",
            "        -8.1237e-05,  6.7735e-05, -1.1221e-04, -3.6421e-05,  3.4699e-05,\n",
            "         1.7339e-06, -4.6175e-05,  7.2104e-05,  1.8619e-07, -4.7472e-05,\n",
            "        -7.6775e-05,  1.0934e-05,  4.6066e-06, -2.5373e-05, -5.7939e-05,\n",
            "        -4.1677e-05, -7.5711e-05, -5.5683e-05, -2.3034e-05, -7.0436e-05,\n",
            "         8.5444e-05,  7.2821e-05,  5.6645e-05,  9.6587e-05, -9.4198e-05,\n",
            "         7.0795e-05, -1.5779e-04,  1.3634e-04, -2.3589e-05, -5.1190e-05,\n",
            "        -4.6035e-05,  2.4008e-05, -4.9183e-05,  6.1246e-06,  6.3834e-05,\n",
            "        -1.2558e-04, -4.6748e-05, -4.9949e-05,  5.7837e-05,  1.3055e-04,\n",
            "         1.8924e-04, -2.8743e-05,  2.0357e-05,  1.9994e-05,  4.8011e-05,\n",
            "        -7.8557e-05, -1.4767e-04,  1.3074e-04, -8.7645e-05,  8.1042e-05,\n",
            "         1.4910e-04,  1.0674e-05,  4.4706e-05, -3.4634e-05,  1.0629e-04,\n",
            "         4.8051e-05,  1.3532e-04,  1.2216e-04,  3.3308e-05, -1.8595e-04,\n",
            "         9.4373e-05, -1.8229e-04, -1.2443e-04,  1.8755e-04, -8.3006e-05,\n",
            "        -2.6806e-04,  1.5483e-04, -2.1407e-05, -8.5483e-05, -9.1833e-05,\n",
            "        -1.8741e-04, -5.1875e-05,  1.0897e-04,  1.1329e-04,  7.1218e-06,\n",
            "        -2.2792e-05, -9.9085e-05,  9.0718e-05, -5.0817e-05,  1.0419e-05,\n",
            "        -1.2407e-04,  1.4475e-04,  3.1307e-05,  1.5005e-05,  8.1288e-05,\n",
            "        -7.3545e-05,  1.1919e-04, -6.9996e-05, -7.4144e-05,  1.3931e-04,\n",
            "        -6.1945e-05,  7.2700e-05,  6.4727e-05, -1.8115e-04, -5.7583e-05,\n",
            "        -7.2736e-05,  9.5154e-05,  4.9408e-06,  1.3014e-04, -1.0780e-04,\n",
            "         2.5440e-05,  3.9142e-05,  8.2045e-05,  3.6168e-05])\n",
            "token_encoder.transformer_encoder.layers.0.self_attn.out_proj.weight tensor([[-0.0486, -0.0551, -0.0124,  ..., -0.0738, -0.0202, -0.0112],\n",
            "        [ 0.0414, -0.0782,  0.0360,  ..., -0.0850,  0.0135, -0.0172],\n",
            "        [ 0.0421,  0.0650, -0.0834,  ...,  0.0044, -0.0079,  0.0845],\n",
            "        ...,\n",
            "        [ 0.0634,  0.0509,  0.0373,  ...,  0.0335, -0.0538,  0.0432],\n",
            "        [-0.0754,  0.0440,  0.0274,  ..., -0.0472, -0.0735, -0.0036],\n",
            "        [-0.0016,  0.0141,  0.0085,  ...,  0.0873,  0.0173, -0.0135]])\n",
            "token_encoder.transformer_encoder.layers.0.self_attn.out_proj.bias tensor([-1.1638e-05,  6.2956e-05, -7.4280e-05, -2.3476e-05,  1.5258e-04,\n",
            "        -1.3721e-04, -1.0336e-04, -1.4036e-04, -4.5167e-05,  6.4025e-05,\n",
            "        -1.4522e-05,  5.9228e-05, -4.0967e-05, -2.0494e-04,  4.0333e-05,\n",
            "        -1.0984e-04,  1.7269e-04, -4.8137e-05,  7.8815e-05, -1.8790e-04,\n",
            "        -1.1314e-04,  1.4328e-04, -1.6914e-04,  9.3586e-06, -5.2019e-05,\n",
            "        -3.0265e-05,  3.1083e-04, -2.1363e-05, -8.7994e-05,  2.3971e-04,\n",
            "         8.3832e-05,  1.1983e-04,  2.1442e-05, -1.4774e-04,  2.2270e-04,\n",
            "        -9.0676e-05,  8.5445e-05,  9.4170e-05, -1.1203e-04, -1.9798e-04,\n",
            "        -2.4148e-04,  1.1942e-04, -1.3693e-04,  3.2487e-05,  2.5117e-04,\n",
            "        -2.4061e-04,  1.3884e-04,  1.1127e-04, -2.2086e-04, -2.7605e-05,\n",
            "        -1.7906e-04,  1.6750e-04,  1.5248e-04, -2.1718e-05, -1.7503e-04,\n",
            "        -2.0769e-04,  8.7847e-05,  8.1398e-06,  9.9671e-06, -9.5547e-05,\n",
            "        -6.4267e-05, -2.4790e-04, -1.9547e-04, -1.6908e-04, -1.0475e-04,\n",
            "        -1.0560e-04, -1.4288e-04,  1.6523e-04, -8.4179e-05, -2.4629e-05,\n",
            "         8.2734e-05, -3.2030e-04, -2.5483e-05,  3.3562e-05, -5.7252e-05,\n",
            "        -1.6124e-05, -4.4964e-05, -9.7913e-05,  2.6088e-04,  9.4598e-05,\n",
            "         1.3742e-04, -1.5531e-04,  1.1232e-04,  1.8520e-04,  1.2264e-04,\n",
            "         1.3517e-04,  6.5046e-05,  2.2666e-04,  1.2547e-04,  7.1225e-05,\n",
            "         4.4416e-05,  6.5353e-06,  1.8237e-05, -1.4712e-04, -2.4622e-04,\n",
            "        -7.5200e-05, -3.4600e-05,  2.0159e-04,  6.1718e-05,  1.0221e-05,\n",
            "        -2.7728e-05, -2.3792e-04,  3.3665e-05,  1.9094e-04, -5.4342e-05,\n",
            "        -1.0543e-04,  2.9285e-04,  5.2551e-05,  2.2138e-04,  5.9524e-05,\n",
            "        -1.6621e-05, -4.1945e-06,  1.5166e-04,  1.8255e-04, -7.9036e-05,\n",
            "         3.8730e-06,  9.4138e-05, -3.0890e-05, -1.7317e-05,  1.7419e-04,\n",
            "         4.2630e-05, -5.9232e-05, -1.5996e-04,  1.0547e-04, -7.6821e-05,\n",
            "        -7.5349e-05, -1.4531e-04, -1.0657e-04])\n",
            "token_encoder.transformer_encoder.layers.0.linear1.weight tensor([[ 0.0571,  0.0584,  0.0481,  ...,  0.0554, -0.0860, -0.0332],\n",
            "        [ 0.0024, -0.0642,  0.0629,  ..., -0.0878, -0.0876, -0.0085],\n",
            "        [ 0.0873, -0.0248, -0.0677,  ...,  0.0376, -0.0556, -0.0844],\n",
            "        ...,\n",
            "        [ 0.0053,  0.0725,  0.0214,  ...,  0.0507,  0.0543, -0.0073],\n",
            "        [ 0.0036, -0.0372,  0.0872,  ..., -0.0674, -0.0342, -0.0129],\n",
            "        [ 0.0791, -0.0020,  0.0156,  ..., -0.0286,  0.0857, -0.0044]])\n",
            "token_encoder.transformer_encoder.layers.0.linear1.bias tensor([ 0.0805,  0.0645,  0.0708,  0.0106, -0.0359,  0.0673, -0.0490, -0.0237,\n",
            "         0.0195, -0.0361,  0.0791,  0.0427,  0.0223, -0.0784, -0.0120, -0.0044,\n",
            "        -0.0263, -0.0268,  0.0388, -0.0349, -0.0571, -0.0779,  0.0744, -0.0014,\n",
            "        -0.0707, -0.0298, -0.0130, -0.0322, -0.0586, -0.0128,  0.0657,  0.0798,\n",
            "         0.0039, -0.0071,  0.0859, -0.0371, -0.0599,  0.0559,  0.0637, -0.0581,\n",
            "        -0.0570, -0.0676,  0.0667, -0.0303,  0.0844, -0.0602, -0.0138,  0.0791,\n",
            "        -0.0372,  0.0405, -0.0669, -0.0245, -0.0285, -0.0024, -0.0158,  0.0672,\n",
            "         0.0211, -0.0673,  0.0302,  0.0424, -0.0319, -0.0602,  0.0422,  0.0574,\n",
            "        -0.0241, -0.0672,  0.0263,  0.0002,  0.0198,  0.0877,  0.0178, -0.0661,\n",
            "        -0.0291, -0.0710,  0.0253, -0.0713, -0.0027, -0.0464,  0.0098, -0.0452,\n",
            "        -0.0769, -0.0025, -0.0241, -0.0703, -0.0825, -0.0580, -0.0321,  0.0019,\n",
            "         0.0698, -0.0119, -0.0202,  0.0221, -0.0869,  0.0477,  0.0763, -0.0352,\n",
            "        -0.0746,  0.0082,  0.0038, -0.0631, -0.0570, -0.0359,  0.0495,  0.0734,\n",
            "        -0.0126,  0.0669, -0.0752,  0.0277,  0.0752,  0.0248, -0.0117, -0.0408,\n",
            "        -0.0865, -0.0594,  0.0469,  0.0095,  0.0657, -0.0172,  0.0030, -0.0626,\n",
            "        -0.0739, -0.0876,  0.0419,  0.0131, -0.0588, -0.0035,  0.0224, -0.0343])\n",
            "token_encoder.transformer_encoder.layers.0.linear2.weight tensor([[-0.0713,  0.0368, -0.0236,  ..., -0.0532, -0.0118,  0.0241],\n",
            "        [-0.0635, -0.0315,  0.0215,  ...,  0.0819, -0.0870, -0.0466],\n",
            "        [-0.0136,  0.0712, -0.0599,  ..., -0.0559,  0.0848,  0.0543],\n",
            "        ...,\n",
            "        [-0.0010,  0.0134, -0.0321,  ..., -0.0444, -0.0406, -0.0521],\n",
            "        [ 0.0315,  0.0460,  0.0526,  ...,  0.0047,  0.0208,  0.0053],\n",
            "        [-0.0515, -0.0722, -0.0596,  ..., -0.0849, -0.0783,  0.0570]])\n",
            "token_encoder.transformer_encoder.layers.0.linear2.bias tensor([-0.0820, -0.0015,  0.0034,  0.0136, -0.0244,  0.0604,  0.0073,  0.0686,\n",
            "         0.0831,  0.0744,  0.0771,  0.0610, -0.0682,  0.0684,  0.0080, -0.0440,\n",
            "        -0.0761, -0.0401, -0.0584,  0.0392, -0.0703, -0.0450, -0.0306, -0.0610,\n",
            "         0.0640, -0.0075, -0.0770,  0.0671, -0.0113, -0.0350, -0.0757, -0.0784,\n",
            "         0.0458,  0.0095,  0.0776, -0.0811, -0.0071,  0.0665,  0.0655, -0.0298,\n",
            "        -0.0187, -0.0357, -0.0604,  0.0664, -0.0678,  0.0085,  0.0139,  0.0693,\n",
            "         0.0421,  0.0077, -0.0842, -0.0052, -0.0207,  0.0685,  0.0018, -0.0827,\n",
            "        -0.0042,  0.0858, -0.0600,  0.0434,  0.0680,  0.0452,  0.0031,  0.0642,\n",
            "         0.0361,  0.0078, -0.0651,  0.0498, -0.0326, -0.0095, -0.0605, -0.0508,\n",
            "         0.0326, -0.0715,  0.0446,  0.0345, -0.0012, -0.0703, -0.0687, -0.0438,\n",
            "         0.0846,  0.0561, -0.0330, -0.0171,  0.0344, -0.0697, -0.0590,  0.0646,\n",
            "         0.0735,  0.0047, -0.0521,  0.0486, -0.0863,  0.0244, -0.0167,  0.0291,\n",
            "         0.0435, -0.0818, -0.0091,  0.0860, -0.0300, -0.0855, -0.0519, -0.0436,\n",
            "         0.0156,  0.0218,  0.0883, -0.0369,  0.0432,  0.0854, -0.0689, -0.0499,\n",
            "        -0.0711, -0.0312, -0.0014,  0.0186, -0.0610, -0.0336, -0.0861, -0.0834,\n",
            "        -0.0072,  0.0451, -0.0667,  0.0381, -0.0458, -0.0283,  0.0339, -0.0330])\n",
            "token_encoder.transformer_encoder.layers.0.norm1.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.0.norm1.bias tensor([-2.0144e-08,  1.1913e-07,  5.3493e-08, -3.3260e-07,  2.9979e-07,\n",
            "        -8.9195e-08, -1.1333e-07, -1.9316e-07,  6.9850e-08,  3.0634e-08,\n",
            "        -2.2976e-08,  1.5162e-07, -1.9418e-07, -3.2870e-07,  1.6745e-07,\n",
            "        -1.4885e-07,  4.0711e-07, -8.9183e-08, -8.1393e-08, -4.2664e-07,\n",
            "        -3.7224e-08,  6.6614e-07, -3.7147e-07, -4.8411e-08,  1.5834e-08,\n",
            "        -6.8554e-08,  2.0855e-07, -1.1921e-08,  3.0350e-07,  2.5991e-07,\n",
            "         1.2230e-07,  4.3363e-08, -2.9491e-08, -2.6187e-07,  5.6670e-07,\n",
            "        -5.5859e-07, -7.3331e-08,  2.6522e-07,  1.0023e-07, -2.9171e-07,\n",
            "        -6.0511e-07,  5.0930e-07, -1.8222e-07,  2.4554e-07,  6.3827e-07,\n",
            "        -7.0837e-07,  1.5360e-07,  2.9572e-07, -4.1024e-07, -1.7138e-07,\n",
            "        -1.3818e-07,  2.8028e-07,  3.3873e-07, -8.2445e-08,  6.0475e-07,\n",
            "        -7.3775e-07,  4.8304e-07, -1.1762e-07,  2.6949e-07, -2.5024e-07,\n",
            "        -2.8777e-07, -5.9661e-07, -3.7268e-09, -2.6546e-07, -3.7276e-07,\n",
            "        -1.5634e-07, -3.1720e-07,  9.6608e-08, -2.3332e-07,  1.3683e-07,\n",
            "         4.4306e-08, -6.0884e-07, -4.0647e-07,  2.9910e-07, -4.1293e-07,\n",
            "         1.6754e-07, -2.2020e-07, -2.7241e-07,  5.1030e-07,  5.0319e-07,\n",
            "         1.3064e-07, -6.7177e-08,  1.7048e-07,  3.9402e-07,  1.5480e-07,\n",
            "         1.7914e-07,  9.6889e-08,  3.1774e-07,  1.3334e-07, -3.5095e-08,\n",
            "        -6.5025e-08, -1.7860e-07,  2.9259e-07, -3.7168e-07, -4.0494e-07,\n",
            "        -7.0172e-08, -3.1703e-07,  4.9733e-07,  3.1600e-07,  1.4707e-07,\n",
            "        -5.0909e-07, -3.9063e-07,  1.7627e-07,  2.3241e-07,  5.1697e-08,\n",
            "        -1.9286e-07,  2.8598e-07,  2.0143e-07,  2.8446e-07, -6.7206e-08,\n",
            "         1.4222e-07,  2.0646e-07,  6.2530e-07,  3.4284e-07, -2.1556e-07,\n",
            "        -9.1966e-09,  2.6882e-07, -1.6393e-07,  1.1763e-07,  3.8555e-07,\n",
            "        -1.4697e-07, -4.0155e-07, -2.0434e-07,  4.4014e-07, -5.2864e-07,\n",
            "        -1.5508e-07, -5.4010e-07, -3.6145e-07])\n",
            "token_encoder.transformer_encoder.layers.0.norm2.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.0.norm2.bias tensor([-1.0360e-07, -4.4160e-08,  9.8924e-08, -1.0386e-07, -2.7115e-08,\n",
            "        -8.6163e-08,  7.0414e-08, -1.3654e-08,  7.7569e-08,  5.8488e-08,\n",
            "         7.3028e-08,  3.7520e-08, -2.0100e-09, -1.0273e-07, -1.2794e-08,\n",
            "        -6.5740e-08,  6.1479e-08,  5.1959e-09,  1.4975e-08, -1.5540e-07,\n",
            "         5.1238e-08,  1.9426e-07, -2.5056e-08, -6.1187e-08,  1.0007e-07,\n",
            "        -3.7109e-08,  3.7809e-08, -6.1080e-08,  2.0287e-07,  8.7668e-09,\n",
            "        -4.1387e-08,  6.7032e-08,  4.2890e-08,  6.7605e-09,  1.0631e-07,\n",
            "        -6.6720e-08, -8.9098e-08,  2.9315e-09,  7.5066e-10, -5.9606e-08,\n",
            "        -2.0767e-07,  6.2526e-08, -4.0082e-08,  1.0771e-07, -1.8836e-08,\n",
            "        -8.3071e-08,  4.7877e-08,  8.4523e-08, -5.5592e-08,  3.0466e-08,\n",
            "        -1.3937e-08,  8.6820e-08, -3.0360e-10, -1.1066e-08,  6.8684e-09,\n",
            "        -3.5739e-08,  8.6668e-08, -5.6362e-08,  4.6070e-08, -6.1951e-08,\n",
            "        -7.4205e-09, -1.0509e-07,  1.3187e-08,  7.5100e-09, -7.5493e-08,\n",
            "        -4.8376e-08,  3.2613e-08, -1.8264e-08, -4.9420e-08,  4.5556e-08,\n",
            "         2.8088e-08, -1.2243e-07, -6.9126e-08, -2.7699e-08, -4.9896e-08,\n",
            "         1.5202e-07, -1.2663e-07, -1.0073e-07, -4.1216e-08,  1.0729e-07,\n",
            "         4.9552e-08, -6.5026e-08, -6.6109e-08, -1.0112e-08,  4.2278e-08,\n",
            "         2.2760e-08,  3.1238e-08,  3.5769e-08,  4.2986e-08,  7.0830e-08,\n",
            "        -7.1164e-08,  4.5339e-08,  5.4174e-09,  8.5153e-09, -5.9283e-08,\n",
            "        -2.6631e-08, -2.0344e-08,  6.7465e-08, -3.9696e-08,  6.1665e-08,\n",
            "        -8.6484e-08, -9.2959e-08, -1.0925e-07,  1.1778e-08, -3.3177e-08,\n",
            "        -4.6639e-08, -2.0294e-08,  6.8979e-08,  5.1028e-08,  7.9176e-09,\n",
            "        -8.0475e-08,  6.5882e-08, -7.8144e-09,  1.5102e-07, -4.7306e-09,\n",
            "        -1.2953e-07,  9.3162e-08,  2.8750e-08, -6.9478e-08,  5.5154e-08,\n",
            "        -6.3900e-09, -3.3976e-09, -8.9981e-08,  3.8255e-08, -8.8427e-08,\n",
            "        -7.2437e-09, -9.8118e-08, -4.9853e-08])\n",
            "token_encoder.transformer_encoder.layers.1.self_attn.in_proj_weight tensor([[-0.0206, -0.0443,  0.0245,  ...,  0.0695,  0.0129, -0.0172],\n",
            "        [-0.0673,  0.0118,  0.0623,  ..., -0.0257, -0.0630,  0.0006],\n",
            "        [-0.0822, -0.0750,  0.0442,  ...,  0.0833,  0.0506,  0.0207],\n",
            "        ...,\n",
            "        [-0.0057,  0.0468, -0.0918,  ...,  0.0195, -0.1040, -0.0061],\n",
            "        [ 0.0214,  0.0100, -0.0558,  ...,  0.0089, -0.0197, -0.0070],\n",
            "        [-0.0933,  0.0894,  0.0328,  ..., -0.0678,  0.0126, -0.1011]])\n",
            "token_encoder.transformer_encoder.layers.1.self_attn.in_proj_bias tensor([-3.3549e-09,  1.3870e-08, -1.9199e-08, -4.4467e-09, -2.4963e-09,\n",
            "         1.5254e-09, -3.6206e-09,  3.8330e-09,  1.2750e-08,  7.2850e-09,\n",
            "         3.7572e-09,  1.3379e-08,  1.3621e-08, -3.0544e-09, -7.8640e-09,\n",
            "        -3.1144e-09, -1.4513e-08,  4.6864e-10, -2.8535e-09,  3.1900e-09,\n",
            "         2.8096e-09,  5.9279e-10,  6.5107e-09,  2.6870e-09, -7.6408e-09,\n",
            "        -9.1754e-09, -6.8567e-09,  6.6009e-09,  1.7322e-09, -3.9667e-09,\n",
            "        -7.2856e-10, -1.2079e-08,  1.3659e-08,  1.6074e-08, -1.4612e-08,\n",
            "         1.2347e-08,  1.3943e-09, -3.0329e-09,  1.6820e-08,  4.1194e-09,\n",
            "        -7.9090e-09,  1.3923e-08,  1.0699e-08,  3.0543e-09,  8.4647e-09,\n",
            "        -1.8772e-09,  3.4633e-09, -1.6704e-08,  1.5665e-08, -1.1783e-09,\n",
            "         3.0519e-09, -1.3588e-08, -2.6767e-09,  8.7044e-09, -8.2951e-09,\n",
            "         7.0727e-09,  7.0813e-09,  1.7064e-08,  5.8714e-09, -2.4552e-08,\n",
            "        -8.6288e-10,  1.3507e-09, -4.6213e-09,  2.4450e-08, -1.8537e-08,\n",
            "        -1.5935e-09, -7.0215e-09, -7.4606e-09,  4.5934e-10, -1.8093e-09,\n",
            "        -2.5452e-09, -7.0255e-09,  2.6176e-10, -3.2015e-09,  6.5269e-10,\n",
            "         8.0269e-09,  1.0358e-08, -7.9819e-09, -7.5769e-09, -6.6405e-09,\n",
            "         4.1542e-09, -5.4224e-09, -6.8189e-09,  1.2235e-09, -4.6141e-09,\n",
            "        -5.8392e-09, -4.6230e-10, -2.2893e-09,  1.6516e-09, -3.4892e-09,\n",
            "         1.7142e-08,  1.8562e-09,  7.3477e-09,  5.0323e-09, -1.5128e-09,\n",
            "        -3.4163e-09, -3.7534e-09,  3.0622e-09, -1.7979e-09,  1.1189e-08,\n",
            "         1.4959e-08,  4.2508e-09,  1.6026e-08, -1.1704e-08, -1.6012e-08,\n",
            "        -1.1009e-08, -7.6677e-09,  1.1010e-08,  5.2859e-09, -7.9140e-09,\n",
            "         9.2027e-09, -1.1843e-08, -8.1030e-09, -2.7560e-09,  4.5978e-09,\n",
            "        -1.3946e-08,  1.3094e-08,  1.0465e-08, -1.5948e-08, -7.9266e-09,\n",
            "         9.9127e-09,  1.5535e-08,  6.4235e-09,  3.6630e-09, -2.6144e-09,\n",
            "         1.0066e-08, -2.4490e-08, -3.4854e-09, -1.3409e-16,  1.0537e-15,\n",
            "         1.4764e-15,  6.1434e-16, -3.8264e-16,  1.8723e-15, -2.8323e-16,\n",
            "        -2.6809e-15,  2.3850e-15,  3.1118e-17,  1.7892e-15, -2.9169e-15,\n",
            "         1.2447e-15, -4.6774e-16, -1.5083e-15,  1.4752e-15, -8.6004e-16,\n",
            "        -2.1128e-15,  1.6720e-15,  1.5012e-15,  8.6135e-16,  1.3413e-16,\n",
            "        -1.7825e-15,  2.1150e-15,  7.6148e-16, -1.1752e-15,  7.8717e-17,\n",
            "        -1.1857e-15, -1.0720e-15, -3.2841e-16,  2.7729e-16,  8.7088e-16,\n",
            "         6.6047e-16,  1.9307e-16, -7.1394e-16,  2.7674e-15, -8.4360e-16,\n",
            "         2.1917e-15, -2.6262e-16,  3.4647e-15, -1.7301e-15,  5.9461e-16,\n",
            "         1.1614e-15,  8.6046e-16,  1.3686e-15, -6.7204e-16,  1.2547e-15,\n",
            "         2.0620e-15, -4.3774e-16, -3.2229e-16,  8.9464e-16,  3.0894e-15,\n",
            "        -5.5670e-16, -1.9720e-15,  7.6116e-16,  2.3856e-16,  1.8047e-15,\n",
            "        -1.6426e-15,  9.0597e-16,  8.2146e-16,  1.8025e-16,  4.6219e-16,\n",
            "        -5.3444e-16, -3.2026e-16, -7.6956e-16, -3.4280e-16, -7.8089e-16,\n",
            "        -7.7145e-16, -5.5574e-16,  1.5413e-16,  5.0031e-16, -2.7527e-15,\n",
            "         8.1207e-16,  1.0813e-16, -8.2507e-16, -3.1201e-16,  1.2730e-15,\n",
            "         4.4765e-16, -3.4826e-15,  7.5957e-16, -1.9831e-15,  9.1616e-16,\n",
            "         1.3267e-15, -2.2239e-15, -4.6734e-16, -1.9212e-15,  1.5381e-15,\n",
            "         6.0030e-18,  2.1018e-15, -8.7409e-16, -1.6912e-15, -1.6017e-15,\n",
            "         2.5197e-15,  2.4141e-15, -1.9004e-15, -2.2432e-15, -1.4605e-15,\n",
            "         9.8988e-16, -6.9402e-16,  1.3467e-15, -2.9437e-16,  7.1523e-16,\n",
            "         6.3368e-16,  2.3412e-15,  1.2643e-16,  2.1353e-15, -3.9169e-15,\n",
            "        -4.8017e-15, -5.1403e-15, -4.6999e-16,  1.5455e-15,  7.7087e-16,\n",
            "         6.2169e-17,  2.2761e-15, -3.5736e-16, -1.1974e-15, -8.6922e-16,\n",
            "        -2.9651e-15, -3.1764e-16,  5.2557e-16,  1.9952e-15, -3.0011e-15,\n",
            "         6.0869e-16,  5.0854e-16,  1.5005e-15,  3.4272e-16,  6.6910e-16,\n",
            "        -5.9059e-16,  4.3887e-08,  1.4376e-07, -1.1570e-08,  1.4144e-08,\n",
            "         5.4819e-08,  2.5999e-08, -7.3965e-08,  9.2769e-09, -2.8498e-08,\n",
            "        -8.8968e-08,  4.9405e-08, -1.1208e-08, -7.0002e-08, -4.4878e-08,\n",
            "        -4.2282e-08,  3.8785e-08,  1.7180e-08, -6.5644e-08, -4.5046e-08,\n",
            "         7.8797e-08,  4.0961e-08,  2.6688e-08,  2.5375e-08, -1.4440e-10,\n",
            "         8.7697e-09,  9.7242e-08, -8.1723e-08, -3.5381e-08, -3.4692e-08,\n",
            "        -1.5424e-08, -4.4927e-08, -9.5661e-08,  1.8393e-08,  1.7382e-08,\n",
            "         1.0436e-08, -5.7078e-09, -1.2274e-08,  7.1102e-09, -5.6680e-08,\n",
            "         3.4087e-08, -3.9166e-08, -2.8731e-08,  1.4336e-08, -1.7130e-08,\n",
            "        -1.5300e-08,  6.9208e-08, -5.4885e-08, -7.5702e-08,  5.3109e-09,\n",
            "        -2.0692e-08, -4.2564e-08,  1.3884e-08,  5.7925e-08, -6.5028e-08,\n",
            "         2.3891e-08, -2.7286e-11,  8.5066e-09,  6.2938e-08, -1.3581e-08,\n",
            "        -4.6311e-08,  1.1901e-07,  9.0054e-08,  6.9685e-08,  3.6733e-08,\n",
            "         7.7356e-08, -3.4379e-09, -7.1492e-08,  3.9372e-09, -3.4475e-09,\n",
            "        -6.5023e-08, -7.1864e-09,  3.3593e-08, -7.4826e-08,  9.2179e-08,\n",
            "         4.6633e-08,  1.2770e-07, -2.8631e-08, -3.4078e-08,  1.9154e-08,\n",
            "         2.4414e-08,  2.9495e-08,  1.9160e-08, -1.5370e-08, -5.8136e-08,\n",
            "         6.3045e-08, -2.5594e-08,  3.5966e-08, -1.3181e-08,  5.6316e-09,\n",
            "         3.4110e-08, -1.2830e-07, -6.5256e-08, -9.7483e-08, -2.3603e-08,\n",
            "        -9.3434e-08, -8.8664e-08, -1.2283e-07,  3.2594e-08, -2.3053e-08,\n",
            "         3.5758e-08, -4.0521e-08, -5.7209e-08,  1.5489e-08,  1.0822e-08,\n",
            "         1.8331e-08, -1.0647e-08,  4.7483e-09,  8.0855e-08, -6.0799e-08,\n",
            "        -4.3107e-08,  6.2098e-09,  6.2732e-09, -2.2131e-08, -7.8226e-08,\n",
            "         1.0571e-08,  4.6808e-08, -5.4204e-08,  9.4879e-09, -8.2928e-08,\n",
            "         1.3033e-08,  9.4677e-08,  1.1529e-08,  1.3284e-07, -5.9459e-08,\n",
            "        -5.9234e-08, -1.0811e-08,  8.0390e-08,  4.0027e-08])\n",
            "token_encoder.transformer_encoder.layers.1.self_attn.out_proj.weight tensor([[-0.0486, -0.0551, -0.0124,  ..., -0.0738, -0.0202, -0.0112],\n",
            "        [ 0.0414, -0.0782,  0.0360,  ..., -0.0850,  0.0135, -0.0172],\n",
            "        [ 0.0421,  0.0650, -0.0834,  ...,  0.0044, -0.0079,  0.0845],\n",
            "        ...,\n",
            "        [ 0.0634,  0.0509,  0.0373,  ...,  0.0335, -0.0538,  0.0432],\n",
            "        [-0.0754,  0.0440,  0.0274,  ..., -0.0472, -0.0735, -0.0036],\n",
            "        [-0.0016,  0.0141,  0.0085,  ...,  0.0873,  0.0173, -0.0135]])\n",
            "token_encoder.transformer_encoder.layers.1.self_attn.out_proj.bias tensor([-1.1326e-07, -9.4326e-08,  9.7021e-08, -1.1526e-07, -6.4244e-08,\n",
            "        -9.7090e-08, -5.0285e-08,  8.8884e-08, -2.1845e-08,  4.5634e-08,\n",
            "         9.0246e-08,  1.1670e-07,  2.0870e-08, -5.8578e-08, -7.3657e-08,\n",
            "        -1.8170e-08, -4.7964e-08, -6.4908e-08, -2.4903e-08, -1.2150e-07,\n",
            "         1.8309e-09,  1.2736e-07,  3.5466e-08, -6.0864e-09,  7.7657e-08,\n",
            "         8.3095e-08,  1.0780e-07, -8.5598e-08,  1.5175e-07, -6.3597e-08,\n",
            "         4.0425e-08,  1.5931e-08, -7.1161e-08,  7.2746e-08,  4.6748e-08,\n",
            "        -8.5554e-08, -6.4640e-08, -3.9022e-09, -5.6471e-08, -5.9635e-08,\n",
            "        -1.3599e-07,  2.1230e-08, -1.0764e-07,  1.0755e-07, -2.0220e-08,\n",
            "        -6.3341e-08,  8.0637e-08,  4.4130e-10, -3.0553e-09, -3.8295e-08,\n",
            "        -6.6768e-08,  1.7067e-07,  2.5228e-08, -7.3480e-08, -1.2975e-07,\n",
            "         2.9511e-08,  5.1452e-08, -3.3548e-08,  5.4064e-08, -1.6396e-07,\n",
            "        -2.4287e-08, -9.7740e-08,  3.2734e-08,  4.4174e-08, -4.1888e-08,\n",
            "         2.5404e-08,  9.3267e-08, -9.2064e-08,  1.6366e-08,  1.8788e-08,\n",
            "         2.7346e-08, -4.7253e-08, -3.7718e-08, -1.6895e-08, -1.1443e-07,\n",
            "         1.0705e-07, -3.6900e-08, -1.6153e-07,  1.9506e-08,  1.1058e-07,\n",
            "        -1.4254e-08, -3.2310e-08,  5.6324e-09, -9.3650e-08, -3.6596e-08,\n",
            "        -3.2069e-08, -1.2266e-08, -9.0885e-10,  2.2543e-08,  1.0270e-07,\n",
            "        -6.1067e-08,  1.8860e-08, -6.4941e-08, -4.6535e-08, -3.4525e-08,\n",
            "        -2.2036e-08,  4.3240e-08,  1.1206e-08, -7.3251e-08,  2.5064e-07,\n",
            "        -3.4503e-08, -2.6953e-07, -9.4499e-08,  4.0583e-08,  7.4313e-08,\n",
            "         4.0425e-09, -2.4047e-08,  8.2252e-08, -1.6206e-08,  3.1809e-09,\n",
            "        -7.2358e-08,  6.3444e-08, -4.6674e-08,  7.9243e-08,  2.9961e-08,\n",
            "        -4.9033e-08,  3.3518e-08, -4.8311e-09, -4.5850e-08,  3.7337e-08,\n",
            "         4.1643e-08, -4.8713e-08, -7.7580e-08,  1.0458e-07,  5.9433e-08,\n",
            "        -1.2171e-07, -6.8199e-08,  7.4656e-08])\n",
            "token_encoder.transformer_encoder.layers.1.linear1.weight tensor([[ 0.0571,  0.0584,  0.0481,  ...,  0.0554, -0.0860, -0.0332],\n",
            "        [ 0.0024, -0.0642,  0.0629,  ..., -0.0878, -0.0876, -0.0085],\n",
            "        [ 0.0873, -0.0248, -0.0677,  ...,  0.0376, -0.0556, -0.0844],\n",
            "        ...,\n",
            "        [ 0.0053,  0.0725,  0.0214,  ...,  0.0507,  0.0543, -0.0073],\n",
            "        [ 0.0036, -0.0372,  0.0872,  ..., -0.0674, -0.0342, -0.0129],\n",
            "        [ 0.0791, -0.0020,  0.0156,  ..., -0.0286,  0.0857, -0.0044]])\n",
            "token_encoder.transformer_encoder.layers.1.linear1.bias tensor([ 0.0805,  0.0645,  0.0708,  0.0106, -0.0359,  0.0673, -0.0490, -0.0237,\n",
            "         0.0195, -0.0361,  0.0791,  0.0427,  0.0223, -0.0784, -0.0120, -0.0044,\n",
            "        -0.0263, -0.0268,  0.0388, -0.0349, -0.0571, -0.0779,  0.0744, -0.0014,\n",
            "        -0.0707, -0.0298, -0.0130, -0.0322, -0.0586, -0.0128,  0.0657,  0.0798,\n",
            "         0.0039, -0.0071,  0.0859, -0.0371, -0.0599,  0.0559,  0.0637, -0.0581,\n",
            "        -0.0570, -0.0676,  0.0667, -0.0303,  0.0844, -0.0602, -0.0138,  0.0791,\n",
            "        -0.0372,  0.0405, -0.0669, -0.0245, -0.0285, -0.0024, -0.0158,  0.0672,\n",
            "         0.0211, -0.0673,  0.0302,  0.0424, -0.0319, -0.0602,  0.0422,  0.0574,\n",
            "        -0.0241, -0.0672,  0.0263,  0.0002,  0.0198,  0.0877,  0.0178, -0.0661,\n",
            "        -0.0291, -0.0710,  0.0253, -0.0713, -0.0027, -0.0464,  0.0098, -0.0452,\n",
            "        -0.0769, -0.0025, -0.0241, -0.0703, -0.0825, -0.0580, -0.0321,  0.0019,\n",
            "         0.0698, -0.0119, -0.0202,  0.0221, -0.0869,  0.0477,  0.0763, -0.0352,\n",
            "        -0.0746,  0.0082,  0.0038, -0.0631, -0.0570, -0.0359,  0.0495,  0.0734,\n",
            "        -0.0126,  0.0669, -0.0752,  0.0277,  0.0752,  0.0248, -0.0117, -0.0408,\n",
            "        -0.0865, -0.0594,  0.0469,  0.0095,  0.0657, -0.0172,  0.0030, -0.0626,\n",
            "        -0.0739, -0.0876,  0.0419,  0.0131, -0.0588, -0.0035,  0.0224, -0.0343])\n",
            "token_encoder.transformer_encoder.layers.1.linear2.weight tensor([[-0.0713,  0.0368, -0.0236,  ..., -0.0532, -0.0118,  0.0241],\n",
            "        [-0.0635, -0.0315,  0.0215,  ...,  0.0819, -0.0870, -0.0466],\n",
            "        [-0.0136,  0.0712, -0.0599,  ..., -0.0559,  0.0848,  0.0543],\n",
            "        ...,\n",
            "        [-0.0010,  0.0134, -0.0321,  ..., -0.0444, -0.0406, -0.0521],\n",
            "        [ 0.0315,  0.0460,  0.0526,  ...,  0.0047,  0.0208,  0.0053],\n",
            "        [-0.0515, -0.0722, -0.0596,  ..., -0.0849, -0.0783,  0.0570]])\n",
            "token_encoder.transformer_encoder.layers.1.linear2.bias tensor([-0.0820, -0.0015,  0.0034,  0.0136, -0.0244,  0.0604,  0.0073,  0.0686,\n",
            "         0.0831,  0.0744,  0.0771,  0.0610, -0.0682,  0.0684,  0.0080, -0.0440,\n",
            "        -0.0761, -0.0401, -0.0584,  0.0392, -0.0703, -0.0450, -0.0306, -0.0610,\n",
            "         0.0640, -0.0075, -0.0770,  0.0671, -0.0113, -0.0350, -0.0757, -0.0784,\n",
            "         0.0458,  0.0095,  0.0776, -0.0811, -0.0071,  0.0665,  0.0655, -0.0298,\n",
            "        -0.0187, -0.0357, -0.0604,  0.0664, -0.0678,  0.0085,  0.0139,  0.0693,\n",
            "         0.0421,  0.0077, -0.0842, -0.0052, -0.0207,  0.0685,  0.0018, -0.0827,\n",
            "        -0.0042,  0.0858, -0.0600,  0.0434,  0.0680,  0.0452,  0.0031,  0.0642,\n",
            "         0.0361,  0.0078, -0.0651,  0.0498, -0.0326, -0.0095, -0.0605, -0.0508,\n",
            "         0.0326, -0.0715,  0.0446,  0.0345, -0.0012, -0.0703, -0.0687, -0.0438,\n",
            "         0.0846,  0.0561, -0.0330, -0.0171,  0.0344, -0.0697, -0.0590,  0.0646,\n",
            "         0.0735,  0.0047, -0.0521,  0.0486, -0.0863,  0.0244, -0.0167,  0.0291,\n",
            "         0.0435, -0.0818, -0.0091,  0.0860, -0.0300, -0.0855, -0.0519, -0.0436,\n",
            "         0.0156,  0.0218,  0.0883, -0.0369,  0.0432,  0.0854, -0.0689, -0.0499,\n",
            "        -0.0711, -0.0312, -0.0014,  0.0186, -0.0610, -0.0336, -0.0861, -0.0834,\n",
            "        -0.0072,  0.0451, -0.0667,  0.0381, -0.0458, -0.0283,  0.0339, -0.0330])\n",
            "token_encoder.transformer_encoder.layers.1.norm1.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.1.norm1.bias tensor([-1.2802e-07, -6.0862e-08,  3.2881e-08, -1.1998e-07, -4.8225e-09,\n",
            "        -5.1263e-08,  5.1819e-08, -9.8530e-09,  6.8870e-08,  5.0893e-08,\n",
            "         7.1032e-08,  9.7688e-08,  4.5670e-10, -3.0951e-08,  8.8170e-09,\n",
            "        -1.6817e-08, -7.6515e-09, -2.4587e-08, -4.2842e-09, -1.4462e-07,\n",
            "         7.9711e-08,  1.6496e-07, -2.2847e-08, -2.4635e-08,  1.4684e-07,\n",
            "        -3.3059e-09,  1.0756e-08, -8.4347e-08,  1.9477e-07,  2.9849e-08,\n",
            "        -1.2859e-09,  2.1084e-08,  4.5370e-08,  4.3519e-08,  4.3639e-08,\n",
            "        -3.8167e-08, -6.0988e-08, -9.0350e-09,  3.2997e-08, -6.6755e-08,\n",
            "        -1.9391e-07,  6.3391e-08, -4.8635e-08,  8.7618e-08, -6.2358e-08,\n",
            "        -2.7966e-08,  8.4494e-08, -5.3121e-08, -6.4946e-08,  4.4973e-08,\n",
            "        -7.5773e-09,  1.2439e-07,  4.3499e-08,  1.7372e-08, -4.7183e-08,\n",
            "         1.8640e-08,  1.0394e-07, -9.3985e-09,  4.6287e-08, -3.1704e-08,\n",
            "        -1.7264e-08, -7.4634e-08, -2.1092e-09,  5.1724e-08, -4.4884e-08,\n",
            "         4.0183e-10,  4.8859e-08, -6.0333e-08,  1.2453e-09,  2.3822e-08,\n",
            "         5.3540e-08, -6.5569e-08, -4.5178e-08, -2.0028e-08, -4.5148e-08,\n",
            "         1.3361e-07, -7.8107e-08, -6.6911e-08, -2.3879e-08,  9.9751e-08,\n",
            "         1.8233e-08, -3.2801e-08, -4.2968e-08,  9.8749e-09,  3.8723e-08,\n",
            "        -3.4046e-08,  7.7809e-08,  1.5019e-08,  4.5428e-08,  1.1856e-07,\n",
            "        -8.4364e-08,  2.0952e-08,  3.9874e-08,  1.8982e-08, -4.5004e-08,\n",
            "         3.9803e-08,  2.5684e-08,  3.8008e-08, -3.2671e-08,  1.1680e-07,\n",
            "        -2.3520e-08, -1.0260e-07, -9.7035e-08,  3.5641e-08, -1.5330e-08,\n",
            "        -5.5525e-08, -1.1843e-08,  6.0563e-08,  1.7434e-08, -3.8345e-08,\n",
            "        -5.5933e-08,  2.6510e-08,  1.5253e-09,  8.5726e-08,  5.3115e-08,\n",
            "        -5.4790e-08,  6.8271e-08,  1.7861e-08, -1.0873e-07,  2.5999e-08,\n",
            "         1.8543e-09, -7.4784e-08, -7.6976e-08,  7.6376e-08, -2.3605e-08,\n",
            "         7.9936e-09, -7.9296e-08,  5.1565e-10])\n",
            "token_encoder.transformer_encoder.layers.1.norm2.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.1.norm2.bias tensor([-1.1214e-07, -4.0787e-08,  4.1821e-08, -1.2398e-07,  1.0996e-08,\n",
            "        -5.1134e-08,  7.2494e-08, -5.8741e-08,  1.6383e-08,  6.4880e-08,\n",
            "         4.6519e-08,  9.4225e-08, -1.0349e-08,  1.9119e-09, -5.5860e-09,\n",
            "        -4.0709e-08,  5.0936e-08, -4.7618e-08, -8.2884e-10, -1.5111e-07,\n",
            "         6.3176e-08,  1.4342e-07, -4.8200e-08,  2.5226e-08,  1.3915e-07,\n",
            "         4.9868e-08,  2.9569e-08, -1.3022e-08,  1.7905e-07,  3.9083e-09,\n",
            "        -1.2499e-08,  6.5764e-08,  6.1132e-08,  4.7234e-08,  5.6361e-08,\n",
            "        -4.0575e-08, -6.3821e-08, -8.7889e-09,  1.3125e-08, -8.2456e-08,\n",
            "        -1.9991e-07,  6.3503e-08, -3.6022e-08,  1.0662e-07, -6.3278e-08,\n",
            "        -1.0168e-08,  6.5177e-08,  2.7161e-09, -5.2159e-08,  2.8172e-08,\n",
            "         5.0298e-09,  1.3044e-07,  4.8879e-08,  1.4056e-08, -8.9121e-08,\n",
            "        -3.6938e-09,  1.4992e-07, -1.5407e-08,  9.0868e-08, -1.3030e-08,\n",
            "        -3.1645e-08, -4.5132e-08, -1.7112e-09,  3.6829e-08, -4.4177e-09,\n",
            "         3.1452e-08,  6.5043e-08, -4.8078e-08, -3.3093e-08, -5.0313e-09,\n",
            "         2.2560e-08, -1.6409e-08, -7.2256e-08, -3.1179e-09,  6.7821e-09,\n",
            "         1.2585e-07, -1.2333e-07, -4.6426e-08,  1.7531e-08,  1.3343e-07,\n",
            "        -7.5154e-09, -1.7675e-08, -6.5627e-08, -1.8440e-08, -2.9923e-09,\n",
            "        -2.0783e-08,  8.8928e-08,  6.2414e-09,  4.5194e-08,  8.6244e-08,\n",
            "        -6.1819e-08,  2.3380e-08, -3.1080e-09,  2.2272e-08, -4.7820e-09,\n",
            "         2.8295e-08,  4.5285e-08,  3.0523e-08,  2.8675e-08,  2.5793e-08,\n",
            "        -3.6910e-08, -1.2764e-07, -9.0366e-08,  7.3416e-09, -3.7478e-09,\n",
            "        -4.5895e-08, -5.2667e-09,  7.8917e-08,  2.1557e-08, -9.0314e-08,\n",
            "        -3.9897e-08,  2.6901e-08, -3.5216e-08,  1.1094e-07,  5.4462e-08,\n",
            "        -6.6912e-08,  1.3834e-07,  5.6496e-09, -1.0039e-07,  5.0415e-08,\n",
            "         1.0117e-08, -2.9870e-08, -8.2155e-08,  6.1817e-08, -3.4543e-08,\n",
            "         5.4889e-08, -5.1027e-08, -2.2101e-09])\n",
            "token_encoder.transformer_encoder.layers.2.self_attn.in_proj_weight tensor([[-0.0206, -0.0443,  0.0245,  ...,  0.0695,  0.0129, -0.0172],\n",
            "        [-0.0673,  0.0118,  0.0623,  ..., -0.0257, -0.0630,  0.0006],\n",
            "        [-0.0822, -0.0750,  0.0442,  ...,  0.0833,  0.0506,  0.0207],\n",
            "        ...,\n",
            "        [-0.0057,  0.0468, -0.0918,  ...,  0.0195, -0.1040, -0.0061],\n",
            "        [ 0.0214,  0.0100, -0.0558,  ...,  0.0089, -0.0197, -0.0070],\n",
            "        [-0.0933,  0.0894,  0.0328,  ..., -0.0678,  0.0126, -0.1011]])\n",
            "token_encoder.transformer_encoder.layers.2.self_attn.in_proj_bias tensor([-1.1849e-08, -1.9309e-09, -2.0321e-09, -8.2927e-09, -5.5206e-09,\n",
            "         7.2346e-11,  8.6237e-09, -1.9634e-09,  6.9981e-09,  4.1940e-09,\n",
            "         6.6056e-09,  2.8677e-09,  4.2842e-09,  1.2600e-08, -4.5411e-09,\n",
            "         6.5091e-10, -4.5558e-09,  1.0468e-08, -2.5512e-09,  1.1385e-09,\n",
            "        -2.2827e-09,  1.0455e-08, -8.6610e-10, -9.7986e-09, -1.2825e-08,\n",
            "        -1.2316e-08, -1.0711e-08,  1.1666e-08,  1.4163e-08,  2.8230e-09,\n",
            "        -9.9402e-09, -9.4306e-09,  3.5688e-09, -2.4792e-09,  8.6867e-09,\n",
            "         3.3803e-08,  5.8205e-09, -9.0201e-09,  8.6992e-10, -3.6216e-09,\n",
            "         7.5725e-09,  1.5191e-08,  5.9789e-09, -2.1217e-08,  2.2232e-09,\n",
            "        -7.9492e-09, -1.7490e-10, -1.4048e-08,  3.6222e-08, -1.0269e-08,\n",
            "         1.6176e-09, -1.1434e-09, -6.1073e-09,  8.9916e-10,  1.2161e-08,\n",
            "         2.5956e-09,  5.7604e-09, -1.0098e-08, -8.7735e-09, -8.0021e-09,\n",
            "        -7.3218e-09, -4.4158e-09,  2.7863e-08,  3.0302e-08, -8.7039e-09,\n",
            "        -1.8629e-09, -3.2898e-09, -9.5561e-09, -7.7149e-09,  1.3129e-08,\n",
            "         1.0286e-09, -1.9388e-09, -9.1719e-09,  6.3409e-09,  1.3520e-08,\n",
            "         7.7957e-10,  2.2468e-08, -1.4724e-08, -1.2984e-08, -3.0407e-09,\n",
            "         1.0372e-08, -4.1109e-09,  1.2145e-09,  2.9365e-10, -2.1476e-08,\n",
            "         9.6530e-09, -1.0096e-08, -3.3277e-09,  5.6143e-09, -3.0840e-09,\n",
            "        -1.4705e-09,  2.8754e-09, -3.5624e-09, -4.1403e-09,  6.0248e-09,\n",
            "        -1.0618e-08, -4.4814e-09,  8.4252e-09,  5.7585e-09, -1.2223e-09,\n",
            "        -7.8893e-10,  7.4140e-09, -1.6487e-10,  3.1730e-10, -3.7142e-09,\n",
            "        -1.2660e-08,  1.9775e-08, -2.3067e-09,  6.4152e-10,  2.3662e-09,\n",
            "        -1.3185e-08, -1.0797e-09, -2.1018e-08, -6.9544e-09,  1.2837e-08,\n",
            "         2.3870e-09, -2.3952e-09, -2.4116e-09,  5.3493e-09, -5.7793e-09,\n",
            "         4.5074e-09,  5.9450e-09,  2.9606e-09,  1.2055e-09,  4.6369e-09,\n",
            "        -4.0544e-09, -4.6086e-09, -1.8460e-09,  4.8580e-16, -1.4959e-15,\n",
            "         6.0237e-18,  2.3114e-15, -1.4181e-15, -6.7748e-16,  9.3005e-16,\n",
            "        -3.5954e-16, -4.3370e-16,  1.9233e-15, -1.1374e-15, -1.8794e-15,\n",
            "        -3.2015e-15,  9.9831e-16,  5.2896e-16,  2.1738e-15, -8.8168e-16,\n",
            "        -1.6107e-15,  2.4773e-15,  1.2730e-15, -1.7093e-15, -1.3566e-15,\n",
            "         3.2077e-16,  2.0059e-15,  1.5440e-15, -1.1932e-15,  4.0626e-16,\n",
            "         9.1415e-16, -2.2275e-15, -3.3695e-16,  1.0024e-15, -1.9353e-15,\n",
            "         2.5630e-15, -3.7375e-16,  1.7507e-15,  2.8586e-16,  4.0224e-17,\n",
            "         1.1896e-15, -3.4948e-17, -5.9048e-16, -4.9458e-16, -2.3003e-15,\n",
            "        -1.2448e-15,  3.9709e-16, -3.4116e-16,  1.1123e-15, -1.1526e-15,\n",
            "         9.2717e-16,  6.9296e-16, -1.8116e-15, -2.1087e-15,  2.7031e-16,\n",
            "         1.8201e-15,  1.8091e-15,  2.1678e-15,  3.7067e-16,  2.4388e-15,\n",
            "         6.5815e-16,  3.7561e-16, -1.5176e-15,  3.9375e-16, -7.2496e-16,\n",
            "        -1.4318e-15,  2.1065e-15,  6.4584e-16,  3.6323e-15, -1.0799e-15,\n",
            "         9.4091e-16, -1.5458e-16, -6.9723e-16,  1.7295e-15,  2.0376e-15,\n",
            "         1.0002e-15, -2.0509e-15,  1.8637e-15,  2.2401e-15,  4.3761e-16,\n",
            "         1.1132e-16, -1.1101e-15,  2.2035e-16,  2.6836e-15, -1.4418e-15,\n",
            "         3.6332e-16, -3.6891e-15,  9.6950e-16, -4.9062e-16,  1.2008e-15,\n",
            "         6.7320e-16,  1.2196e-17, -2.3599e-15, -3.1330e-15, -2.4503e-15,\n",
            "         1.0889e-15,  1.0570e-15, -1.4954e-16,  2.1373e-15,  2.1782e-15,\n",
            "        -2.1828e-15,  9.8990e-16,  6.3232e-16,  1.2151e-15,  5.3179e-16,\n",
            "        -1.2608e-15,  2.9837e-16, -1.9872e-16,  8.9702e-16, -3.7934e-15,\n",
            "        -2.3685e-15,  6.3512e-16,  2.5661e-15, -1.2615e-15, -1.2050e-15,\n",
            "        -5.5107e-16,  4.5268e-15,  4.3777e-16,  2.2125e-15, -1.4258e-15,\n",
            "        -1.4081e-15, -6.6690e-16,  2.0743e-15,  1.8677e-15, -1.2145e-15,\n",
            "         1.7183e-16, -1.4139e-15,  2.2499e-15,  1.4323e-16,  1.0941e-15,\n",
            "         2.6076e-15,  1.5934e-07,  5.4736e-08,  6.4278e-08,  5.8348e-08,\n",
            "         1.7003e-07,  1.5403e-08,  1.4503e-08, -9.2204e-08,  9.2140e-08,\n",
            "         1.0297e-08, -2.9250e-08, -3.8509e-08, -2.2880e-08, -2.1497e-08,\n",
            "         4.3524e-08, -2.5648e-08,  6.2107e-08,  3.1120e-08,  2.5568e-08,\n",
            "        -4.6911e-08,  2.1039e-08, -3.4890e-08,  2.9271e-08, -1.5297e-08,\n",
            "         8.0326e-08,  1.0670e-08, -3.3021e-09,  2.2136e-08, -6.7152e-08,\n",
            "         6.3233e-08,  9.9882e-09, -2.8517e-08, -1.4347e-08,  1.1892e-08,\n",
            "        -5.7411e-08, -1.2811e-09, -2.2667e-08,  2.7860e-08, -5.3455e-08,\n",
            "         6.3137e-08,  5.9489e-08, -3.5932e-08,  1.6223e-08,  1.0826e-08,\n",
            "         4.9169e-08,  7.7027e-08,  4.9007e-08,  7.7771e-09, -6.4615e-08,\n",
            "        -4.5512e-09, -5.0003e-08,  4.4061e-08,  4.6880e-09, -1.3881e-08,\n",
            "         1.2667e-08,  2.4642e-08,  5.1815e-08, -8.6799e-08, -4.7950e-08,\n",
            "         3.8719e-09,  1.0629e-08,  9.2647e-08,  3.2653e-08,  4.2620e-08,\n",
            "         4.2234e-08, -5.5139e-08,  4.2499e-09, -1.2633e-07, -6.1903e-08,\n",
            "         3.3501e-08, -9.1761e-08, -8.7323e-08, -5.3006e-08,  4.1223e-08,\n",
            "         3.6551e-08, -8.1795e-09, -1.1197e-08,  3.1092e-09, -1.8734e-08,\n",
            "         4.4793e-08, -2.4648e-08,  4.9844e-09,  5.2772e-08, -4.8143e-08,\n",
            "         6.4712e-08, -2.0440e-08,  1.8535e-08,  6.2454e-08, -1.0812e-08,\n",
            "         1.2739e-08, -7.6729e-08,  4.4440e-08, -4.8741e-08, -7.7793e-08,\n",
            "        -7.8214e-09,  3.9079e-08,  1.2375e-08,  3.5143e-08, -7.9101e-09,\n",
            "        -2.0982e-08,  2.9154e-10,  1.3005e-08, -1.8141e-08,  3.7655e-08,\n",
            "         2.3737e-08, -2.7748e-09,  5.4634e-08, -5.3777e-08, -6.3754e-08,\n",
            "        -7.6513e-08,  1.7846e-08, -1.0619e-07, -2.8096e-08, -5.6943e-08,\n",
            "         2.5876e-08, -1.2483e-08, -5.4608e-08,  1.4692e-08, -1.9491e-08,\n",
            "         5.6950e-08,  2.3349e-08,  5.0380e-08,  3.3581e-08, -6.4643e-08,\n",
            "        -7.3652e-08,  3.2191e-08, -1.7510e-08,  5.5846e-08])\n",
            "token_encoder.transformer_encoder.layers.2.self_attn.out_proj.weight tensor([[-0.0486, -0.0551, -0.0124,  ..., -0.0738, -0.0202, -0.0112],\n",
            "        [ 0.0414, -0.0782,  0.0360,  ..., -0.0850,  0.0135, -0.0172],\n",
            "        [ 0.0421,  0.0650, -0.0834,  ...,  0.0044, -0.0079,  0.0845],\n",
            "        ...,\n",
            "        [ 0.0634,  0.0509,  0.0373,  ...,  0.0335, -0.0538,  0.0432],\n",
            "        [-0.0754,  0.0440,  0.0274,  ..., -0.0472, -0.0735, -0.0036],\n",
            "        [-0.0016,  0.0141,  0.0085,  ...,  0.0873,  0.0173, -0.0135]])\n",
            "token_encoder.transformer_encoder.layers.2.self_attn.out_proj.bias tensor([-1.1663e-07, -3.2355e-08,  1.5438e-07, -1.0480e-07, -5.5468e-08,\n",
            "         2.9635e-08,  8.7588e-08, -9.9175e-08,  5.2118e-08,  4.8915e-08,\n",
            "         1.5578e-07,  1.2745e-07, -4.0608e-08,  1.3791e-07,  1.1751e-08,\n",
            "        -4.5672e-08,  3.7241e-08,  2.2091e-08, -1.6138e-08, -2.8579e-08,\n",
            "        -5.3007e-09,  1.9597e-08, -4.0947e-09,  2.3823e-08,  4.0187e-08,\n",
            "         1.6023e-08, -2.9838e-08, -4.1636e-09,  1.4561e-07,  7.5038e-08,\n",
            "        -9.4037e-08,  5.1167e-08,  8.1824e-08,  1.6397e-08,  4.4804e-08,\n",
            "         1.7451e-08,  5.4512e-08, -1.0731e-07,  5.3585e-08, -1.5083e-07,\n",
            "        -1.6900e-07,  9.5236e-08, -3.7063e-08,  8.7946e-09, -6.6033e-08,\n",
            "        -7.8714e-08, -6.1688e-08,  1.2649e-08, -2.0182e-09,  2.6325e-08,\n",
            "        -1.5896e-08,  2.3368e-08,  7.2963e-08, -7.7972e-08,  6.7087e-08,\n",
            "         1.9636e-08,  4.6736e-08, -5.4947e-09,  2.0925e-08,  2.1331e-08,\n",
            "        -7.2630e-08,  1.1052e-08, -1.9545e-08, -2.8510e-08,  6.4326e-08,\n",
            "        -3.5742e-08, -4.4330e-09,  1.4327e-08,  2.1812e-08,  4.1540e-08,\n",
            "        -1.9954e-08, -1.5707e-09, -3.9678e-08,  9.6944e-08,  1.3881e-08,\n",
            "         4.3261e-08, -3.0580e-08, -9.6596e-08,  3.4588e-08,  7.1396e-08,\n",
            "        -2.7012e-08,  1.8836e-08, -1.0420e-07,  5.1032e-08, -8.7305e-08,\n",
            "         2.1440e-09,  1.9934e-08,  6.8129e-08,  8.0116e-08,  5.1186e-08,\n",
            "        -1.3878e-08, -8.3549e-09, -6.0126e-08,  5.3539e-09,  6.3022e-08,\n",
            "        -2.4672e-08,  1.3169e-09,  4.3895e-08, -1.0454e-08,  2.5465e-08,\n",
            "        -3.3807e-10, -6.8020e-08, -9.6212e-09,  1.0867e-08,  1.0953e-07,\n",
            "        -3.8008e-09,  1.7490e-08,  3.8661e-08, -1.7401e-08, -5.8259e-08,\n",
            "         1.7850e-08,  1.3472e-07, -8.2254e-08,  6.3231e-08, -1.9204e-08,\n",
            "        -8.8855e-08,  7.2174e-08,  6.8873e-09, -8.6782e-08,  2.5100e-08,\n",
            "         2.3955e-08, -3.5560e-08, -4.8172e-08,  3.3142e-08,  3.9402e-08,\n",
            "        -7.5315e-08, -7.1014e-08, -1.9847e-08])\n",
            "token_encoder.transformer_encoder.layers.2.linear1.weight tensor([[ 0.0571,  0.0584,  0.0481,  ...,  0.0554, -0.0860, -0.0332],\n",
            "        [ 0.0024, -0.0642,  0.0629,  ..., -0.0878, -0.0876, -0.0085],\n",
            "        [ 0.0873, -0.0248, -0.0677,  ...,  0.0376, -0.0556, -0.0844],\n",
            "        ...,\n",
            "        [ 0.0053,  0.0725,  0.0214,  ...,  0.0507,  0.0543, -0.0073],\n",
            "        [ 0.0036, -0.0372,  0.0872,  ..., -0.0674, -0.0342, -0.0129],\n",
            "        [ 0.0791, -0.0020,  0.0156,  ..., -0.0286,  0.0857, -0.0044]])\n",
            "token_encoder.transformer_encoder.layers.2.linear1.bias tensor([ 0.0805,  0.0645,  0.0708,  0.0106, -0.0359,  0.0673, -0.0490, -0.0237,\n",
            "         0.0195, -0.0361,  0.0791,  0.0427,  0.0223, -0.0784, -0.0120, -0.0044,\n",
            "        -0.0263, -0.0268,  0.0388, -0.0349, -0.0571, -0.0779,  0.0744, -0.0014,\n",
            "        -0.0707, -0.0298, -0.0130, -0.0322, -0.0586, -0.0128,  0.0657,  0.0798,\n",
            "         0.0039, -0.0071,  0.0859, -0.0371, -0.0599,  0.0559,  0.0637, -0.0581,\n",
            "        -0.0570, -0.0676,  0.0667, -0.0303,  0.0844, -0.0602, -0.0138,  0.0791,\n",
            "        -0.0372,  0.0405, -0.0669, -0.0245, -0.0285, -0.0024, -0.0158,  0.0672,\n",
            "         0.0211, -0.0673,  0.0302,  0.0424, -0.0319, -0.0602,  0.0422,  0.0574,\n",
            "        -0.0241, -0.0672,  0.0263,  0.0002,  0.0198,  0.0877,  0.0178, -0.0661,\n",
            "        -0.0291, -0.0710,  0.0253, -0.0713, -0.0027, -0.0464,  0.0098, -0.0452,\n",
            "        -0.0769, -0.0025, -0.0241, -0.0703, -0.0825, -0.0580, -0.0321,  0.0019,\n",
            "         0.0698, -0.0119, -0.0202,  0.0221, -0.0869,  0.0477,  0.0763, -0.0352,\n",
            "        -0.0746,  0.0082,  0.0038, -0.0631, -0.0570, -0.0359,  0.0495,  0.0734,\n",
            "        -0.0126,  0.0669, -0.0752,  0.0277,  0.0752,  0.0248, -0.0117, -0.0408,\n",
            "        -0.0865, -0.0594,  0.0469,  0.0095,  0.0657, -0.0172,  0.0030, -0.0626,\n",
            "        -0.0739, -0.0876,  0.0419,  0.0131, -0.0588, -0.0035,  0.0224, -0.0343])\n",
            "token_encoder.transformer_encoder.layers.2.linear2.weight tensor([[-0.0713,  0.0368, -0.0236,  ..., -0.0532, -0.0118,  0.0241],\n",
            "        [-0.0635, -0.0315,  0.0215,  ...,  0.0819, -0.0870, -0.0466],\n",
            "        [-0.0136,  0.0712, -0.0599,  ..., -0.0559,  0.0848,  0.0543],\n",
            "        ...,\n",
            "        [-0.0010,  0.0134, -0.0321,  ..., -0.0444, -0.0406, -0.0521],\n",
            "        [ 0.0315,  0.0460,  0.0526,  ...,  0.0047,  0.0208,  0.0053],\n",
            "        [-0.0515, -0.0722, -0.0596,  ..., -0.0849, -0.0783,  0.0570]])\n",
            "token_encoder.transformer_encoder.layers.2.linear2.bias tensor([-0.0820, -0.0015,  0.0034,  0.0136, -0.0244,  0.0604,  0.0073,  0.0686,\n",
            "         0.0831,  0.0744,  0.0771,  0.0610, -0.0682,  0.0684,  0.0080, -0.0440,\n",
            "        -0.0761, -0.0401, -0.0584,  0.0392, -0.0703, -0.0450, -0.0306, -0.0610,\n",
            "         0.0640, -0.0075, -0.0770,  0.0671, -0.0113, -0.0350, -0.0757, -0.0784,\n",
            "         0.0458,  0.0095,  0.0776, -0.0811, -0.0071,  0.0665,  0.0655, -0.0298,\n",
            "        -0.0187, -0.0357, -0.0604,  0.0664, -0.0678,  0.0085,  0.0139,  0.0693,\n",
            "         0.0421,  0.0077, -0.0842, -0.0052, -0.0207,  0.0685,  0.0018, -0.0827,\n",
            "        -0.0042,  0.0858, -0.0600,  0.0434,  0.0680,  0.0452,  0.0031,  0.0642,\n",
            "         0.0361,  0.0078, -0.0651,  0.0498, -0.0326, -0.0095, -0.0605, -0.0508,\n",
            "         0.0326, -0.0715,  0.0446,  0.0345, -0.0012, -0.0703, -0.0687, -0.0438,\n",
            "         0.0846,  0.0561, -0.0330, -0.0171,  0.0344, -0.0697, -0.0590,  0.0646,\n",
            "         0.0735,  0.0047, -0.0521,  0.0486, -0.0863,  0.0244, -0.0167,  0.0291,\n",
            "         0.0435, -0.0818, -0.0091,  0.0860, -0.0300, -0.0855, -0.0519, -0.0436,\n",
            "         0.0156,  0.0218,  0.0883, -0.0369,  0.0432,  0.0854, -0.0689, -0.0499,\n",
            "        -0.0711, -0.0312, -0.0014,  0.0186, -0.0610, -0.0336, -0.0861, -0.0834,\n",
            "        -0.0072,  0.0451, -0.0667,  0.0381, -0.0458, -0.0283,  0.0339, -0.0330])\n",
            "token_encoder.transformer_encoder.layers.2.norm1.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.2.norm1.bias tensor([-9.5345e-08, -2.2365e-08,  4.3853e-08, -1.3343e-07, -1.0242e-08,\n",
            "        -4.8186e-08,  9.8473e-08, -1.1413e-07,  3.5294e-09,  4.5538e-08,\n",
            "         5.4512e-08,  9.0122e-08, -8.0551e-09,  6.4051e-08, -1.4616e-08,\n",
            "        -4.4255e-08,  2.0465e-08, -6.8287e-08,  7.4238e-09, -9.3294e-08,\n",
            "         4.0936e-08,  7.3395e-08, -5.4912e-08,  3.4562e-08,  1.2070e-07,\n",
            "         2.6866e-09, -2.7316e-08, -2.6800e-08,  1.8009e-07,  4.8461e-08,\n",
            "        -9.8519e-09,  5.4403e-08,  5.0591e-08,  4.3827e-08,  4.7662e-08,\n",
            "        -5.2290e-09, -1.3679e-08, -1.2183e-07, -3.1390e-08, -1.5316e-07,\n",
            "        -2.0109e-07,  8.4718e-08,  1.0902e-08,  4.1788e-08, -4.3755e-09,\n",
            "        -5.4797e-08, -1.4061e-08,  1.1342e-08, -3.8000e-08,  5.3267e-08,\n",
            "         2.2626e-08,  1.1414e-07,  6.2197e-08, -1.5615e-08, -9.0235e-08,\n",
            "         1.1582e-08,  5.6183e-08,  2.2298e-08,  8.9974e-08,  2.4776e-08,\n",
            "        -6.9071e-08, -3.2295e-08,  3.0307e-08,  8.7369e-09,  1.5993e-08,\n",
            "        -5.3042e-08,  1.1922e-09, -5.0102e-08, -9.6344e-08, -2.8744e-08,\n",
            "         2.5274e-08, -2.6923e-09, -5.0572e-08,  4.9824e-08, -5.3267e-09,\n",
            "         7.2675e-08, -5.9553e-08, -8.9658e-08,  4.5771e-09,  8.4258e-08,\n",
            "        -4.9297e-08, -6.2957e-08, -1.0052e-07,  5.6674e-08, -1.0993e-08,\n",
            "        -5.4600e-08,  3.3546e-08,  4.8635e-08,  3.3773e-08,  3.6256e-08,\n",
            "        -9.1891e-08,  1.9270e-08, -1.8439e-09,  2.7325e-08, -1.1870e-08,\n",
            "         1.9997e-09,  5.4786e-08,  6.7349e-08, -6.7649e-08,  3.2862e-08,\n",
            "        -5.0202e-08, -1.1564e-07, -4.2014e-08,  6.1972e-08, -4.7370e-08,\n",
            "        -2.3030e-08,  2.3646e-08,  8.8068e-08,  4.1753e-09, -4.6409e-08,\n",
            "        -3.3935e-08, -8.5707e-09, -8.3111e-08,  1.3046e-07,  2.7236e-09,\n",
            "        -4.5480e-08,  1.3597e-07,  2.1864e-08, -8.7595e-08,  2.5174e-08,\n",
            "         3.8232e-08, -4.7802e-08, -4.1946e-08,  6.4058e-08, -4.4073e-08,\n",
            "         7.2714e-08, -9.9825e-08, -2.1205e-08])\n",
            "token_encoder.transformer_encoder.layers.2.norm2.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.2.norm2.bias tensor([-6.9325e-08,  1.7697e-08,  6.9593e-08, -1.1647e-07,  5.2292e-08,\n",
            "        -5.6464e-08,  7.6409e-08, -1.1805e-07, -1.3722e-09,  9.1152e-08,\n",
            "         2.1913e-08,  9.1179e-08,  1.5034e-08, -1.7112e-08, -5.7179e-09,\n",
            "        -6.9203e-08,  5.9797e-08, -5.3177e-08,  1.7637e-08, -6.6849e-08,\n",
            "         8.3432e-08,  1.1284e-07, -5.4879e-08,  1.5602e-08,  8.5306e-08,\n",
            "        -1.3524e-08, -3.3186e-08, -8.0460e-10,  2.0742e-07,  3.0709e-09,\n",
            "        -5.6608e-10,  5.7171e-08,  2.9955e-08,  6.6137e-08,  3.8792e-08,\n",
            "         7.6748e-09,  7.3866e-09, -9.1647e-08, -2.7223e-08, -1.8242e-07,\n",
            "        -2.2206e-07,  9.3562e-08, -5.3836e-09,  6.2194e-08,  1.7725e-08,\n",
            "        -4.3993e-08, -2.0066e-09,  7.0459e-08, -7.7366e-09,  2.1280e-08,\n",
            "         1.0122e-08,  1.2642e-07,  6.1106e-08,  2.8051e-08, -8.9775e-08,\n",
            "        -4.8671e-09,  5.0055e-08,  1.8034e-08,  9.7124e-08, -1.0534e-08,\n",
            "        -5.1148e-08, -4.3890e-09, -1.3329e-10,  1.2251e-08,  1.7366e-08,\n",
            "        -6.6673e-08,  5.4956e-08, -1.3186e-08, -9.0895e-08,  8.8828e-09,\n",
            "        -2.3290e-08, -4.4900e-08, -4.7821e-08,  5.7020e-08,  2.0245e-11,\n",
            "         4.5119e-08, -5.6546e-08, -6.8906e-08, -1.8795e-08,  7.0922e-08,\n",
            "        -3.5073e-08, -6.9048e-08, -9.0896e-08,  5.6644e-08,  2.2125e-08,\n",
            "        -6.7449e-08,  1.7353e-08,  3.5971e-08,  4.0304e-08,  2.1126e-08,\n",
            "        -1.1834e-07, -1.7311e-08, -1.4426e-08,  2.0706e-08,  8.3564e-09,\n",
            "         2.5855e-08,  8.3783e-08,  3.9688e-08, -4.6867e-08,  6.4334e-09,\n",
            "        -7.7487e-08, -7.0485e-08, -3.8706e-09,  9.6592e-08, -3.1343e-08,\n",
            "        -4.2364e-08,  2.4051e-08,  8.4104e-08, -2.7700e-09, -2.5509e-08,\n",
            "        -5.8686e-08, -3.1833e-08, -8.4005e-08,  1.2334e-07, -1.1550e-08,\n",
            "        -3.5566e-08,  1.0877e-07,  3.4068e-08, -9.1752e-08,  3.3605e-08,\n",
            "         7.1166e-08,  1.8666e-08, -2.6911e-08,  6.6421e-08, -8.4552e-08,\n",
            "         3.3914e-09, -3.9228e-08,  1.2586e-09])\n",
            "token_encoder.transformer_encoder.layers.3.self_attn.in_proj_weight tensor([[-0.0206, -0.0443,  0.0245,  ...,  0.0695,  0.0129, -0.0172],\n",
            "        [-0.0673,  0.0118,  0.0623,  ..., -0.0257, -0.0630,  0.0006],\n",
            "        [-0.0822, -0.0750,  0.0442,  ...,  0.0833,  0.0506,  0.0207],\n",
            "        ...,\n",
            "        [-0.0057,  0.0468, -0.0918,  ...,  0.0195, -0.1040, -0.0061],\n",
            "        [ 0.0214,  0.0100, -0.0558,  ...,  0.0089, -0.0197, -0.0070],\n",
            "        [-0.0933,  0.0894,  0.0328,  ..., -0.0678,  0.0126, -0.1011]])\n",
            "token_encoder.transformer_encoder.layers.3.self_attn.in_proj_bias tensor([-7.2404e-10, -2.7288e-09,  9.0377e-09, -1.2270e-08, -3.8099e-09,\n",
            "         1.8930e-09,  8.1045e-09,  2.2708e-09,  1.0890e-09,  4.4034e-09,\n",
            "         4.0327e-09,  2.3365e-09,  5.9997e-09, -1.1006e-08,  6.7760e-09,\n",
            "        -8.0367e-09, -3.8895e-09, -6.6621e-09,  2.1551e-09, -1.2175e-08,\n",
            "         1.1314e-08, -1.3010e-09, -9.1308e-09, -3.3794e-09, -7.1918e-09,\n",
            "        -1.2638e-08,  1.7838e-09, -8.3814e-11,  1.3678e-09,  1.0996e-09,\n",
            "         3.2389e-09,  1.0011e-08, -6.7709e-09,  2.2706e-09,  2.4117e-08,\n",
            "         3.3971e-08,  1.5652e-09, -7.6618e-09, -1.0392e-08, -4.4874e-09,\n",
            "        -1.1225e-08, -6.8348e-09, -1.0551e-09,  7.5106e-10,  5.7883e-09,\n",
            "         1.0594e-08, -1.2503e-08, -1.3827e-10,  1.2057e-08, -2.3121e-09,\n",
            "        -1.7866e-08, -1.1469e-08,  1.5507e-08,  3.5070e-09,  3.1072e-08,\n",
            "         3.7507e-09,  1.2185e-08, -1.1127e-08,  1.4918e-08, -1.7700e-08,\n",
            "         5.5721e-09,  7.9945e-10,  1.8128e-08,  1.7820e-08, -1.0732e-08,\n",
            "         4.7197e-09, -1.4806e-08, -6.0303e-09, -6.8219e-09,  9.6696e-09,\n",
            "         8.3318e-09, -2.2100e-08, -1.4608e-08, -1.0114e-08, -1.3659e-08,\n",
            "         3.0915e-09,  1.2221e-08,  4.9434e-09,  7.0148e-09,  2.0936e-08,\n",
            "        -1.1295e-08,  1.4898e-08, -2.7906e-09,  3.9891e-09, -4.2920e-09,\n",
            "        -4.7184e-09,  6.7473e-10,  2.0653e-09,  2.9500e-09, -1.3433e-08,\n",
            "         1.7484e-08, -5.3707e-09,  4.6015e-09,  1.1006e-08, -9.9933e-10,\n",
            "        -9.4575e-10, -1.2552e-08,  8.4346e-09, -1.6570e-09,  1.6901e-08,\n",
            "         1.0270e-08,  7.2120e-09,  3.1146e-09,  1.9268e-10, -2.7003e-08,\n",
            "        -4.1013e-09, -2.8240e-09, -5.4365e-09,  2.2833e-09, -3.1775e-09,\n",
            "        -2.1174e-09, -1.1691e-09, -1.3946e-08, -1.3060e-09,  2.8797e-09,\n",
            "        -6.0885e-09,  1.0945e-08,  1.0146e-08,  9.9916e-10, -5.1065e-09,\n",
            "        -3.6825e-09,  4.4779e-09, -5.0907e-09, -3.7931e-09,  4.7670e-09,\n",
            "         1.1634e-08, -4.7749e-09, -6.2906e-09,  2.2607e-15,  1.6239e-15,\n",
            "        -4.8858e-18,  3.5006e-16,  1.3393e-16, -2.0553e-16, -8.5203e-16,\n",
            "         2.2266e-15, -9.5689e-16, -1.1624e-15,  1.0558e-15,  4.1467e-15,\n",
            "         1.1753e-15, -9.0239e-16, -1.8357e-16, -6.8970e-16, -1.7397e-16,\n",
            "         1.9851e-15, -8.7223e-16, -5.7766e-17,  1.3205e-17,  1.1390e-15,\n",
            "         6.2458e-16, -5.2019e-16, -5.7040e-17,  3.0651e-15,  1.3188e-15,\n",
            "        -1.9366e-16, -9.7524e-16,  1.3254e-15,  2.3510e-15, -9.3902e-16,\n",
            "        -7.8622e-16,  1.5138e-15,  4.4714e-18, -9.7925e-16, -1.4434e-15,\n",
            "         1.2866e-15, -4.6703e-16,  2.3750e-15,  1.4135e-16, -3.4815e-16,\n",
            "         2.5588e-16, -1.6525e-15, -5.2678e-15, -1.9386e-15,  1.3619e-15,\n",
            "        -5.1489e-16,  1.8019e-16, -5.5317e-16,  4.5998e-16, -3.4237e-17,\n",
            "        -1.4960e-15, -1.5694e-15,  7.2747e-16,  1.4386e-15, -1.5393e-15,\n",
            "         2.6905e-15, -1.0591e-15,  1.7148e-15, -1.2990e-15,  3.6176e-16,\n",
            "         1.0556e-15, -2.1474e-15, -2.3089e-15, -5.6740e-15,  1.3827e-15,\n",
            "         1.6768e-15, -2.3454e-17, -9.8473e-16,  6.2212e-16, -2.6490e-15,\n",
            "        -3.7084e-15, -1.9252e-16, -2.9741e-16, -1.5140e-15,  1.1763e-16,\n",
            "         3.5954e-16,  1.0851e-15,  9.8868e-16,  7.4021e-16,  1.8975e-15,\n",
            "         2.9674e-16,  5.5965e-16, -1.9453e-15, -5.8471e-16,  9.8005e-16,\n",
            "         1.3656e-15, -7.5735e-16, -5.8696e-16, -1.4316e-15, -9.8631e-16,\n",
            "         4.4446e-16,  2.7440e-16,  1.0957e-15, -3.2013e-16, -5.1131e-16,\n",
            "        -6.4814e-16, -2.4179e-16, -2.3188e-15,  1.4406e-16,  1.5804e-15,\n",
            "         1.2454e-15,  8.3636e-16,  2.5586e-15, -6.0823e-16,  2.6166e-16,\n",
            "        -4.7566e-16,  1.5516e-15,  8.7425e-16,  1.1896e-15, -6.2406e-16,\n",
            "         5.9464e-16, -1.8574e-15, -1.2771e-15,  5.8119e-15, -8.5049e-16,\n",
            "         1.0610e-15, -6.9944e-16, -1.6205e-15, -3.3824e-15,  2.7537e-15,\n",
            "         1.5363e-15,  4.0347e-16, -1.7254e-16, -1.2603e-15, -2.3028e-15,\n",
            "        -1.4995e-15,  3.7529e-08, -4.7330e-09, -5.7058e-08, -1.4391e-08,\n",
            "         7.5144e-08, -6.8662e-08, -6.1452e-08, -5.8285e-08,  5.4767e-08,\n",
            "         1.9136e-08, -1.0410e-08,  5.0040e-08, -2.1611e-08, -5.5468e-08,\n",
            "         7.5761e-08,  4.6943e-08,  9.2519e-08,  4.0512e-09, -3.5415e-08,\n",
            "        -4.5602e-08, -5.2071e-08, -2.2267e-08, -7.2039e-08,  2.7904e-08,\n",
            "         4.5083e-08, -7.6138e-10, -1.7460e-08,  6.5171e-08, -4.7886e-08,\n",
            "         3.1018e-08, -3.2760e-08, -1.4813e-08,  2.2883e-08,  4.5926e-08,\n",
            "         5.7932e-08,  2.3450e-08,  3.9780e-08, -1.1375e-08,  1.1350e-08,\n",
            "        -6.0894e-09, -1.6473e-08, -4.0444e-09,  2.7990e-08,  4.5299e-09,\n",
            "         6.0547e-08, -8.9954e-09, -7.3142e-09,  6.9498e-09, -1.9074e-09,\n",
            "        -1.1385e-08, -4.1066e-08,  3.4729e-08, -1.9350e-08, -4.6431e-08,\n",
            "         1.8844e-08,  4.6693e-08,  5.7334e-08,  4.7989e-08, -4.2868e-08,\n",
            "        -1.3092e-08, -8.8644e-09,  2.8713e-08,  7.1672e-08, -2.4725e-08,\n",
            "         1.3616e-09,  4.0341e-08, -5.4935e-08,  2.8557e-08, -9.8255e-08,\n",
            "         3.4943e-08, -3.2492e-09,  6.6295e-08, -7.2854e-09,  7.9006e-09,\n",
            "         3.7623e-08,  4.2041e-08, -2.7865e-08,  2.8969e-08, -5.3995e-08,\n",
            "        -4.1489e-08, -4.4916e-08, -4.9996e-08, -2.6544e-08, -2.6093e-08,\n",
            "         6.4388e-08,  2.7883e-09, -8.9404e-09,  1.4183e-08,  1.8241e-08,\n",
            "         4.1962e-08, -1.0922e-07,  3.3596e-08,  3.2983e-08,  8.1507e-09,\n",
            "         5.2958e-09,  1.6785e-08, -4.6730e-08,  5.5889e-09, -4.0838e-08,\n",
            "         5.3818e-09, -5.8920e-08,  1.8150e-08,  5.2070e-08,  4.5783e-08,\n",
            "         2.0400e-08, -6.7314e-08, -1.4201e-08,  2.3221e-08, -7.0782e-08,\n",
            "        -1.6919e-08, -4.8950e-08, -4.1074e-08,  6.8086e-09, -4.5467e-08,\n",
            "         5.0559e-08, -6.5988e-08, -9.8712e-09,  1.8837e-08,  8.6953e-09,\n",
            "         3.1669e-08,  2.6542e-08,  1.1321e-08,  5.9056e-08, -3.4195e-08,\n",
            "         3.0364e-08,  5.5847e-08, -6.0556e-08,  6.5365e-08])\n",
            "token_encoder.transformer_encoder.layers.3.self_attn.out_proj.weight tensor([[-0.0486, -0.0551, -0.0124,  ..., -0.0738, -0.0202, -0.0112],\n",
            "        [ 0.0414, -0.0782,  0.0360,  ..., -0.0850,  0.0135, -0.0172],\n",
            "        [ 0.0421,  0.0650, -0.0834,  ...,  0.0044, -0.0079,  0.0845],\n",
            "        ...,\n",
            "        [ 0.0634,  0.0509,  0.0373,  ...,  0.0335, -0.0538,  0.0432],\n",
            "        [-0.0754,  0.0440,  0.0274,  ..., -0.0472, -0.0735, -0.0036],\n",
            "        [-0.0016,  0.0141,  0.0085,  ...,  0.0873,  0.0173, -0.0135]])\n",
            "token_encoder.transformer_encoder.layers.3.self_attn.out_proj.bias tensor([-6.1821e-08,  5.9404e-09,  3.8425e-08, -4.8420e-08,  2.3139e-08,\n",
            "        -4.5226e-09,  2.6795e-08, -1.3009e-07, -3.6743e-08, -1.2939e-08,\n",
            "        -3.8065e-08,  4.2518e-08, -1.9029e-08, -9.1946e-08,  8.9537e-08,\n",
            "        -7.9678e-08,  3.1138e-08,  7.8396e-09, -8.9289e-09,  1.0397e-08,\n",
            "         3.3866e-08,  2.5665e-08, -3.8523e-08,  4.5885e-08,  4.1811e-08,\n",
            "         1.4340e-08,  4.2587e-08, -9.3131e-10,  1.1417e-07,  7.5369e-08,\n",
            "        -8.0223e-09,  7.3250e-09,  1.8307e-08,  1.3434e-07, -3.5730e-08,\n",
            "         7.3216e-09,  1.0384e-07, -1.1911e-07, -1.0179e-09, -1.1422e-07,\n",
            "        -1.0103e-07,  1.2092e-07,  4.3216e-08,  5.2872e-08,  7.9436e-08,\n",
            "        -5.0214e-08, -3.6154e-08,  8.4387e-08,  1.2067e-08, -1.1476e-07,\n",
            "         2.7523e-08,  2.0260e-07, -3.7085e-09,  9.9755e-08, -7.4806e-08,\n",
            "         2.2250e-08,  6.3307e-08, -6.5927e-09,  7.0094e-08,  4.7074e-08,\n",
            "        -6.1829e-08, -8.8176e-08,  5.1050e-08, -9.0667e-09,  2.9017e-08,\n",
            "        -1.8376e-08,  3.8620e-08, -8.0627e-10, -9.1381e-08, -4.8568e-08,\n",
            "        -4.2437e-08,  1.1036e-08,  1.6914e-08,  7.9061e-08,  4.3847e-08,\n",
            "        -4.1525e-08, -3.0775e-08, -5.9646e-08, -4.9530e-09, -1.4145e-08,\n",
            "         2.1937e-08, -9.1008e-08, -4.5481e-08,  1.2111e-08,  2.9301e-08,\n",
            "        -1.6313e-07, -8.6070e-08, -7.7287e-08,  8.5923e-08, -2.7733e-08,\n",
            "        -5.1067e-08, -9.6623e-08,  5.6187e-08, -2.4822e-08,  6.9764e-08,\n",
            "         8.8775e-09,  6.6439e-09, -6.4525e-08,  1.2789e-08,  1.1366e-07,\n",
            "        -3.6308e-08, -1.0921e-07,  2.5098e-08,  3.3747e-08,  3.2340e-08,\n",
            "        -5.3205e-08, -7.7608e-08,  1.7940e-08,  8.9142e-09,  5.2761e-08,\n",
            "        -7.7026e-08, -6.5346e-08, -2.9371e-08,  1.4151e-07, -3.3211e-08,\n",
            "        -6.1654e-08,  1.1284e-07,  3.5854e-08, -1.4347e-07,  6.4304e-08,\n",
            "         6.9599e-08, -5.9157e-08,  1.1407e-08,  6.9977e-08, -7.0836e-08,\n",
            "        -2.2868e-07, -4.0149e-08, -6.0179e-08])\n",
            "token_encoder.transformer_encoder.layers.3.linear1.weight tensor([[ 0.0571,  0.0584,  0.0481,  ...,  0.0554, -0.0860, -0.0332],\n",
            "        [ 0.0024, -0.0642,  0.0629,  ..., -0.0878, -0.0876, -0.0085],\n",
            "        [ 0.0873, -0.0248, -0.0677,  ...,  0.0376, -0.0556, -0.0844],\n",
            "        ...,\n",
            "        [ 0.0053,  0.0725,  0.0214,  ...,  0.0507,  0.0543, -0.0073],\n",
            "        [ 0.0036, -0.0372,  0.0872,  ..., -0.0674, -0.0342, -0.0129],\n",
            "        [ 0.0791, -0.0020,  0.0156,  ..., -0.0286,  0.0857, -0.0044]])\n",
            "token_encoder.transformer_encoder.layers.3.linear1.bias tensor([ 0.0805,  0.0645,  0.0708,  0.0106, -0.0359,  0.0673, -0.0490, -0.0237,\n",
            "         0.0195, -0.0361,  0.0791,  0.0427,  0.0223, -0.0784, -0.0120, -0.0044,\n",
            "        -0.0263, -0.0268,  0.0388, -0.0349, -0.0571, -0.0779,  0.0744, -0.0014,\n",
            "        -0.0707, -0.0298, -0.0130, -0.0322, -0.0586, -0.0128,  0.0657,  0.0798,\n",
            "         0.0039, -0.0071,  0.0859, -0.0371, -0.0599,  0.0559,  0.0637, -0.0581,\n",
            "        -0.0570, -0.0676,  0.0667, -0.0303,  0.0844, -0.0602, -0.0138,  0.0791,\n",
            "        -0.0372,  0.0405, -0.0669, -0.0245, -0.0285, -0.0024, -0.0158,  0.0672,\n",
            "         0.0211, -0.0673,  0.0302,  0.0424, -0.0319, -0.0602,  0.0422,  0.0574,\n",
            "        -0.0241, -0.0672,  0.0263,  0.0002,  0.0198,  0.0877,  0.0178, -0.0661,\n",
            "        -0.0291, -0.0710,  0.0253, -0.0713, -0.0027, -0.0464,  0.0098, -0.0452,\n",
            "        -0.0769, -0.0025, -0.0241, -0.0703, -0.0825, -0.0580, -0.0321,  0.0019,\n",
            "         0.0698, -0.0119, -0.0202,  0.0221, -0.0869,  0.0477,  0.0763, -0.0352,\n",
            "        -0.0746,  0.0082,  0.0038, -0.0631, -0.0570, -0.0359,  0.0495,  0.0734,\n",
            "        -0.0126,  0.0669, -0.0752,  0.0277,  0.0752,  0.0248, -0.0117, -0.0408,\n",
            "        -0.0865, -0.0594,  0.0469,  0.0095,  0.0657, -0.0172,  0.0030, -0.0626,\n",
            "        -0.0739, -0.0876,  0.0419,  0.0131, -0.0588, -0.0035,  0.0224, -0.0343])\n",
            "token_encoder.transformer_encoder.layers.3.linear2.weight tensor([[-0.0713,  0.0368, -0.0236,  ..., -0.0532, -0.0118,  0.0241],\n",
            "        [-0.0635, -0.0315,  0.0215,  ...,  0.0819, -0.0870, -0.0466],\n",
            "        [-0.0136,  0.0712, -0.0599,  ..., -0.0559,  0.0848,  0.0543],\n",
            "        ...,\n",
            "        [-0.0010,  0.0134, -0.0321,  ..., -0.0444, -0.0406, -0.0521],\n",
            "        [ 0.0315,  0.0460,  0.0526,  ...,  0.0047,  0.0208,  0.0053],\n",
            "        [-0.0515, -0.0722, -0.0596,  ..., -0.0849, -0.0783,  0.0570]])\n",
            "token_encoder.transformer_encoder.layers.3.linear2.bias tensor([-0.0820, -0.0015,  0.0034,  0.0136, -0.0244,  0.0604,  0.0073,  0.0686,\n",
            "         0.0831,  0.0744,  0.0771,  0.0610, -0.0682,  0.0684,  0.0080, -0.0440,\n",
            "        -0.0761, -0.0401, -0.0584,  0.0392, -0.0703, -0.0450, -0.0306, -0.0610,\n",
            "         0.0640, -0.0075, -0.0770,  0.0671, -0.0113, -0.0350, -0.0757, -0.0784,\n",
            "         0.0458,  0.0095,  0.0776, -0.0811, -0.0071,  0.0665,  0.0655, -0.0298,\n",
            "        -0.0187, -0.0357, -0.0604,  0.0664, -0.0678,  0.0085,  0.0139,  0.0693,\n",
            "         0.0421,  0.0077, -0.0842, -0.0052, -0.0207,  0.0685,  0.0018, -0.0827,\n",
            "        -0.0042,  0.0858, -0.0600,  0.0434,  0.0680,  0.0452,  0.0031,  0.0642,\n",
            "         0.0361,  0.0078, -0.0651,  0.0498, -0.0326, -0.0095, -0.0605, -0.0508,\n",
            "         0.0326, -0.0715,  0.0446,  0.0345, -0.0012, -0.0703, -0.0687, -0.0438,\n",
            "         0.0846,  0.0561, -0.0330, -0.0171,  0.0344, -0.0697, -0.0590,  0.0646,\n",
            "         0.0735,  0.0047, -0.0521,  0.0486, -0.0863,  0.0244, -0.0167,  0.0291,\n",
            "         0.0435, -0.0818, -0.0091,  0.0860, -0.0300, -0.0855, -0.0519, -0.0436,\n",
            "         0.0156,  0.0218,  0.0883, -0.0369,  0.0432,  0.0854, -0.0689, -0.0499,\n",
            "        -0.0711, -0.0312, -0.0014,  0.0186, -0.0610, -0.0336, -0.0861, -0.0834,\n",
            "        -0.0072,  0.0451, -0.0667,  0.0381, -0.0458, -0.0283,  0.0339, -0.0330])\n",
            "token_encoder.transformer_encoder.layers.3.norm1.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.3.norm1.bias tensor([-1.0528e-07,  5.9443e-08,  9.7930e-08, -8.2700e-08,  3.6396e-08,\n",
            "        -3.9908e-08,  6.2730e-08, -1.1611e-07,  2.1499e-08,  9.7158e-08,\n",
            "        -4.0306e-08,  5.8744e-08,  2.0341e-08, -6.2454e-08, -2.2213e-08,\n",
            "        -6.6970e-08,  3.4589e-08, -1.9197e-08, -8.4448e-09, -1.5785e-08,\n",
            "         1.0713e-08,  9.3639e-08, -6.5448e-08,  2.4492e-08,  4.9265e-08,\n",
            "         8.1287e-09, -1.8826e-08, -2.2060e-08,  1.8371e-07,  7.2882e-09,\n",
            "         4.0015e-08,  3.7754e-08, -2.1620e-08,  7.0565e-08,  6.6714e-09,\n",
            "         7.7459e-09, -2.1949e-10, -1.4774e-07, -2.9703e-08, -2.2386e-07,\n",
            "        -1.8190e-07,  1.0510e-07,  3.2007e-08,  3.3966e-08,  6.4260e-08,\n",
            "        -3.8496e-08, -2.0284e-08,  8.7990e-08,  1.1596e-08,  3.2110e-08,\n",
            "         1.4054e-09,  1.8518e-07,  7.7342e-08,  2.3588e-08, -7.5282e-08,\n",
            "        -5.1705e-08,  7.5968e-08, -3.7224e-10,  1.3970e-07,  1.7045e-08,\n",
            "        -5.4640e-08,  2.5892e-08, -1.2484e-08,  1.4843e-08,  6.1238e-08,\n",
            "        -5.5279e-08,  8.7589e-08, -9.1874e-09, -7.7983e-08, -1.8749e-08,\n",
            "        -3.9309e-08, -7.8091e-08, -2.1903e-08,  9.0322e-08,  2.8864e-08,\n",
            "         1.3527e-08,  4.4380e-09, -9.9583e-08, -8.8222e-09,  5.7123e-08,\n",
            "         8.7927e-09, -2.8094e-08, -3.1416e-08,  6.4610e-08,  2.2386e-08,\n",
            "        -6.4100e-08, -2.2150e-08,  2.5306e-08,  6.2842e-08, -1.4094e-08,\n",
            "        -8.1129e-08, -2.7351e-08, -2.4625e-08,  2.7843e-08,  1.2404e-08,\n",
            "         1.9687e-08,  1.1792e-07,  1.1997e-09, -2.9647e-08,  3.6350e-08,\n",
            "        -2.5361e-08, -1.3375e-07,  1.1393e-08,  6.0963e-08, -5.6105e-08,\n",
            "        -8.3844e-08, -5.1000e-08,  6.4531e-08, -4.9785e-08, -5.2234e-10,\n",
            "        -1.0400e-07, -3.2796e-08, -1.2122e-07,  1.2532e-07, -3.8883e-08,\n",
            "        -2.0665e-08,  1.4353e-07,  5.0907e-08, -1.2686e-07,  5.3324e-08,\n",
            "         9.1773e-08, -5.1572e-09,  2.9557e-08,  7.6121e-08, -9.8651e-08,\n",
            "         5.5638e-08, -3.4830e-08,  1.2159e-08])\n",
            "token_encoder.transformer_encoder.layers.3.norm2.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.3.norm2.bias tensor([-1.1785e-07,  3.7879e-08,  1.0592e-07, -5.3112e-08, -2.0421e-08,\n",
            "        -1.7170e-08, -6.5651e-09, -1.2517e-07,  3.5987e-08,  7.1044e-08,\n",
            "        -2.4497e-08,  5.0008e-08, -4.0558e-08, -6.4518e-08, -1.1110e-09,\n",
            "        -8.0565e-09,  3.3321e-08, -5.7340e-08,  5.1903e-09,  3.7511e-10,\n",
            "        -1.8739e-08,  9.3337e-08, -9.4440e-08,  1.0873e-08,  3.6076e-08,\n",
            "        -3.4298e-08, -4.1370e-08, -2.1881e-08,  1.6789e-07,  2.2293e-08,\n",
            "        -1.7104e-10,  7.5307e-08,  3.7981e-08,  5.8849e-08,  7.5722e-08,\n",
            "         2.8713e-09, -4.5797e-09, -9.4013e-08, -2.3333e-09, -1.9011e-07,\n",
            "        -1.8278e-07,  8.5023e-08,  4.9652e-08,  1.7444e-08,  5.5388e-08,\n",
            "         1.2013e-08,  2.7456e-08,  5.9894e-08,  7.6709e-09,  7.6928e-09,\n",
            "        -3.5443e-08,  1.5808e-07,  7.4156e-08,  2.8660e-08, -2.9896e-08,\n",
            "        -1.0230e-07,  4.8400e-08, -4.0719e-08,  1.0853e-07,  2.3225e-08,\n",
            "        -1.3315e-08,  4.3086e-08, -7.7277e-09,  6.0200e-08,  2.9688e-08,\n",
            "        -3.6954e-08,  4.8229e-08,  2.9589e-08, -6.2426e-08,  7.8629e-10,\n",
            "        -4.0958e-08, -2.0249e-08,  3.6582e-08,  3.9050e-08,  2.2062e-08,\n",
            "         2.0543e-09,  2.1250e-08, -1.0191e-07, -3.6886e-08,  4.6070e-08,\n",
            "         4.6780e-08, -5.4965e-08, -2.4898e-09,  4.5164e-08,  7.8624e-08,\n",
            "        -7.4132e-08, -2.6443e-08,  3.5927e-08,  6.1077e-08,  2.3825e-08,\n",
            "        -7.0334e-08, -3.3520e-08, -2.5999e-08,  1.5397e-08,  1.5829e-08,\n",
            "         2.5952e-08,  1.5591e-07,  1.9630e-08, -4.1441e-08, -2.3980e-09,\n",
            "        -6.5150e-08, -1.2321e-07,  1.9368e-08,  2.7466e-08, -4.3402e-08,\n",
            "        -6.9133e-08, -1.7881e-08,  4.1329e-08, -3.0338e-08,  6.7743e-09,\n",
            "        -1.2809e-07, -1.3460e-08, -1.0554e-07,  1.4934e-07, -2.8367e-08,\n",
            "        -5.6695e-08,  1.8553e-07,  1.7989e-08, -1.2122e-07,  8.0101e-08,\n",
            "         8.5245e-08,  2.5374e-08,  3.4291e-08,  3.6426e-08, -1.0084e-07,\n",
            "         7.7993e-08,  1.3649e-08,  3.8537e-08])\n",
            "token_encoder.transformer_encoder.layers.4.self_attn.in_proj_weight tensor([[-0.0206, -0.0443,  0.0245,  ...,  0.0695,  0.0129, -0.0172],\n",
            "        [-0.0673,  0.0118,  0.0623,  ..., -0.0257, -0.0630,  0.0006],\n",
            "        [-0.0822, -0.0750,  0.0442,  ...,  0.0833,  0.0506,  0.0207],\n",
            "        ...,\n",
            "        [-0.0057,  0.0468, -0.0918,  ...,  0.0195, -0.1040, -0.0061],\n",
            "        [ 0.0214,  0.0100, -0.0558,  ...,  0.0089, -0.0197, -0.0070],\n",
            "        [-0.0933,  0.0894,  0.0328,  ..., -0.0678,  0.0126, -0.1011]])\n",
            "token_encoder.transformer_encoder.layers.4.self_attn.in_proj_bias tensor([ 2.6520e-09,  1.4446e-08,  3.7528e-09,  1.1990e-09,  3.1743e-09,\n",
            "         2.6031e-09, -2.9002e-09,  5.3397e-09,  1.9974e-08, -7.6554e-09,\n",
            "        -8.6172e-09, -9.5149e-09, -6.7513e-09, -9.6933e-09,  4.4873e-09,\n",
            "         5.3919e-09, -6.6040e-09, -2.1665e-08, -4.8176e-09,  2.7346e-09,\n",
            "        -4.7869e-10,  1.3422e-08, -3.8014e-09, -9.1307e-09, -2.1113e-09,\n",
            "        -1.8865e-08, -1.3236e-08, -2.2706e-08,  9.5632e-09,  1.1290e-08,\n",
            "         9.0470e-09,  1.3023e-08,  1.0668e-08, -3.7783e-09,  2.5532e-08,\n",
            "         2.5025e-08, -7.9822e-09,  1.7872e-08, -2.4051e-08, -5.4571e-09,\n",
            "         1.2595e-08, -1.8348e-08, -1.6839e-08, -1.8534e-08, -2.4489e-09,\n",
            "        -1.3923e-08,  2.5470e-09,  1.0519e-08,  1.6820e-08,  5.4920e-09,\n",
            "        -1.1848e-09,  6.2411e-09, -5.7420e-09,  1.4367e-09,  1.7058e-08,\n",
            "         7.8694e-09,  3.6807e-09, -2.3302e-09,  1.1631e-08, -1.6982e-08,\n",
            "        -1.0414e-08,  4.0646e-09,  9.8019e-09,  1.3029e-09, -1.2834e-08,\n",
            "         9.0525e-09,  1.1103e-08,  4.3202e-09, -3.6195e-09,  1.8146e-09,\n",
            "         1.5338e-08, -2.3222e-09, -5.0769e-09, -5.6052e-10,  1.6504e-09,\n",
            "         2.7037e-09, -3.3637e-09,  1.9224e-08,  2.1538e-08,  3.2825e-09,\n",
            "        -7.0009e-10,  1.3310e-08, -1.0337e-08, -4.7930e-09,  1.0153e-08,\n",
            "         5.5394e-09,  3.4859e-09, -1.1201e-08,  1.7780e-09, -1.2513e-08,\n",
            "         2.2482e-09, -6.3486e-09,  4.5838e-09, -6.8368e-10, -7.7880e-09,\n",
            "         2.7706e-09, -2.6849e-09,  1.0681e-08, -6.8051e-10, -6.9969e-09,\n",
            "        -6.2024e-09,  3.6479e-09, -2.4046e-09, -7.3243e-09, -6.8334e-09,\n",
            "        -2.9245e-09, -1.9188e-09,  3.4865e-09,  6.8676e-09,  5.1378e-09,\n",
            "         2.2263e-09,  2.0605e-09, -7.2177e-09, -6.9707e-09,  7.0221e-09,\n",
            "        -3.6220e-09,  2.5528e-09, -1.3656e-09,  2.5259e-09, -1.3455e-08,\n",
            "         4.4686e-09, -4.2800e-09, -4.7108e-09, -9.8957e-10,  1.2388e-08,\n",
            "         1.6732e-09, -3.8524e-09,  6.3306e-10,  2.8103e-15, -2.2882e-15,\n",
            "         1.3063e-15,  4.6896e-15, -3.0310e-16,  7.3383e-16, -1.3406e-15,\n",
            "         1.1129e-15,  2.3752e-15, -5.6873e-16,  4.8521e-16,  1.3731e-15,\n",
            "         1.4646e-15, -2.8597e-16,  1.6379e-16, -2.4821e-16, -1.5297e-15,\n",
            "        -3.5153e-16, -1.2162e-15,  1.1448e-15,  1.5819e-16,  1.5041e-15,\n",
            "        -1.2980e-15, -6.5576e-16,  2.4390e-15, -1.2253e-15, -1.4458e-16,\n",
            "        -1.5646e-15,  3.3389e-15, -6.3250e-16, -5.5915e-16, -2.2551e-15,\n",
            "         7.5390e-16,  1.3085e-15,  2.1310e-16,  1.6650e-15,  2.9008e-17,\n",
            "         4.1022e-16, -8.9633e-16, -4.1357e-16,  1.2888e-15, -1.6702e-15,\n",
            "         2.4141e-16, -1.0591e-15, -7.3307e-16,  8.8650e-16,  9.7330e-16,\n",
            "         3.5769e-16,  1.0301e-15,  8.7297e-16,  1.4185e-16, -2.4790e-16,\n",
            "         3.3298e-15,  6.2332e-17,  3.9440e-16, -1.0876e-15, -9.0069e-16,\n",
            "         7.5695e-16, -1.4476e-16, -1.9554e-16, -6.2619e-16, -3.6400e-16,\n",
            "        -8.2244e-16,  8.2389e-16, -1.0017e-15,  4.3204e-15,  6.5146e-16,\n",
            "         4.1319e-16, -9.7736e-16,  9.3764e-16,  2.0768e-16,  2.6000e-15,\n",
            "         2.2159e-15, -1.9653e-15, -8.8795e-16,  2.8852e-16,  2.7199e-15,\n",
            "         2.6407e-15, -1.5018e-15,  4.7138e-16,  5.8027e-16,  1.6458e-15,\n",
            "        -1.6206e-15,  1.1561e-15,  6.3988e-16,  1.0404e-15,  6.1200e-16,\n",
            "        -3.3573e-16,  1.2547e-15,  7.4369e-16,  1.2431e-15,  1.0674e-15,\n",
            "        -1.0675e-15, -1.2319e-15,  8.3293e-16,  1.6663e-16,  1.8620e-16,\n",
            "        -3.9805e-15,  2.0908e-15,  2.0200e-15,  1.9185e-15,  1.6047e-15,\n",
            "         8.5021e-16,  4.2573e-16, -5.5693e-16,  6.4874e-16, -4.5807e-16,\n",
            "         1.5919e-15, -2.2267e-15, -1.2213e-15,  2.2860e-15, -2.0136e-15,\n",
            "         9.4655e-16, -5.9717e-17,  2.8307e-15, -4.0524e-15,  9.2101e-16,\n",
            "         3.3302e-16,  1.9103e-15, -9.8792e-16, -1.1368e-15, -2.3463e-16,\n",
            "         1.6276e-15, -1.4191e-15, -9.7357e-16,  1.3262e-15, -1.8304e-15,\n",
            "         4.1574e-16, -2.5456e-08,  4.4865e-08, -7.4392e-09, -1.7964e-08,\n",
            "        -1.7123e-08,  1.5179e-08,  7.5527e-09,  1.7895e-08, -2.1338e-08,\n",
            "        -3.8585e-08,  1.1334e-08, -2.6605e-08,  6.4632e-08, -2.1347e-08,\n",
            "         5.9040e-08, -5.0272e-10, -5.3817e-08,  5.8966e-09,  1.5800e-08,\n",
            "        -5.3817e-09, -2.5062e-08, -1.6229e-08, -1.2693e-08, -1.3507e-08,\n",
            "        -8.1384e-09, -3.3898e-08,  2.1226e-08, -4.2016e-08, -3.1419e-08,\n",
            "        -1.7235e-08,  1.6070e-08, -1.3510e-08, -7.5295e-08,  4.7307e-08,\n",
            "        -1.1553e-07,  2.1325e-08, -4.2721e-08, -2.5084e-08,  2.9212e-08,\n",
            "         6.3822e-08, -1.7296e-08,  8.0655e-08,  3.3929e-08, -6.2076e-08,\n",
            "        -8.0805e-08,  1.1033e-08, -8.7693e-08, -9.2277e-08, -2.6046e-08,\n",
            "        -4.2531e-08, -4.4384e-08,  3.5386e-08, -6.0014e-08, -4.2870e-08,\n",
            "         1.5748e-08,  8.8592e-09,  1.5337e-08, -4.6412e-08,  1.7019e-08,\n",
            "         3.9256e-08,  1.9410e-08,  7.6296e-08,  6.3956e-08,  3.2428e-08,\n",
            "         1.1749e-08,  1.9589e-08,  9.4518e-08,  1.7849e-09, -1.2475e-08,\n",
            "         2.9340e-08, -4.3502e-08, -2.7157e-08, -5.4881e-08,  2.2870e-08,\n",
            "         7.4104e-08, -5.0047e-08, -2.1402e-08,  1.5227e-08,  1.3305e-08,\n",
            "        -1.8468e-08, -3.4604e-08,  5.3245e-09,  2.4810e-08, -6.4131e-08,\n",
            "         2.6536e-08, -6.8349e-08, -1.9771e-08,  3.4191e-08, -4.6311e-08,\n",
            "         7.9641e-08, -4.9151e-08, -6.3292e-08,  2.2731e-08,  2.8870e-08,\n",
            "         2.3084e-08,  8.7580e-09,  5.4772e-09,  3.5854e-09, -1.1203e-07,\n",
            "        -2.6617e-08, -1.2022e-07, -5.7783e-08,  2.6168e-08, -3.5282e-08,\n",
            "         2.4444e-08, -4.6102e-09, -1.2202e-08,  4.9448e-08, -1.7915e-08,\n",
            "        -7.8097e-08, -7.9367e-08,  2.7262e-08,  1.0442e-08,  4.0642e-08,\n",
            "        -1.4496e-08,  1.9112e-08, -1.1234e-08,  9.4799e-09, -1.8478e-08,\n",
            "         6.4485e-08,  3.2077e-08,  2.9518e-08,  7.5779e-08, -1.5432e-07,\n",
            "        -7.2097e-08, -1.0682e-07, -5.0882e-08,  1.4977e-07])\n",
            "token_encoder.transformer_encoder.layers.4.self_attn.out_proj.weight tensor([[-0.0486, -0.0551, -0.0124,  ..., -0.0738, -0.0202, -0.0112],\n",
            "        [ 0.0414, -0.0782,  0.0360,  ..., -0.0850,  0.0135, -0.0172],\n",
            "        [ 0.0421,  0.0650, -0.0834,  ...,  0.0044, -0.0079,  0.0845],\n",
            "        ...,\n",
            "        [ 0.0634,  0.0509,  0.0373,  ...,  0.0335, -0.0538,  0.0432],\n",
            "        [-0.0754,  0.0440,  0.0274,  ..., -0.0472, -0.0735, -0.0036],\n",
            "        [-0.0016,  0.0141,  0.0085,  ...,  0.0873,  0.0173, -0.0135]])\n",
            "token_encoder.transformer_encoder.layers.4.self_attn.out_proj.bias tensor([-7.3455e-08,  6.5910e-10,  5.7331e-08, -8.6804e-08, -2.0232e-08,\n",
            "        -3.4009e-08,  7.7127e-08, -1.6985e-07,  5.1604e-08,  2.1791e-08,\n",
            "        -6.8223e-08,  1.3735e-08,  6.2648e-08, -2.8231e-08, -1.4731e-08,\n",
            "         7.1056e-09, -1.3194e-08, -4.6072e-08, -3.2436e-08, -5.8175e-08,\n",
            "        -3.7223e-08,  4.9439e-08, -1.2770e-07,  7.5093e-08,  4.9345e-08,\n",
            "        -2.9145e-08, -2.6821e-08, -3.5909e-08,  1.4906e-07, -7.0127e-08,\n",
            "        -2.5351e-10,  8.4944e-09,  1.7413e-09,  7.1528e-08,  3.8354e-08,\n",
            "         1.4986e-09, -1.4408e-08, -7.4210e-08,  2.6431e-08, -1.9909e-08,\n",
            "        -2.1054e-07,  5.5478e-08, -7.4802e-08,  1.9150e-08,  4.8117e-08,\n",
            "        -3.9023e-09,  1.1187e-07,  1.4099e-08,  2.1654e-07, -5.0242e-08,\n",
            "        -7.5590e-09,  4.9021e-08,  2.0674e-08, -9.0032e-08, -9.9169e-08,\n",
            "         6.5678e-09,  9.2419e-08,  4.6611e-08,  1.1517e-07, -5.1071e-08,\n",
            "        -7.9327e-09,  6.1242e-08,  4.1684e-08, -6.8014e-08,  5.7651e-08,\n",
            "        -9.3441e-08, -2.3512e-08,  3.1970e-08, -1.8303e-07, -3.2965e-09,\n",
            "        -4.9199e-08, -9.9983e-08,  3.1323e-09,  4.1829e-08,  1.2870e-08,\n",
            "        -1.3021e-07,  5.7146e-09, -4.6046e-08,  3.9967e-08,  1.4700e-08,\n",
            "        -1.7621e-08, -1.6426e-08,  6.4245e-08, -2.1086e-08,  1.9632e-08,\n",
            "        -2.0663e-07, -5.1804e-08,  5.7407e-08,  4.1511e-08, -1.1467e-08,\n",
            "        -1.0939e-08, -9.2477e-08, -1.2720e-07, -3.5864e-08,  3.7217e-08,\n",
            "        -2.0607e-08, -2.0391e-08, -1.4294e-08, -1.3320e-07, -5.7738e-08,\n",
            "        -3.2360e-08, -6.9241e-08,  6.2151e-08,  9.1030e-08,  4.8609e-08,\n",
            "         2.8788e-09, -2.5268e-08, -1.2124e-09, -7.5005e-08,  4.1061e-08,\n",
            "        -1.3497e-07, -3.5352e-08, -5.5651e-09,  6.4353e-08,  5.2424e-08,\n",
            "        -7.3518e-08,  5.9759e-08,  5.8932e-08, -2.6214e-08,  3.9160e-08,\n",
            "         5.3807e-08, -4.9809e-09,  9.1410e-08,  5.7209e-08, -5.5984e-08,\n",
            "         1.7961e-07,  9.3372e-09,  4.5508e-08])\n",
            "token_encoder.transformer_encoder.layers.4.linear1.weight tensor([[ 0.0571,  0.0584,  0.0481,  ...,  0.0554, -0.0860, -0.0332],\n",
            "        [ 0.0024, -0.0642,  0.0629,  ..., -0.0878, -0.0876, -0.0085],\n",
            "        [ 0.0873, -0.0248, -0.0677,  ...,  0.0376, -0.0556, -0.0844],\n",
            "        ...,\n",
            "        [ 0.0053,  0.0725,  0.0214,  ...,  0.0507,  0.0543, -0.0073],\n",
            "        [ 0.0036, -0.0372,  0.0872,  ..., -0.0674, -0.0342, -0.0129],\n",
            "        [ 0.0791, -0.0020,  0.0156,  ..., -0.0286,  0.0857, -0.0044]])\n",
            "token_encoder.transformer_encoder.layers.4.linear1.bias tensor([ 0.0805,  0.0645,  0.0708,  0.0106, -0.0359,  0.0673, -0.0490, -0.0237,\n",
            "         0.0195, -0.0361,  0.0791,  0.0427,  0.0223, -0.0784, -0.0120, -0.0044,\n",
            "        -0.0263, -0.0268,  0.0388, -0.0349, -0.0571, -0.0779,  0.0744, -0.0014,\n",
            "        -0.0707, -0.0298, -0.0130, -0.0322, -0.0586, -0.0128,  0.0657,  0.0798,\n",
            "         0.0039, -0.0071,  0.0859, -0.0371, -0.0599,  0.0559,  0.0637, -0.0581,\n",
            "        -0.0570, -0.0676,  0.0667, -0.0303,  0.0844, -0.0602, -0.0138,  0.0791,\n",
            "        -0.0372,  0.0405, -0.0669, -0.0245, -0.0285, -0.0024, -0.0158,  0.0672,\n",
            "         0.0211, -0.0673,  0.0302,  0.0424, -0.0319, -0.0602,  0.0422,  0.0574,\n",
            "        -0.0241, -0.0672,  0.0263,  0.0002,  0.0198,  0.0877,  0.0178, -0.0661,\n",
            "        -0.0291, -0.0710,  0.0253, -0.0713, -0.0027, -0.0464,  0.0098, -0.0452,\n",
            "        -0.0769, -0.0025, -0.0241, -0.0703, -0.0825, -0.0580, -0.0321,  0.0019,\n",
            "         0.0698, -0.0119, -0.0202,  0.0221, -0.0869,  0.0477,  0.0763, -0.0352,\n",
            "        -0.0746,  0.0082,  0.0038, -0.0631, -0.0570, -0.0359,  0.0495,  0.0734,\n",
            "        -0.0126,  0.0669, -0.0752,  0.0277,  0.0752,  0.0248, -0.0117, -0.0408,\n",
            "        -0.0865, -0.0594,  0.0469,  0.0095,  0.0657, -0.0172,  0.0030, -0.0626,\n",
            "        -0.0739, -0.0876,  0.0419,  0.0131, -0.0588, -0.0035,  0.0224, -0.0343])\n",
            "token_encoder.transformer_encoder.layers.4.linear2.weight tensor([[-0.0713,  0.0368, -0.0236,  ..., -0.0532, -0.0118,  0.0241],\n",
            "        [-0.0635, -0.0315,  0.0215,  ...,  0.0819, -0.0870, -0.0466],\n",
            "        [-0.0136,  0.0712, -0.0599,  ..., -0.0559,  0.0848,  0.0543],\n",
            "        ...,\n",
            "        [-0.0010,  0.0134, -0.0321,  ..., -0.0444, -0.0406, -0.0521],\n",
            "        [ 0.0315,  0.0460,  0.0526,  ...,  0.0047,  0.0208,  0.0053],\n",
            "        [-0.0515, -0.0722, -0.0596,  ..., -0.0849, -0.0783,  0.0570]])\n",
            "token_encoder.transformer_encoder.layers.4.linear2.bias tensor([-0.0820, -0.0015,  0.0034,  0.0136, -0.0244,  0.0604,  0.0073,  0.0686,\n",
            "         0.0831,  0.0744,  0.0771,  0.0610, -0.0682,  0.0684,  0.0080, -0.0440,\n",
            "        -0.0761, -0.0401, -0.0584,  0.0392, -0.0703, -0.0450, -0.0306, -0.0610,\n",
            "         0.0640, -0.0075, -0.0770,  0.0671, -0.0113, -0.0350, -0.0757, -0.0784,\n",
            "         0.0458,  0.0095,  0.0776, -0.0811, -0.0071,  0.0665,  0.0655, -0.0298,\n",
            "        -0.0187, -0.0357, -0.0604,  0.0664, -0.0678,  0.0085,  0.0139,  0.0693,\n",
            "         0.0421,  0.0077, -0.0842, -0.0052, -0.0207,  0.0685,  0.0018, -0.0827,\n",
            "        -0.0042,  0.0858, -0.0600,  0.0434,  0.0680,  0.0452,  0.0031,  0.0642,\n",
            "         0.0361,  0.0078, -0.0651,  0.0498, -0.0326, -0.0095, -0.0605, -0.0508,\n",
            "         0.0326, -0.0715,  0.0446,  0.0345, -0.0012, -0.0703, -0.0687, -0.0438,\n",
            "         0.0846,  0.0561, -0.0330, -0.0171,  0.0344, -0.0697, -0.0590,  0.0646,\n",
            "         0.0735,  0.0047, -0.0521,  0.0486, -0.0863,  0.0244, -0.0167,  0.0291,\n",
            "         0.0435, -0.0818, -0.0091,  0.0860, -0.0300, -0.0855, -0.0519, -0.0436,\n",
            "         0.0156,  0.0218,  0.0883, -0.0369,  0.0432,  0.0854, -0.0689, -0.0499,\n",
            "        -0.0711, -0.0312, -0.0014,  0.0186, -0.0610, -0.0336, -0.0861, -0.0834,\n",
            "        -0.0072,  0.0451, -0.0667,  0.0381, -0.0458, -0.0283,  0.0339, -0.0330])\n",
            "token_encoder.transformer_encoder.layers.4.norm1.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.4.norm1.bias tensor([-8.2497e-08, -1.0580e-08,  3.4228e-08, -9.3111e-08, -2.9712e-08,\n",
            "        -2.8095e-08,  1.0237e-08, -1.1502e-07,  7.0545e-08,  4.9282e-08,\n",
            "        -6.3514e-08,  3.2818e-08, -2.8547e-08, -2.9460e-08, -4.8092e-08,\n",
            "        -3.2728e-08,  3.1104e-09, -8.3920e-08, -3.2767e-08, -4.8916e-08,\n",
            "        -1.6698e-08,  6.3214e-08, -5.1032e-08,  2.7224e-08,  6.3502e-08,\n",
            "        -9.9195e-08, -2.6849e-08,  2.2598e-09,  1.5692e-07, -9.6719e-09,\n",
            "        -2.9744e-09,  2.3476e-08,  4.2034e-08,  5.9702e-08,  4.5414e-08,\n",
            "         7.4250e-09,  1.1275e-08, -8.0811e-08, -2.7943e-08, -1.3103e-07,\n",
            "        -1.0743e-07,  4.6655e-08, -9.5708e-10,  1.3401e-08,  2.0325e-08,\n",
            "         1.4033e-08,  1.7119e-08,  2.5719e-08,  2.5470e-08,  1.7256e-08,\n",
            "        -1.3907e-08,  8.4980e-08,  7.9751e-08,  1.7617e-08, -1.6932e-08,\n",
            "        -5.6996e-08,  4.1401e-08,  1.8869e-08,  9.9320e-08, -3.2169e-08,\n",
            "        -1.7703e-08,  1.8054e-09,  1.0109e-08,  3.8199e-08,  6.5585e-08,\n",
            "        -9.3175e-08,  3.5179e-09,  4.2075e-08, -1.6952e-08,  3.1360e-08,\n",
            "        -6.7609e-08, -5.0472e-08, -5.1759e-08,  3.4249e-08,  1.0245e-08,\n",
            "        -3.9070e-08,  1.8662e-08, -9.8388e-08, -2.3658e-08,  7.8720e-08,\n",
            "        -4.5090e-09, -3.0372e-08,  3.1409e-09,  6.4956e-08,  2.6795e-08,\n",
            "        -8.4955e-08, -8.8833e-09,  5.4779e-08,  5.3004e-08,  5.1642e-09,\n",
            "        -6.1972e-08, -6.5988e-08, -6.3603e-08,  2.5264e-08,  5.0512e-09,\n",
            "        -2.3478e-08,  1.2790e-07,  3.6491e-08, -1.5553e-08,  1.2518e-08,\n",
            "        -1.5071e-08, -5.5487e-08,  2.8482e-08,  9.8326e-08, -3.8547e-08,\n",
            "        -4.1787e-08, -3.1973e-08, -5.7866e-08, -5.0119e-09,  5.7957e-08,\n",
            "        -1.5013e-07, -4.7197e-08, -8.8998e-08,  8.9391e-08,  2.4912e-08,\n",
            "        -7.1952e-08,  1.0499e-07,  5.3956e-08, -8.2754e-08,  5.7517e-08,\n",
            "         7.4225e-08, -3.2154e-08,  3.6204e-08,  4.5396e-08, -8.7994e-08,\n",
            "         5.4110e-08,  2.1823e-08,  8.2899e-08])\n",
            "token_encoder.transformer_encoder.layers.4.norm2.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.4.norm2.bias tensor([-6.4705e-08, -1.6942e-08,  2.7356e-08, -7.1443e-08, -3.6665e-08,\n",
            "        -4.4941e-08, -8.4689e-09, -1.0086e-07,  4.1501e-08,  1.1035e-08,\n",
            "        -2.1889e-08,  3.2415e-08, -3.1698e-08, -2.3409e-08, -1.7869e-08,\n",
            "        -2.2005e-08,  6.4891e-09, -8.4863e-08, -3.1997e-08, -3.2876e-08,\n",
            "        -1.1097e-08,  7.5212e-08, -5.2303e-08, -3.1979e-08,  5.2871e-08,\n",
            "        -4.9066e-08, -4.6946e-09,  7.2715e-09,  1.2746e-07, -4.9672e-08,\n",
            "        -6.3099e-08,  3.4608e-08,  8.2284e-08,  4.2822e-09,  6.3311e-08,\n",
            "        -9.3892e-09,  1.0537e-08, -3.1450e-08, -3.6565e-08, -7.2262e-08,\n",
            "        -1.1587e-07,  4.5269e-08, -3.0176e-08,  4.6349e-08,  4.5590e-08,\n",
            "         1.8377e-08,  1.4193e-08,  4.5166e-08,  9.0380e-10,  2.7031e-08,\n",
            "        -6.4192e-09,  5.4178e-08,  4.3746e-08,  4.0319e-08, -3.3304e-08,\n",
            "        -5.3721e-08, -6.8455e-10, -2.2963e-08,  7.9422e-08, -4.0722e-08,\n",
            "         2.8796e-08, -2.8617e-08,  4.0873e-08,  2.1563e-08,  2.0903e-08,\n",
            "        -6.7315e-08, -2.8227e-09,  2.9822e-08, -5.1958e-08,  4.8060e-08,\n",
            "        -7.5390e-08, -7.5192e-09, -4.7733e-08,  3.2937e-08, -1.6504e-08,\n",
            "        -3.4546e-08,  1.0138e-08, -5.8614e-08, -1.4750e-08,  6.9536e-08,\n",
            "         2.3191e-08, -1.6942e-08, -3.7373e-08, -6.6139e-09,  6.4544e-08,\n",
            "        -8.3983e-08, -2.1255e-08,  7.4990e-08,  3.8237e-08,  3.1619e-08,\n",
            "        -7.0931e-08, -2.2997e-08, -6.0920e-08, -8.3344e-09,  2.5993e-08,\n",
            "         3.2024e-08,  1.4671e-07,  2.7262e-08, -2.6232e-08, -1.6737e-08,\n",
            "        -1.5051e-08, -7.3107e-08,  4.5858e-08,  7.2899e-08, -2.0464e-08,\n",
            "        -1.7533e-08, -4.8908e-08, -7.4284e-08,  1.2436e-08,  7.9077e-08,\n",
            "        -1.2760e-07, -1.7040e-08, -7.7243e-08,  4.9690e-08, -4.9590e-09,\n",
            "        -6.9735e-08,  1.1169e-07,  8.0722e-09, -6.4913e-08,  1.5201e-08,\n",
            "         7.1091e-08, -4.5169e-09,  4.3241e-08,  1.6414e-08, -8.6135e-08,\n",
            "         4.4802e-08,  1.7550e-08,  5.0989e-08])\n",
            "token_encoder.transformer_encoder.layers.5.self_attn.in_proj_weight tensor([[-0.0206, -0.0443,  0.0245,  ...,  0.0695,  0.0129, -0.0172],\n",
            "        [-0.0673,  0.0118,  0.0623,  ..., -0.0257, -0.0630,  0.0006],\n",
            "        [-0.0822, -0.0750,  0.0442,  ...,  0.0833,  0.0506,  0.0207],\n",
            "        ...,\n",
            "        [-0.0057,  0.0468, -0.0918,  ...,  0.0195, -0.1040, -0.0061],\n",
            "        [ 0.0214,  0.0100, -0.0558,  ...,  0.0089, -0.0197, -0.0070],\n",
            "        [-0.0933,  0.0894,  0.0328,  ..., -0.0678,  0.0126, -0.1011]])\n",
            "token_encoder.transformer_encoder.layers.5.self_attn.in_proj_bias tensor([ 6.2630e-09, -4.5516e-10,  1.0362e-08,  9.1543e-09, -8.1872e-09,\n",
            "         7.2652e-09,  1.2004e-08, -7.3925e-09, -3.8769e-09,  7.2214e-09,\n",
            "         2.1319e-08,  1.9468e-09, -2.2039e-09,  2.8491e-09,  4.2698e-09,\n",
            "         1.4021e-08,  1.1583e-08, -2.0885e-08,  6.7455e-09, -1.2010e-08,\n",
            "        -8.3349e-09,  2.8888e-08, -9.7410e-09, -1.1752e-09,  2.1369e-08,\n",
            "        -3.7118e-08, -6.4473e-09, -7.8776e-09, -3.1121e-09,  1.1721e-09,\n",
            "         4.8179e-09, -1.1061e-08,  6.7472e-09, -3.2964e-09,  4.7038e-09,\n",
            "         2.3565e-09,  3.9692e-10,  1.9888e-09, -9.5512e-09,  6.3519e-09,\n",
            "        -2.1390e-08, -6.1927e-09, -9.6984e-09, -1.3446e-08,  8.9288e-09,\n",
            "        -1.4531e-08,  1.2279e-08,  1.1596e-08,  4.1583e-09,  1.1761e-08,\n",
            "         6.6980e-09,  1.6198e-09, -7.6659e-09,  6.9491e-09,  7.8901e-09,\n",
            "         2.5674e-10,  1.8399e-09, -1.1222e-08, -5.2254e-10, -3.7351e-09,\n",
            "         4.8241e-09,  1.1039e-08,  1.1961e-10, -6.2363e-09, -1.4876e-08,\n",
            "         1.0940e-08, -9.6026e-09,  6.1052e-10,  1.1842e-08,  4.4838e-09,\n",
            "         3.4305e-09,  6.6262e-09, -2.2580e-08, -4.9182e-09,  9.6456e-09,\n",
            "        -3.9517e-09, -1.3137e-08, -3.1681e-09, -9.9230e-09, -1.2775e-08,\n",
            "         5.3095e-09,  1.2730e-08, -4.7183e-09, -1.9610e-08,  2.1166e-08,\n",
            "        -8.2176e-09,  7.2223e-09, -2.0778e-08, -1.0698e-08,  7.1127e-09,\n",
            "        -6.0033e-09, -9.2845e-09,  2.5766e-09, -4.7457e-09, -6.7293e-09,\n",
            "         2.3712e-08, -2.3756e-09, -1.1289e-08,  1.2889e-08,  5.4144e-11,\n",
            "        -1.3662e-08, -7.4777e-09,  2.3479e-09,  1.1687e-08, -1.7805e-09,\n",
            "         9.2075e-10, -2.0789e-09, -1.3547e-08, -6.6612e-09, -7.3285e-09,\n",
            "         1.4006e-10,  5.3371e-09, -1.2336e-08, -3.1755e-09, -4.2787e-09,\n",
            "        -4.5900e-10, -1.0176e-08,  5.4415e-09,  6.8129e-09,  4.5203e-09,\n",
            "        -8.2800e-09, -3.1336e-09,  6.9179e-09,  2.8825e-09,  1.7968e-09,\n",
            "         1.1156e-09, -3.0084e-10,  6.4534e-09, -1.7842e-15,  1.1352e-15,\n",
            "         9.9383e-16, -3.3455e-15, -4.5724e-16, -8.8313e-16, -2.2940e-15,\n",
            "        -9.4265e-16, -2.0151e-15,  1.5830e-16, -6.0278e-16, -5.5656e-16,\n",
            "        -2.2505e-15,  4.9898e-16,  1.7386e-15,  2.4424e-15,  2.0683e-15,\n",
            "         2.3559e-16,  3.0672e-15,  9.9660e-16, -9.6889e-16,  1.8541e-15,\n",
            "        -2.2280e-15, -1.8114e-15,  1.2768e-15,  6.7046e-16, -2.2928e-15,\n",
            "        -8.4462e-18,  2.5276e-15, -3.4509e-15, -8.1190e-16,  4.5375e-15,\n",
            "         2.0996e-15, -1.0783e-14,  1.2625e-15,  8.3561e-16,  7.2380e-16,\n",
            "        -1.3488e-17,  2.1549e-15,  7.9895e-16,  1.1847e-15, -8.0247e-17,\n",
            "        -2.5873e-15, -5.4187e-16, -3.1443e-15,  1.4729e-15, -2.0294e-15,\n",
            "        -3.2667e-15,  1.1065e-16, -2.3139e-15,  2.0375e-15, -4.3834e-16,\n",
            "         1.7183e-15,  4.6723e-16,  1.3314e-15,  3.6777e-16,  3.4883e-16,\n",
            "        -3.8182e-16,  1.2559e-15,  3.0272e-16, -1.3611e-15,  1.8417e-15,\n",
            "         7.6114e-16, -1.3942e-15, -1.4247e-15,  2.3047e-15,  7.6866e-16,\n",
            "        -6.2912e-16, -2.0364e-15,  1.5326e-15, -6.6013e-16, -1.9985e-15,\n",
            "         1.0417e-15, -6.5762e-15, -9.4349e-16, -7.2276e-16,  1.1793e-15,\n",
            "         2.9614e-15, -7.4021e-16,  2.0055e-15, -2.5474e-15,  3.4285e-15,\n",
            "        -3.4926e-15, -8.7861e-16,  3.1752e-15,  7.0152e-16,  7.6615e-16,\n",
            "        -2.6130e-15,  1.0923e-15, -9.9470e-16,  3.0962e-15,  1.0460e-15,\n",
            "         4.0386e-16,  2.1320e-15,  1.0522e-15, -3.8526e-16, -1.9006e-17,\n",
            "        -1.8368e-16,  3.1120e-15, -9.3151e-16, -1.1641e-15, -8.1738e-16,\n",
            "        -1.1742e-16, -1.1235e-15, -1.9693e-15,  2.5457e-15,  1.0666e-15,\n",
            "         1.0052e-15,  1.1003e-16, -1.4127e-15, -2.2840e-15, -1.3036e-16,\n",
            "         1.5279e-15, -6.1851e-16, -8.8821e-16,  9.6657e-16,  3.1521e-16,\n",
            "         4.1268e-16, -1.5844e-15,  3.1904e-16,  6.1213e-16, -8.1951e-16,\n",
            "        -1.0114e-15,  7.0086e-16, -2.1808e-15, -1.1186e-15, -1.2921e-16,\n",
            "         2.2740e-16, -4.9463e-08,  7.6306e-08, -1.3380e-08, -6.5502e-08,\n",
            "         5.9714e-08, -1.5291e-08, -5.1111e-08,  5.7849e-08, -3.7463e-08,\n",
            "         1.7542e-10,  5.4054e-08,  2.2298e-08,  1.5228e-08,  3.8002e-08,\n",
            "         7.0277e-08,  3.4587e-08,  3.1703e-08,  2.9774e-08,  5.3614e-08,\n",
            "         1.9482e-08, -2.0295e-08, -3.7679e-08, -4.5228e-08,  2.6472e-08,\n",
            "         4.6244e-08,  1.7805e-08,  7.6538e-08, -1.6770e-08, -1.5993e-08,\n",
            "         5.4930e-08,  5.2974e-09, -7.9025e-09,  4.9935e-08,  3.4296e-08,\n",
            "        -2.7211e-08, -2.1967e-08,  1.1753e-08, -6.6350e-08, -1.8131e-08,\n",
            "         6.7852e-08,  4.0243e-08, -4.2740e-09,  6.6770e-08,  6.2385e-08,\n",
            "         2.9660e-08, -1.6118e-08, -2.9262e-08,  4.1869e-08, -4.4400e-08,\n",
            "        -7.8381e-08,  1.1083e-08,  9.4641e-08,  1.0503e-09,  6.9624e-09,\n",
            "        -4.3095e-08,  1.4327e-08,  8.7345e-08, -2.7234e-08, -6.4505e-09,\n",
            "         5.6788e-08,  8.2767e-08, -7.2827e-09, -2.4736e-09, -7.6945e-08,\n",
            "         1.1993e-08,  6.7015e-08, -7.1918e-09,  1.2898e-08,  6.1771e-08,\n",
            "         1.3955e-08, -2.9735e-08,  5.9321e-08, -4.4609e-08,  2.5954e-08,\n",
            "         3.8326e-08, -4.9402e-08, -1.4196e-08, -2.2604e-09, -3.6164e-09,\n",
            "        -4.2357e-08, -2.5994e-08, -4.3283e-09, -1.7294e-08, -8.6982e-08,\n",
            "         3.4079e-08, -2.0747e-08, -4.3189e-08, -1.0088e-08, -6.1165e-09,\n",
            "         8.1068e-08, -9.7030e-08, -1.2321e-08, -4.0712e-10, -4.4740e-08,\n",
            "        -2.9623e-08,  1.7824e-08,  3.1275e-09,  1.2782e-08, -3.3243e-08,\n",
            "        -1.5334e-08, -3.6029e-08,  3.0623e-08,  1.5427e-08, -2.7129e-08,\n",
            "         5.2059e-08, -2.2362e-08,  5.2610e-08,  6.8935e-08, -3.6508e-08,\n",
            "        -5.8404e-08, -8.0045e-08,  4.3417e-08, -5.9246e-08,  3.3881e-08,\n",
            "         2.5863e-08,  1.5988e-08, -5.4615e-08,  3.4316e-08, -5.4468e-08,\n",
            "        -3.7204e-08,  5.7801e-08,  9.8432e-09,  2.0319e-08, -1.4154e-08,\n",
            "        -3.7675e-08,  4.2984e-08,  3.3557e-08,  7.4841e-08])\n",
            "token_encoder.transformer_encoder.layers.5.self_attn.out_proj.weight tensor([[-0.0486, -0.0551, -0.0124,  ..., -0.0738, -0.0202, -0.0112],\n",
            "        [ 0.0414, -0.0782,  0.0360,  ..., -0.0850,  0.0135, -0.0172],\n",
            "        [ 0.0421,  0.0650, -0.0834,  ...,  0.0044, -0.0079,  0.0845],\n",
            "        ...,\n",
            "        [ 0.0634,  0.0509,  0.0373,  ...,  0.0335, -0.0538,  0.0432],\n",
            "        [-0.0754,  0.0440,  0.0274,  ..., -0.0472, -0.0735, -0.0036],\n",
            "        [-0.0016,  0.0141,  0.0085,  ...,  0.0873,  0.0173, -0.0135]])\n",
            "token_encoder.transformer_encoder.layers.5.self_attn.out_proj.bias tensor([ 1.1459e-08, -2.8508e-08,  1.2628e-07, -2.5430e-08, -4.3476e-08,\n",
            "         1.0330e-08,  2.9134e-08, -7.2354e-08,  1.0412e-08,  3.4661e-08,\n",
            "        -1.4712e-07,  2.0660e-08,  3.2020e-08, -4.8442e-09,  1.9211e-08,\n",
            "        -5.4977e-08, -5.9568e-08,  4.8121e-08,  2.4052e-08, -8.3995e-09,\n",
            "        -3.0352e-08, -3.1595e-08,  4.3531e-08,  7.2865e-08,  1.5681e-08,\n",
            "        -1.8121e-07, -2.7541e-09, -2.3239e-08,  4.9676e-08, -3.1254e-08,\n",
            "         6.2358e-09,  7.3520e-08,  8.3024e-08,  5.4608e-08,  1.0377e-07,\n",
            "        -2.0241e-08, -1.8766e-08, -1.4656e-08,  1.4447e-08,  4.0362e-09,\n",
            "        -9.7305e-08,  4.2869e-08,  4.1238e-09,  2.0338e-09,  1.3285e-08,\n",
            "         2.9561e-08,  6.0921e-08,  1.2829e-08, -7.9772e-08, -1.4276e-08,\n",
            "         1.0173e-07, -3.1396e-08,  5.8864e-08,  1.1465e-07, -1.1031e-08,\n",
            "         2.1076e-07, -7.3341e-08,  5.0467e-09,  5.8655e-08, -5.8330e-08,\n",
            "        -1.3524e-08,  1.2121e-08,  3.9313e-09,  8.9764e-08,  7.9230e-08,\n",
            "         1.5440e-08, -1.8739e-08, -1.1550e-07, -7.5825e-09,  5.4819e-08,\n",
            "        -1.1057e-08, -3.4836e-08,  2.9224e-09, -1.0166e-08,  2.0419e-09,\n",
            "        -1.1142e-07,  8.7908e-09, -3.3860e-09, -1.7380e-08,  8.4580e-08,\n",
            "        -1.2620e-08,  2.3989e-08,  2.7048e-09,  5.0944e-08, -1.9173e-08,\n",
            "        -8.5891e-08,  5.1287e-08,  4.5829e-08,  4.6727e-08,  7.1646e-08,\n",
            "        -1.0513e-08, -1.9768e-08, -6.2928e-08,  7.5835e-08, -3.2540e-08,\n",
            "         1.5832e-08,  5.7856e-08,  3.1757e-08, -2.4055e-10,  1.8525e-07,\n",
            "         5.0801e-08, -1.6328e-08,  3.1181e-08,  8.7933e-08,  5.5414e-08,\n",
            "        -1.9741e-08, -2.8140e-08,  1.5344e-09, -1.8267e-07,  3.9605e-09,\n",
            "        -3.3911e-08,  1.0684e-07,  1.1174e-08,  2.9020e-08, -4.2338e-08,\n",
            "        -4.3316e-08, -4.7539e-08,  1.8978e-09, -4.6178e-08, -2.8674e-08,\n",
            "         3.9740e-08, -2.0292e-07, -1.8217e-08,  1.2705e-07, -8.5646e-08,\n",
            "         1.1949e-08,  3.5018e-09,  2.8947e-08])\n",
            "token_encoder.transformer_encoder.layers.5.linear1.weight tensor([[ 0.0571,  0.0584,  0.0481,  ...,  0.0554, -0.0860, -0.0332],\n",
            "        [ 0.0024, -0.0642,  0.0629,  ..., -0.0878, -0.0876, -0.0085],\n",
            "        [ 0.0873, -0.0248, -0.0677,  ...,  0.0376, -0.0556, -0.0844],\n",
            "        ...,\n",
            "        [ 0.0053,  0.0725,  0.0214,  ...,  0.0507,  0.0543, -0.0073],\n",
            "        [ 0.0036, -0.0372,  0.0872,  ..., -0.0674, -0.0342, -0.0129],\n",
            "        [ 0.0791, -0.0020,  0.0156,  ..., -0.0286,  0.0857, -0.0044]])\n",
            "token_encoder.transformer_encoder.layers.5.linear1.bias tensor([ 0.0805,  0.0645,  0.0708,  0.0106, -0.0359,  0.0673, -0.0490, -0.0237,\n",
            "         0.0195, -0.0361,  0.0791,  0.0427,  0.0223, -0.0784, -0.0120, -0.0044,\n",
            "        -0.0263, -0.0268,  0.0388, -0.0349, -0.0571, -0.0779,  0.0744, -0.0014,\n",
            "        -0.0707, -0.0298, -0.0130, -0.0322, -0.0586, -0.0128,  0.0657,  0.0798,\n",
            "         0.0039, -0.0071,  0.0859, -0.0371, -0.0599,  0.0559,  0.0637, -0.0581,\n",
            "        -0.0570, -0.0676,  0.0667, -0.0303,  0.0844, -0.0602, -0.0138,  0.0791,\n",
            "        -0.0372,  0.0405, -0.0669, -0.0245, -0.0285, -0.0024, -0.0158,  0.0672,\n",
            "         0.0211, -0.0673,  0.0302,  0.0424, -0.0319, -0.0602,  0.0422,  0.0574,\n",
            "        -0.0241, -0.0672,  0.0263,  0.0002,  0.0198,  0.0877,  0.0178, -0.0661,\n",
            "        -0.0291, -0.0710,  0.0253, -0.0713, -0.0027, -0.0464,  0.0098, -0.0452,\n",
            "        -0.0769, -0.0025, -0.0241, -0.0703, -0.0825, -0.0580, -0.0321,  0.0019,\n",
            "         0.0698, -0.0119, -0.0202,  0.0221, -0.0869,  0.0477,  0.0763, -0.0352,\n",
            "        -0.0746,  0.0082,  0.0038, -0.0631, -0.0570, -0.0359,  0.0495,  0.0734,\n",
            "        -0.0126,  0.0669, -0.0752,  0.0277,  0.0752,  0.0248, -0.0117, -0.0408,\n",
            "        -0.0865, -0.0594,  0.0469,  0.0095,  0.0657, -0.0172,  0.0030, -0.0626,\n",
            "        -0.0739, -0.0876,  0.0419,  0.0131, -0.0588, -0.0035,  0.0224, -0.0343])\n",
            "token_encoder.transformer_encoder.layers.5.linear2.weight tensor([[-0.0713,  0.0368, -0.0236,  ..., -0.0532, -0.0118,  0.0241],\n",
            "        [-0.0635, -0.0315,  0.0215,  ...,  0.0819, -0.0870, -0.0466],\n",
            "        [-0.0136,  0.0712, -0.0599,  ..., -0.0559,  0.0848,  0.0543],\n",
            "        ...,\n",
            "        [-0.0010,  0.0134, -0.0321,  ..., -0.0444, -0.0406, -0.0521],\n",
            "        [ 0.0315,  0.0460,  0.0526,  ...,  0.0047,  0.0208,  0.0053],\n",
            "        [-0.0515, -0.0722, -0.0596,  ..., -0.0849, -0.0783,  0.0570]])\n",
            "token_encoder.transformer_encoder.layers.5.linear2.bias tensor([-0.0820, -0.0015,  0.0034,  0.0136, -0.0244,  0.0604,  0.0073,  0.0686,\n",
            "         0.0831,  0.0744,  0.0771,  0.0610, -0.0682,  0.0684,  0.0080, -0.0440,\n",
            "        -0.0761, -0.0401, -0.0584,  0.0392, -0.0703, -0.0450, -0.0306, -0.0610,\n",
            "         0.0640, -0.0075, -0.0770,  0.0671, -0.0113, -0.0350, -0.0757, -0.0784,\n",
            "         0.0458,  0.0095,  0.0776, -0.0811, -0.0071,  0.0665,  0.0655, -0.0298,\n",
            "        -0.0187, -0.0357, -0.0604,  0.0664, -0.0678,  0.0085,  0.0139,  0.0693,\n",
            "         0.0421,  0.0077, -0.0842, -0.0052, -0.0207,  0.0685,  0.0018, -0.0827,\n",
            "        -0.0042,  0.0858, -0.0600,  0.0434,  0.0680,  0.0452,  0.0031,  0.0642,\n",
            "         0.0361,  0.0078, -0.0651,  0.0498, -0.0326, -0.0095, -0.0605, -0.0508,\n",
            "         0.0326, -0.0715,  0.0446,  0.0345, -0.0012, -0.0703, -0.0687, -0.0438,\n",
            "         0.0846,  0.0561, -0.0330, -0.0171,  0.0344, -0.0697, -0.0590,  0.0646,\n",
            "         0.0735,  0.0047, -0.0521,  0.0486, -0.0863,  0.0244, -0.0167,  0.0291,\n",
            "         0.0435, -0.0818, -0.0091,  0.0860, -0.0300, -0.0855, -0.0519, -0.0436,\n",
            "         0.0156,  0.0218,  0.0883, -0.0369,  0.0432,  0.0854, -0.0689, -0.0499,\n",
            "        -0.0711, -0.0312, -0.0014,  0.0186, -0.0610, -0.0336, -0.0861, -0.0834,\n",
            "        -0.0072,  0.0451, -0.0667,  0.0381, -0.0458, -0.0283,  0.0339, -0.0330])\n",
            "token_encoder.transformer_encoder.layers.5.norm1.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.5.norm1.bias tensor([-2.2288e-08, -7.0211e-08, -1.7101e-08, -7.4011e-08, -2.0448e-08,\n",
            "        -3.1819e-08, -1.2633e-08, -6.7879e-08, -5.7472e-09, -3.2634e-08,\n",
            "        -7.4167e-08,  3.7362e-08,  2.2573e-08, -2.9532e-08,  3.6242e-08,\n",
            "        -2.6649e-08, -9.6288e-09, -1.3633e-08, -2.8426e-08, -6.2678e-09,\n",
            "        -7.5633e-09,  4.5577e-08, -4.5142e-08, -4.6080e-09,  2.3558e-10,\n",
            "        -5.7118e-08,  7.9540e-08,  9.6998e-09,  6.8770e-08,  9.3939e-09,\n",
            "         1.2149e-08, -5.4242e-09,  8.3738e-08,  8.7944e-08,  6.8632e-08,\n",
            "        -7.8647e-08, -9.7453e-09,  3.2029e-09, -3.3120e-08, -6.2234e-08,\n",
            "        -7.8097e-08,  1.8321e-08, -4.9345e-08,  9.0434e-08,  1.9590e-08,\n",
            "         2.6336e-08,  3.8417e-08,  6.8468e-08,  4.1228e-08,  3.3977e-08,\n",
            "        -9.0632e-09,  1.7524e-08,  5.0220e-08,  6.6123e-08,  3.1753e-08,\n",
            "        -3.6164e-08, -3.9547e-08,  4.1315e-08,  6.7218e-08, -3.8268e-08,\n",
            "        -1.2696e-08, -2.2957e-08,  4.4298e-08,  4.5693e-08,  4.6169e-08,\n",
            "        -9.0187e-09, -9.2344e-09, -1.8838e-08,  3.3305e-08,  3.2490e-08,\n",
            "        -4.8144e-08, -4.6868e-08, -2.5557e-08,  4.1771e-08, -2.1202e-08,\n",
            "         1.6668e-09,  1.3003e-08, -2.3377e-08,  8.5176e-09,  1.2856e-07,\n",
            "         1.2454e-08,  3.9346e-08,  1.8458e-08,  3.5725e-08,  3.1404e-08,\n",
            "        -5.6000e-08, -2.7914e-08,  6.3043e-08,  7.1254e-08,  4.0037e-08,\n",
            "        -6.0534e-08, -6.3224e-08, -2.9241e-08,  2.3795e-08,  7.5262e-09,\n",
            "         2.0016e-08,  1.1739e-07,  2.7456e-08, -2.4181e-08,  7.9575e-08,\n",
            "         5.5895e-08, -5.7103e-08,  1.4527e-08,  5.7051e-08,  1.7945e-08,\n",
            "        -1.4069e-08,  8.2285e-10, -6.7447e-08,  4.3591e-11,  7.5804e-08,\n",
            "        -6.6043e-08,  1.0594e-08, -6.8265e-08,  3.1112e-08,  6.4288e-08,\n",
            "        -3.7731e-08,  1.5382e-08,  1.5437e-08, -2.9847e-08,  2.6007e-09,\n",
            "         1.1496e-09, -1.9119e-08,  6.4917e-08,  6.1017e-08, -8.7755e-08,\n",
            "         1.1835e-08,  3.6788e-08,  1.5276e-08])\n",
            "token_encoder.transformer_encoder.layers.5.norm2.weight tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "token_encoder.transformer_encoder.layers.5.norm2.bias tensor([-1.0463e-08, -8.6756e-10, -9.0519e-09,  2.7893e-09, -7.4140e-09,\n",
            "        -2.1965e-08, -1.9442e-08,  9.6218e-09, -6.7998e-09, -2.5353e-08,\n",
            "         1.5820e-08,  7.1941e-10,  9.0724e-09, -2.1230e-08,  1.0991e-08,\n",
            "         2.2000e-09,  1.8562e-08, -2.2232e-08,  1.0768e-09,  1.5607e-08,\n",
            "         8.0787e-09,  2.2499e-08, -1.7859e-08,  2.2777e-08, -8.6264e-09,\n",
            "         2.2034e-08, -1.5373e-08, -6.5467e-10, -6.7635e-09,  2.0007e-08,\n",
            "         9.2841e-09, -2.6858e-08, -5.3305e-09,  3.3209e-09,  1.4576e-08,\n",
            "         1.4603e-08, -2.2500e-08, -1.2254e-08, -1.1259e-08, -1.7462e-08,\n",
            "        -9.1028e-09,  9.1851e-10,  1.1787e-08, -6.6583e-09, -2.3170e-09,\n",
            "         3.6068e-09,  8.7710e-09,  6.6442e-09,  4.4155e-08, -1.8259e-08,\n",
            "        -2.4811e-08,  1.1527e-08,  2.4508e-08,  1.0117e-08, -1.4774e-08,\n",
            "         4.3205e-08, -3.5856e-09,  1.1059e-08,  5.3270e-09,  9.6729e-09,\n",
            "         2.3573e-09,  6.6948e-09,  4.6004e-09,  1.0356e-08,  1.2910e-08,\n",
            "         2.1730e-09, -1.5232e-09,  2.2709e-08,  1.5452e-08,  7.8553e-09,\n",
            "         5.0923e-09, -4.9467e-09, -1.3294e-08, -1.8365e-09,  2.5675e-09,\n",
            "         1.1631e-08,  5.3893e-09, -3.5493e-09, -1.6310e-08,  1.1838e-08,\n",
            "         2.1866e-09, -1.5215e-08,  3.9943e-09,  1.5980e-08, -6.8899e-09,\n",
            "        -1.8930e-08, -1.6760e-08,  9.5037e-11, -1.1711e-09, -2.1769e-10,\n",
            "        -2.4732e-08, -8.2134e-09, -1.6006e-08,  2.1688e-08, -5.0391e-09,\n",
            "         5.8437e-09,  2.6854e-08,  1.9184e-09,  1.3990e-08,  1.7040e-08,\n",
            "         1.0769e-09, -3.1119e-09, -1.9155e-08, -4.9340e-09, -2.8973e-08,\n",
            "         1.9482e-09, -2.4672e-09, -1.9878e-08, -3.7672e-08, -1.6318e-09,\n",
            "         4.6294e-09, -1.2626e-08, -6.8140e-10,  3.9361e-09, -1.6878e-08,\n",
            "         9.4775e-09,  9.1824e-09, -7.3832e-09,  4.3666e-09, -1.0303e-08,\n",
            "        -2.5804e-08,  3.3941e-08, -1.2437e-08, -1.3589e-08, -9.7734e-09,\n",
            "         2.7908e-08, -7.3216e-09,  1.2100e-08])\n",
            "cnn_encoder.encoder.0.weight tensor([[[[-0.0714,  0.1093,  0.0246, -0.0477, -0.0999],\n",
            "          [ 0.0593,  0.0211,  0.0326,  0.0246, -0.0084],\n",
            "          [-0.0040, -0.0449, -0.0305,  0.0343,  0.0291],\n",
            "          [ 0.0862, -0.0679,  0.0863, -0.1113, -0.0167],\n",
            "          [ 0.0931,  0.0477,  0.0013,  0.0791, -0.0363]],\n",
            "\n",
            "         [[ 0.0978,  0.0095, -0.0134,  0.1050,  0.0890],\n",
            "          [-0.0986, -0.0537, -0.0738,  0.0898, -0.0744],\n",
            "          [ 0.0232, -0.0067,  0.0164, -0.0325,  0.0627],\n",
            "          [-0.0665, -0.0687, -0.0581, -0.0033,  0.0454],\n",
            "          [ 0.0908, -0.1136, -0.0915, -0.0944, -0.0724]],\n",
            "\n",
            "         [[ 0.1150,  0.0366, -0.0823,  0.0526, -0.0198],\n",
            "          [-0.0277, -0.0258, -0.0738, -0.0831,  0.0992],\n",
            "          [ 0.0066,  0.0107, -0.0613, -0.0532, -0.0074],\n",
            "          [-0.0320,  0.0849, -0.1084,  0.0051,  0.0866],\n",
            "          [ 0.0507,  0.0030, -0.0424,  0.0922, -0.0199]]],\n",
            "\n",
            "\n",
            "        [[[-0.0083,  0.0596,  0.0792, -0.0985, -0.0741],\n",
            "          [-0.0740, -0.0077, -0.1082, -0.0701, -0.0682],\n",
            "          [-0.0804, -0.0535,  0.0488, -0.0413, -0.0129],\n",
            "          [-0.0989, -0.0480,  0.0064, -0.0850, -0.0278],\n",
            "          [-0.0992, -0.0219,  0.0767,  0.0535, -0.0935]],\n",
            "\n",
            "         [[-0.0945, -0.0040, -0.0431, -0.0512, -0.1086],\n",
            "          [-0.0862,  0.0538,  0.0800, -0.0633, -0.0738],\n",
            "          [-0.0053,  0.0974,  0.0055, -0.0110,  0.0809],\n",
            "          [-0.1150,  0.0664, -0.0269,  0.1123,  0.0633],\n",
            "          [-0.0016,  0.0567, -0.1116, -0.0885,  0.0770]],\n",
            "\n",
            "         [[ 0.0173,  0.0085, -0.1007,  0.0480, -0.0054],\n",
            "          [-0.0165,  0.0347,  0.0929, -0.0019,  0.0444],\n",
            "          [-0.0174,  0.0667, -0.0606,  0.0300,  0.0270],\n",
            "          [ 0.1119,  0.0260,  0.0183, -0.0907, -0.0497],\n",
            "          [-0.0545,  0.0101,  0.0767, -0.1079,  0.1136]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0823, -0.0915, -0.0291,  0.0237,  0.0178],\n",
            "          [-0.0204, -0.0140,  0.0514,  0.1085, -0.0397],\n",
            "          [ 0.1109, -0.0653,  0.0271, -0.0544, -0.0520],\n",
            "          [-0.0649,  0.0247,  0.0131,  0.0693,  0.0615],\n",
            "          [ 0.0190,  0.0656, -0.0131,  0.0523,  0.0193]],\n",
            "\n",
            "         [[-0.0378,  0.0769,  0.0848, -0.0061,  0.0301],\n",
            "          [-0.0747,  0.0396, -0.0290, -0.1123, -0.0994],\n",
            "          [ 0.0623,  0.0569, -0.0179,  0.1148,  0.0861],\n",
            "          [-0.0551, -0.0070, -0.0430,  0.0103, -0.0424],\n",
            "          [-0.0439,  0.0866, -0.0597, -0.0408,  0.0719]],\n",
            "\n",
            "         [[ 0.0592,  0.0293,  0.0877, -0.0925, -0.0641],\n",
            "          [ 0.0641,  0.0181,  0.0571,  0.0503, -0.0606],\n",
            "          [ 0.0164, -0.1145, -0.0049,  0.1118, -0.0050],\n",
            "          [-0.0878, -0.0150, -0.0820,  0.0777, -0.1115],\n",
            "          [ 0.0324,  0.0524,  0.1015,  0.0220,  0.0930]]],\n",
            "\n",
            "\n",
            "        [[[-0.0278, -0.0295,  0.0585,  0.0191, -0.0598],\n",
            "          [-0.0262, -0.1139,  0.0051, -0.0312, -0.0199],\n",
            "          [ 0.1148,  0.0388, -0.0356,  0.0705,  0.0307],\n",
            "          [ 0.0001,  0.0903,  0.0921,  0.0345,  0.0822],\n",
            "          [-0.0446,  0.0701,  0.0691,  0.0766,  0.0716]],\n",
            "\n",
            "         [[-0.0067, -0.0016, -0.0074, -0.0867,  0.0710],\n",
            "          [-0.0268, -0.0164, -0.1016, -0.0901, -0.0154],\n",
            "          [ 0.0971, -0.0076,  0.0660, -0.0787,  0.0447],\n",
            "          [ 0.0975, -0.0628,  0.0274, -0.1035, -0.0467],\n",
            "          [-0.0880, -0.0064, -0.0516,  0.0873, -0.0626]],\n",
            "\n",
            "         [[ 0.0187,  0.0105,  0.0059, -0.1026,  0.0148],\n",
            "          [ 0.0531,  0.0098,  0.1070,  0.0325, -0.1066],\n",
            "          [-0.0590,  0.0477, -0.0346, -0.0094,  0.0945],\n",
            "          [ 0.0689,  0.0882,  0.0060, -0.0272, -0.0067],\n",
            "          [ 0.0393, -0.0561, -0.0977,  0.0363, -0.1041]]],\n",
            "\n",
            "\n",
            "        [[[-0.0310,  0.0350, -0.0724, -0.0763,  0.0828],\n",
            "          [-0.0323,  0.0254,  0.0609,  0.0876, -0.0303],\n",
            "          [ 0.0936, -0.0258,  0.0582, -0.0724,  0.0727],\n",
            "          [-0.0572, -0.0085, -0.0931,  0.0562, -0.0504],\n",
            "          [-0.1061,  0.0487,  0.0084,  0.0330, -0.0490]],\n",
            "\n",
            "         [[-0.0957,  0.1111, -0.0578,  0.0693, -0.0867],\n",
            "          [ 0.0391,  0.0304,  0.0146,  0.0824, -0.0546],\n",
            "          [-0.0691, -0.0391, -0.1055, -0.0542,  0.0890],\n",
            "          [ 0.0254, -0.0854, -0.0487,  0.0524,  0.0910],\n",
            "          [ 0.0620, -0.0058, -0.0776, -0.1049, -0.0834]],\n",
            "\n",
            "         [[ 0.0852,  0.0551,  0.0815,  0.0687, -0.0054],\n",
            "          [-0.0851,  0.0570, -0.0042, -0.0199,  0.1075],\n",
            "          [-0.0518,  0.0928,  0.0917,  0.0747,  0.0358],\n",
            "          [ 0.0585, -0.0934, -0.0772,  0.0598, -0.0563],\n",
            "          [-0.0329, -0.0644, -0.0829, -0.0374, -0.0855]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0779,  0.0963, -0.1019,  0.0225, -0.0596],\n",
            "          [-0.0079,  0.0134, -0.0503,  0.0405,  0.0759],\n",
            "          [-0.1098, -0.0657,  0.0496,  0.0963, -0.1097],\n",
            "          [ 0.0141, -0.0039, -0.0049,  0.0621, -0.0415],\n",
            "          [ 0.0498, -0.0902, -0.1077,  0.0817, -0.0745]],\n",
            "\n",
            "         [[-0.0131, -0.0032,  0.0411,  0.0125,  0.0877],\n",
            "          [ 0.0732, -0.0323,  0.0863,  0.0943,  0.0734],\n",
            "          [-0.0324,  0.1048, -0.0929, -0.0289,  0.0373],\n",
            "          [ 0.0618, -0.0719,  0.0555, -0.0727, -0.0145],\n",
            "          [-0.0652,  0.0591,  0.0448,  0.0317,  0.0411]],\n",
            "\n",
            "         [[ 0.1143,  0.0708, -0.1113,  0.0410,  0.0766],\n",
            "          [ 0.0072, -0.0135, -0.1083,  0.0876, -0.0753],\n",
            "          [ 0.1154, -0.0536, -0.0500,  0.0613,  0.0711],\n",
            "          [-0.1095,  0.1038,  0.0753,  0.0627, -0.0368],\n",
            "          [ 0.0096, -0.1071, -0.1150,  0.0359,  0.0062]]]])\n",
            "cnn_encoder.encoder.0.bias tensor([-0.0627, -0.0175, -0.1017,  0.0172, -0.1033, -0.0321])\n",
            "cnn_encoder.encoder.3.weight tensor([[[[ 0.0238, -0.0209, -0.0378, -0.0073,  0.0214],\n",
            "          [ 0.0374,  0.0441, -0.0020, -0.0207, -0.0703],\n",
            "          [-0.0704,  0.0301,  0.0226,  0.0762, -0.0687],\n",
            "          [ 0.0699, -0.0443, -0.0711,  0.0354,  0.0364],\n",
            "          [ 0.0487, -0.0569,  0.0276, -0.0564,  0.0185]],\n",
            "\n",
            "         [[ 0.0681, -0.0575,  0.0149, -0.0614,  0.0576],\n",
            "          [-0.0418, -0.0100, -0.0661, -0.0313,  0.0683],\n",
            "          [ 0.0723, -0.0578, -0.0787, -0.0582, -0.0067],\n",
            "          [-0.0493,  0.0157, -0.0645,  0.0436,  0.0768],\n",
            "          [-0.0801, -0.0178, -0.0583,  0.0576, -0.0688]],\n",
            "\n",
            "         [[-0.0317, -0.0480,  0.0670, -0.0678, -0.0494],\n",
            "          [ 0.0669,  0.0649,  0.0774, -0.0715, -0.0273],\n",
            "          [-0.0046,  0.0305,  0.0591,  0.0466,  0.0046],\n",
            "          [ 0.0338, -0.0468,  0.0021, -0.0397,  0.0481],\n",
            "          [-0.0812,  0.0206, -0.0216, -0.0573, -0.0614]],\n",
            "\n",
            "         [[ 0.0815, -0.0293,  0.0443, -0.0680,  0.0352],\n",
            "          [ 0.0286,  0.0349, -0.0780,  0.0566,  0.0028],\n",
            "          [-0.0122,  0.0056, -0.0012, -0.0631,  0.0366],\n",
            "          [-0.0156, -0.0663,  0.0012,  0.0614,  0.0432],\n",
            "          [-0.0478, -0.0435,  0.0049,  0.0246,  0.0559]],\n",
            "\n",
            "         [[ 0.0127, -0.0592, -0.0775, -0.0553,  0.0697],\n",
            "          [ 0.0114, -0.0388, -0.0625,  0.0069, -0.0135],\n",
            "          [-0.0206, -0.0566, -0.0404, -0.0701,  0.0290],\n",
            "          [-0.0740, -0.0227, -0.0603,  0.0672,  0.0529],\n",
            "          [ 0.0577, -0.0138,  0.0605, -0.0436,  0.0202]],\n",
            "\n",
            "         [[ 0.0730,  0.0417, -0.0752,  0.0147, -0.0545],\n",
            "          [ 0.0554, -0.0666,  0.0118,  0.0705,  0.0548],\n",
            "          [-0.0379,  0.0685, -0.0344,  0.0167, -0.0599],\n",
            "          [-0.0357, -0.0641, -0.0783, -0.0029, -0.0540],\n",
            "          [-0.0613,  0.0472, -0.0384,  0.0213,  0.0135]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0255, -0.0581,  0.0637, -0.0393,  0.0024],\n",
            "          [ 0.0556, -0.0016, -0.0737, -0.0160,  0.0175],\n",
            "          [-0.0030, -0.0272, -0.0710,  0.0189, -0.0628],\n",
            "          [-0.0420,  0.0773, -0.0257, -0.0604,  0.0578],\n",
            "          [ 0.0194,  0.0667,  0.0535, -0.0758, -0.0583]],\n",
            "\n",
            "         [[-0.0197, -0.0499, -0.0130, -0.0797, -0.0434],\n",
            "          [-0.0348, -0.0046,  0.0735, -0.0353, -0.0332],\n",
            "          [ 0.0815, -0.0034, -0.0485, -0.0282,  0.0071],\n",
            "          [ 0.0109,  0.0520,  0.0276,  0.0494, -0.0617],\n",
            "          [-0.0411, -0.0347,  0.0598,  0.0454,  0.0247]],\n",
            "\n",
            "         [[-0.0256, -0.0754,  0.0047, -0.0161, -0.0553],\n",
            "          [ 0.0355, -0.0749,  0.0719,  0.0483,  0.0176],\n",
            "          [ 0.0198,  0.0492, -0.0482,  0.0211, -0.0200],\n",
            "          [ 0.0669, -0.0236, -0.0605, -0.0701, -0.0378],\n",
            "          [-0.0473, -0.0577,  0.0106,  0.0764, -0.0103]],\n",
            "\n",
            "         [[ 0.0025, -0.0709, -0.0049,  0.0558,  0.0507],\n",
            "          [-0.0159,  0.0320,  0.0269,  0.0462,  0.0203],\n",
            "          [-0.0458,  0.0772, -0.0177,  0.0109, -0.0337],\n",
            "          [ 0.0585, -0.0282,  0.0389,  0.0271,  0.0213],\n",
            "          [ 0.0695, -0.0145, -0.0242,  0.0275,  0.0375]],\n",
            "\n",
            "         [[-0.0435, -0.0635,  0.0791, -0.0336, -0.0297],\n",
            "          [-0.0529, -0.0720, -0.0211,  0.0012, -0.0344],\n",
            "          [-0.0718, -0.0295, -0.0573, -0.0632, -0.0741],\n",
            "          [ 0.0416,  0.0605, -0.0414, -0.0247, -0.0329],\n",
            "          [-0.0506,  0.0162,  0.0226,  0.0118, -0.0359]],\n",
            "\n",
            "         [[ 0.0341,  0.0188,  0.0016, -0.0224, -0.0290],\n",
            "          [ 0.0705,  0.0706,  0.0413,  0.0108,  0.0373],\n",
            "          [-0.0787, -0.0695, -0.0321,  0.0669, -0.0070],\n",
            "          [ 0.0454,  0.0710, -0.0222,  0.0757,  0.0645],\n",
            "          [-0.0391,  0.0511,  0.0062, -0.0529, -0.0737]]],\n",
            "\n",
            "\n",
            "        [[[-0.0749,  0.0220, -0.0539, -0.0336,  0.0137],\n",
            "          [-0.0364, -0.0195, -0.0449, -0.0194, -0.0248],\n",
            "          [-0.0472, -0.0047, -0.0050,  0.0328, -0.0492],\n",
            "          [-0.0543,  0.0599,  0.0456, -0.0163,  0.0206],\n",
            "          [-0.0068, -0.0681, -0.0032,  0.0440, -0.0570]],\n",
            "\n",
            "         [[-0.0415,  0.0517, -0.0675, -0.0202,  0.0496],\n",
            "          [ 0.0458,  0.0586, -0.0609,  0.0135,  0.0604],\n",
            "          [ 0.0091,  0.0416, -0.0393, -0.0109, -0.0185],\n",
            "          [ 0.0519, -0.0473, -0.0385,  0.0331, -0.0496],\n",
            "          [ 0.0747,  0.0223, -0.0483, -0.0660,  0.0748]],\n",
            "\n",
            "         [[ 0.0034,  0.0623,  0.0640,  0.0276,  0.0075],\n",
            "          [-0.0448, -0.0191,  0.0528, -0.0752,  0.0271],\n",
            "          [ 0.0351, -0.0295, -0.0467,  0.0764,  0.0309],\n",
            "          [-0.0462, -0.0390,  0.0478,  0.0407,  0.0332],\n",
            "          [-0.0724,  0.0419, -0.0391,  0.0085, -0.0473]],\n",
            "\n",
            "         [[ 0.0221, -0.0358, -0.0649,  0.0093,  0.0166],\n",
            "          [-0.0672,  0.0710, -0.0485, -0.0660, -0.0681],\n",
            "          [-0.0749, -0.0315, -0.0493, -0.0302, -0.0325],\n",
            "          [-0.0049,  0.0053,  0.0271,  0.0587, -0.0608],\n",
            "          [ 0.0143,  0.0798,  0.0571, -0.0183, -0.0257]],\n",
            "\n",
            "         [[-0.0063,  0.0384, -0.0690,  0.0361,  0.0716],\n",
            "          [-0.0524, -0.0267, -0.0441,  0.0642,  0.0131],\n",
            "          [ 0.0527, -0.0012, -0.0115,  0.0468,  0.0146],\n",
            "          [-0.0098,  0.0217,  0.0609,  0.0558,  0.0707],\n",
            "          [-0.0463, -0.0182, -0.0355, -0.0180, -0.0460]],\n",
            "\n",
            "         [[-0.0235,  0.0813,  0.0664, -0.0254, -0.0227],\n",
            "          [ 0.0109,  0.0733,  0.0403,  0.0691, -0.0270],\n",
            "          [-0.0542, -0.0666, -0.0708, -0.0635,  0.0665],\n",
            "          [-0.0681,  0.0059,  0.0583,  0.0096,  0.0650],\n",
            "          [ 0.0754, -0.0749, -0.0195, -0.0708, -0.0450]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0133, -0.0086, -0.0120,  0.0566, -0.0087],\n",
            "          [-0.0076,  0.0338,  0.0445,  0.0076, -0.0416],\n",
            "          [ 0.0454, -0.0770, -0.0237,  0.0655, -0.0296],\n",
            "          [-0.0320,  0.0561, -0.0713, -0.0545, -0.0495],\n",
            "          [ 0.0198,  0.0490, -0.0791,  0.0499,  0.0084]],\n",
            "\n",
            "         [[ 0.0219,  0.0667, -0.0373,  0.0217,  0.0776],\n",
            "          [-0.0256,  0.0075, -0.0338, -0.0164,  0.0649],\n",
            "          [-0.0588,  0.0805,  0.0575, -0.0689, -0.0641],\n",
            "          [-0.0305, -0.0264,  0.0117,  0.0305, -0.0123],\n",
            "          [ 0.0115, -0.0728,  0.0313,  0.0622,  0.0710]],\n",
            "\n",
            "         [[-0.0216, -0.0767,  0.0369,  0.0069,  0.0084],\n",
            "          [-0.0443,  0.0545, -0.0792,  0.0195, -0.0672],\n",
            "          [-0.0681, -0.0361, -0.0743, -0.0719,  0.0688],\n",
            "          [-0.0237, -0.0800, -0.0037,  0.0312, -0.0476],\n",
            "          [ 0.0395,  0.0396, -0.0358, -0.0111, -0.0016]],\n",
            "\n",
            "         [[-0.0145,  0.0471, -0.0545, -0.0035, -0.0688],\n",
            "          [-0.0044,  0.0635,  0.0585, -0.0551, -0.0812],\n",
            "          [-0.0340,  0.0475,  0.0168,  0.0275,  0.0056],\n",
            "          [-0.0325, -0.0462,  0.0535,  0.0088, -0.0776],\n",
            "          [-0.0350,  0.0353, -0.0555,  0.0375,  0.0285]],\n",
            "\n",
            "         [[ 0.0120,  0.0800, -0.0551, -0.0306,  0.0550],\n",
            "          [ 0.0418, -0.0272, -0.0589, -0.0576,  0.0679],\n",
            "          [-0.0368,  0.0759, -0.0346,  0.0449,  0.0764],\n",
            "          [ 0.0695,  0.0669,  0.0151, -0.0733,  0.0325],\n",
            "          [-0.0460, -0.0634,  0.0458, -0.0648,  0.0318]],\n",
            "\n",
            "         [[ 0.0292,  0.0792, -0.0802, -0.0200,  0.0457],\n",
            "          [-0.0169, -0.0806,  0.0082,  0.0611, -0.0074],\n",
            "          [ 0.0623, -0.0250, -0.0381, -0.0781,  0.0125],\n",
            "          [ 0.0391,  0.0260, -0.0404, -0.0177,  0.0528],\n",
            "          [-0.0615,  0.0026,  0.0296,  0.0032, -0.0493]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0271,  0.0238,  0.0179,  0.0741,  0.0268],\n",
            "          [ 0.0272,  0.0707,  0.0771,  0.0117, -0.0261],\n",
            "          [ 0.0201, -0.0330, -0.0135,  0.0441,  0.0339],\n",
            "          [ 0.0768, -0.0419,  0.0108,  0.0760, -0.0794],\n",
            "          [-0.0647, -0.0514, -0.0309, -0.0094, -0.0205]],\n",
            "\n",
            "         [[ 0.0345, -0.0379,  0.0055, -0.0101,  0.0040],\n",
            "          [-0.0341, -0.0713, -0.0585, -0.0478,  0.0216],\n",
            "          [-0.0058, -0.0464, -0.0308, -0.0516,  0.0595],\n",
            "          [-0.0592, -0.0430,  0.0043, -0.0141, -0.0748],\n",
            "          [-0.0688, -0.0016,  0.0147, -0.0662, -0.0779]],\n",
            "\n",
            "         [[-0.0433, -0.0814, -0.0155, -0.0430, -0.0410],\n",
            "          [ 0.0217, -0.0618, -0.0220,  0.0196,  0.0374],\n",
            "          [ 0.0815, -0.0563,  0.0202,  0.0749,  0.0791],\n",
            "          [-0.0599,  0.0329,  0.0257,  0.0352,  0.0550],\n",
            "          [-0.0395,  0.0268, -0.0358, -0.0772,  0.0003]],\n",
            "\n",
            "         [[ 0.0099, -0.0495,  0.0269,  0.0674,  0.0537],\n",
            "          [ 0.0239,  0.0179, -0.0059,  0.0242, -0.0689],\n",
            "          [-0.0123, -0.0247, -0.0517, -0.0808, -0.0327],\n",
            "          [-0.0224,  0.0742,  0.0313, -0.0132,  0.0509],\n",
            "          [ 0.0101, -0.0120,  0.0075, -0.0703,  0.0123]],\n",
            "\n",
            "         [[ 0.0028, -0.0746,  0.0703,  0.0598, -0.0448],\n",
            "          [ 0.0678,  0.0307, -0.0277,  0.0244, -0.0306],\n",
            "          [ 0.0625,  0.0337, -0.0526, -0.0253, -0.0210],\n",
            "          [-0.0668,  0.0593, -0.0680, -0.0269, -0.0635],\n",
            "          [ 0.0781,  0.0598, -0.0147, -0.0090,  0.0175]],\n",
            "\n",
            "         [[-0.0751, -0.0583, -0.0059,  0.0810, -0.0777],\n",
            "          [ 0.0074,  0.0699,  0.0097,  0.0047,  0.0150],\n",
            "          [-0.0740,  0.0376, -0.0733,  0.0394,  0.0104],\n",
            "          [-0.0086,  0.0792, -0.0682,  0.0497,  0.0427],\n",
            "          [-0.0610,  0.0033, -0.0093,  0.0448,  0.0598]]],\n",
            "\n",
            "\n",
            "        [[[-0.0143, -0.0220,  0.0631,  0.0289, -0.0182],\n",
            "          [ 0.0039, -0.0651,  0.0443,  0.0501, -0.0595],\n",
            "          [-0.0536,  0.0058,  0.0480, -0.0535, -0.0277],\n",
            "          [-0.0630, -0.0001,  0.0044, -0.0197, -0.0489],\n",
            "          [-0.0247,  0.0655,  0.0142,  0.0806, -0.0624]],\n",
            "\n",
            "         [[ 0.0233,  0.0674, -0.0541, -0.0635,  0.0179],\n",
            "          [-0.0279,  0.0187,  0.0301, -0.0416,  0.0599],\n",
            "          [-0.0571,  0.0744, -0.0427,  0.0125, -0.0280],\n",
            "          [-0.0463,  0.0313, -0.0665,  0.0688,  0.0517],\n",
            "          [ 0.0530, -0.0374, -0.0553, -0.0742, -0.0364]],\n",
            "\n",
            "         [[ 0.0076,  0.0176,  0.0202,  0.0321, -0.0525],\n",
            "          [-0.0790, -0.0434,  0.0462, -0.0145, -0.0588],\n",
            "          [ 0.0266,  0.0431,  0.0603, -0.0058,  0.0698],\n",
            "          [-0.0156, -0.0282,  0.0258, -0.0633,  0.0743],\n",
            "          [ 0.0012, -0.0402,  0.0514, -0.0023,  0.0244]],\n",
            "\n",
            "         [[-0.0558,  0.0073,  0.0436,  0.0081, -0.0263],\n",
            "          [-0.0641,  0.0152, -0.0368,  0.0361, -0.0704],\n",
            "          [ 0.0138,  0.0571, -0.0677, -0.0381, -0.0114],\n",
            "          [-0.0602, -0.0717,  0.0371,  0.0580,  0.0556],\n",
            "          [ 0.0813,  0.0423, -0.0138, -0.0204,  0.0344]],\n",
            "\n",
            "         [[ 0.0405,  0.0424, -0.0653,  0.0534, -0.0207],\n",
            "          [-0.0343, -0.0685, -0.0510, -0.0246, -0.0745],\n",
            "          [-0.0243, -0.0484,  0.0722,  0.0664, -0.0018],\n",
            "          [-0.0438,  0.0436,  0.0684,  0.0245, -0.0052],\n",
            "          [-0.0780, -0.0372,  0.0605,  0.0050, -0.0761]],\n",
            "\n",
            "         [[ 0.0417, -0.0230,  0.0297,  0.0495,  0.0520],\n",
            "          [-0.0014,  0.0784,  0.0073, -0.0807, -0.0105],\n",
            "          [-0.0565,  0.0585, -0.0430, -0.0195, -0.0233],\n",
            "          [ 0.0757,  0.0249,  0.0182, -0.0594,  0.0308],\n",
            "          [-0.0059,  0.0348,  0.0762, -0.0185,  0.0497]]]])\n",
            "cnn_encoder.encoder.3.bias tensor([-0.0188, -0.0619, -0.0704, -0.0805, -0.0108, -0.0681,  0.0026, -0.0587,\n",
            "        -0.0578,  0.0802, -0.0804, -0.0399,  0.0015, -0.0718,  0.0654, -0.0544])\n",
            "cnn_encoder.encoder.7.weight tensor([[ 4.0672e-02,  2.9101e-02,  2.0612e-03,  ..., -3.6387e-02,\n",
            "         -2.6224e-02,  4.4303e-02],\n",
            "        [-1.1747e-02, -2.9515e-02, -1.5581e-03,  ..., -2.0430e-02,\n",
            "         -3.8544e-02,  1.2936e-02],\n",
            "        [-1.0737e-03,  1.8477e-02, -3.8721e-02,  ..., -3.7003e-02,\n",
            "         -3.1447e-02, -1.2528e-02],\n",
            "        ...,\n",
            "        [ 4.8838e-02,  3.2272e-02,  1.9333e-02,  ..., -4.9468e-02,\n",
            "          1.6740e-02, -1.7280e-02],\n",
            "        [ 3.8176e-02,  1.4686e-02, -3.1565e-02,  ...,  3.5029e-02,\n",
            "          4.5449e-02, -5.9605e-07],\n",
            "        [ 1.3736e-02, -1.2789e-02,  2.7286e-02,  ...,  2.5895e-02,\n",
            "          4.2269e-02, -4.1720e-02]])\n",
            "cnn_encoder.encoder.7.bias tensor([-0.0312, -0.0161, -0.0163,  0.0363,  0.0216, -0.0244, -0.0158, -0.0197,\n",
            "         0.0493, -0.0093, -0.0236, -0.0226,  0.0423,  0.0032,  0.0244, -0.0107,\n",
            "        -0.0251, -0.0457, -0.0431,  0.0369,  0.0444, -0.0089,  0.0255,  0.0202,\n",
            "        -0.0328, -0.0342, -0.0087,  0.0271, -0.0007,  0.0095,  0.0057, -0.0412,\n",
            "        -0.0151,  0.0500, -0.0395,  0.0039, -0.0099, -0.0179,  0.0274,  0.0222,\n",
            "         0.0323, -0.0015,  0.0370, -0.0060, -0.0274, -0.0406,  0.0448,  0.0103,\n",
            "        -0.0397,  0.0436,  0.0442, -0.0199, -0.0370,  0.0169,  0.0261,  0.0187,\n",
            "        -0.0005, -0.0335, -0.0234, -0.0195, -0.0262,  0.0005,  0.0294,  0.0468,\n",
            "         0.0144,  0.0447, -0.0022, -0.0148, -0.0379,  0.0085,  0.0226, -0.0185,\n",
            "         0.0024, -0.0264,  0.0493,  0.0051, -0.0283,  0.0312,  0.0422,  0.0386,\n",
            "         0.0343, -0.0339, -0.0411,  0.0454, -0.0058,  0.0275,  0.0411,  0.0378,\n",
            "        -0.0357, -0.0497, -0.0453,  0.0145, -0.0351,  0.0410,  0.0117, -0.0424,\n",
            "         0.0394, -0.0104,  0.0007, -0.0275, -0.0458,  0.0306, -0.0021,  0.0088,\n",
            "        -0.0268,  0.0185,  0.0080, -0.0158,  0.0029, -0.0432, -0.0321, -0.0087,\n",
            "        -0.0244, -0.0046, -0.0244, -0.0207, -0.0047, -0.0006,  0.0363, -0.0313,\n",
            "         0.0198, -0.0419, -0.0354,  0.0488,  0.0130, -0.0465, -0.0213, -0.0411,\n",
            "        -0.0455,  0.0448, -0.0020, -0.0375, -0.0230, -0.0063,  0.0461,  0.0060,\n",
            "         0.0096,  0.0111, -0.0475,  0.0260, -0.0105,  0.0450, -0.0350,  0.0030,\n",
            "        -0.0141, -0.0188, -0.0165,  0.0002, -0.0489, -0.0315,  0.0064,  0.0094,\n",
            "        -0.0454,  0.0493, -0.0017, -0.0415,  0.0388,  0.0176,  0.0127, -0.0169,\n",
            "        -0.0076,  0.0015, -0.0440, -0.0351,  0.0044, -0.0260,  0.0236, -0.0051,\n",
            "        -0.0128, -0.0287, -0.0449,  0.0077, -0.0211,  0.0382,  0.0270, -0.0441,\n",
            "         0.0297,  0.0460,  0.0474,  0.0114, -0.0313, -0.0219,  0.0213, -0.0037,\n",
            "        -0.0325, -0.0213,  0.0124, -0.0165,  0.0190,  0.0345,  0.0402,  0.0362,\n",
            "        -0.0012, -0.0347, -0.0413,  0.0479, -0.0385,  0.0486, -0.0196,  0.0044,\n",
            "         0.0081,  0.0222, -0.0061, -0.0258,  0.0353,  0.0316, -0.0018, -0.0358,\n",
            "         0.0185, -0.0321, -0.0466, -0.0486, -0.0153, -0.0017,  0.0127,  0.0019,\n",
            "         0.0229,  0.0317, -0.0021, -0.0140, -0.0174,  0.0499,  0.0009, -0.0411,\n",
            "         0.0133, -0.0024, -0.0291,  0.0357,  0.0303,  0.0011,  0.0233,  0.0429,\n",
            "        -0.0299,  0.0233, -0.0325, -0.0207,  0.0042, -0.0140, -0.0277,  0.0181,\n",
            "        -0.0307, -0.0352,  0.0135,  0.0199, -0.0079, -0.0174,  0.0372,  0.0085,\n",
            "        -0.0006, -0.0491,  0.0226, -0.0311, -0.0155,  0.0322, -0.0111,  0.0132])\n",
            "cnn_encoder.encoder.9.weight tensor([[-0.0573, -0.0380, -0.0546,  ..., -0.0177,  0.0509,  0.0329],\n",
            "        [ 0.0454,  0.0293,  0.0010,  ...,  0.0220,  0.0275, -0.0303],\n",
            "        [-0.0304,  0.0603,  0.0005,  ...,  0.0066,  0.0363,  0.0291],\n",
            "        ...,\n",
            "        [ 0.0552,  0.0333, -0.0109,  ..., -0.0281, -0.0133, -0.0056],\n",
            "        [ 0.0043,  0.0094,  0.0345,  ..., -0.0292, -0.0495,  0.0599],\n",
            "        [ 0.0482, -0.0096, -0.0457,  ..., -0.0083, -0.0567, -0.0582]])\n",
            "cnn_encoder.encoder.9.bias tensor([ 0.0143,  0.0057,  0.0017, -0.0212,  0.0171, -0.0590, -0.0090,  0.0604,\n",
            "        -0.0017, -0.0226, -0.0332,  0.0330, -0.0323,  0.0411,  0.0034, -0.0155,\n",
            "         0.0398,  0.0619, -0.0505,  0.0107, -0.0433,  0.0104, -0.0139, -0.0305,\n",
            "        -0.0545,  0.0617, -0.0227, -0.0074, -0.0378,  0.0351,  0.0538,  0.0003,\n",
            "        -0.0273, -0.0560, -0.0181, -0.0262, -0.0028,  0.0498,  0.0318,  0.0174,\n",
            "         0.0517,  0.0317, -0.0284, -0.0386, -0.0126, -0.0181,  0.0109, -0.0083,\n",
            "         0.0499,  0.0262, -0.0213,  0.0566,  0.0399,  0.0032,  0.0347,  0.0575,\n",
            "         0.0370, -0.0368, -0.0214,  0.0234,  0.0307,  0.0189, -0.0180, -0.0225,\n",
            "         0.0308, -0.0083,  0.0224,  0.0071, -0.0118,  0.0123,  0.0386,  0.0336,\n",
            "        -0.0187, -0.0406, -0.0350, -0.0358,  0.0084,  0.0608, -0.0128, -0.0214,\n",
            "         0.0069,  0.0531,  0.0364,  0.0108, -0.0263,  0.0618, -0.0511, -0.0352,\n",
            "        -0.0584, -0.0044, -0.0134, -0.0355,  0.0020,  0.0262,  0.0013,  0.0419,\n",
            "         0.0451, -0.0596,  0.0490,  0.0417, -0.0241, -0.0276, -0.0370,  0.0590,\n",
            "        -0.0159, -0.0126, -0.0533,  0.0034, -0.0233, -0.0010, -0.0410, -0.0494,\n",
            "         0.0547, -0.0342,  0.0497, -0.0564, -0.0423, -0.0364,  0.0075, -0.0555,\n",
            "        -0.0201, -0.0434, -0.0084, -0.0454, -0.0439,  0.0493, -0.0573,  0.0519])\n",
            "concat.weight tensor([[-0.0203, -0.0209,  0.0588,  ..., -0.0219, -0.0277, -0.0340],\n",
            "        [-0.0395, -0.0017,  0.0329,  ..., -0.0559, -0.0132, -0.0328],\n",
            "        [ 0.0350,  0.0237,  0.0312,  ..., -0.0319, -0.0078,  0.0103],\n",
            "        ...,\n",
            "        [-0.0538,  0.0025,  0.0012,  ..., -0.0579, -0.0509,  0.0036],\n",
            "        [-0.0239,  0.0621, -0.0240,  ...,  0.0024, -0.0518, -0.0619],\n",
            "        [-0.0596,  0.0133,  0.0175,  ...,  0.0102,  0.0359,  0.0087]])\n",
            "concat.bias tensor([-0.0062, -0.0217, -0.0494,  0.0360, -0.0379, -0.0168, -0.0014,  0.0173,\n",
            "         0.0499, -0.0386,  0.0496, -0.0565, -0.0127, -0.0474,  0.0101,  0.0491,\n",
            "         0.0186, -0.0355, -0.0528,  0.0509,  0.0346, -0.0129,  0.0610,  0.0233,\n",
            "         0.0478,  0.0433, -0.0281,  0.0026,  0.0417, -0.0520,  0.0518,  0.0209,\n",
            "         0.0510, -0.0049, -0.0278,  0.0120,  0.0082,  0.0341, -0.0146,  0.0496,\n",
            "        -0.0567, -0.0140, -0.0202, -0.0202, -0.0449,  0.0111,  0.0483,  0.0138,\n",
            "         0.0577, -0.0477, -0.0387,  0.0277, -0.0180,  0.0141,  0.0618,  0.0475,\n",
            "         0.0577, -0.0416, -0.0428, -0.0273,  0.0423, -0.0137, -0.0504,  0.0505,\n",
            "        -0.0275, -0.0310, -0.0280, -0.0492,  0.0158, -0.0206,  0.0102, -0.0375,\n",
            "         0.0613, -0.0194,  0.0104,  0.0114,  0.0296, -0.0395,  0.0207, -0.0236,\n",
            "        -0.0313,  0.0489,  0.0428,  0.0430, -0.0028,  0.0137, -0.0080, -0.0185,\n",
            "         0.0188, -0.0336,  0.0496,  0.0452, -0.0537,  0.0030,  0.0325, -0.0530,\n",
            "        -0.0345,  0.0521, -0.0177, -0.0159, -0.0195,  0.0548,  0.0320,  0.0599,\n",
            "        -0.0496, -0.0009,  0.0354, -0.0582,  0.0469,  0.0597, -0.0102,  0.0007,\n",
            "         0.0026, -0.0063,  0.0315, -0.0372,  0.0181,  0.0446,  0.0220,  0.0357,\n",
            "         0.0374,  0.0051, -0.0497,  0.0156, -0.0510, -0.0114,  0.0144,  0.0051])\n",
            "fc.weight tensor([[ 0.0080, -0.0757,  0.0878,  ..., -0.0620,  0.0576,  0.0373],\n",
            "        [ 0.0774,  0.0163, -0.0820,  ..., -0.0331, -0.0232, -0.0539],\n",
            "        [ 0.0625,  0.0736,  0.0790,  ...,  0.0159, -0.0651, -0.0879],\n",
            "        ...,\n",
            "        [ 0.0031, -0.0107,  0.0669,  ...,  0.0501,  0.0769, -0.0180],\n",
            "        [ 0.0831,  0.0430,  0.0188,  ...,  0.0080, -0.0652,  0.0329],\n",
            "        [ 0.0586, -0.0035, -0.0283,  ...,  0.0050,  0.0520,  0.0367]])\n",
            "fc.bias tensor([ 0.0751,  0.0507,  0.0081,  0.0458, -0.0118,  0.0641,  0.0313,  0.0180,\n",
            "        -0.0839, -0.0629, -0.0084,  0.0857, -0.0657, -0.0629,  0.0823,  0.0416,\n",
            "         0.0872, -0.0625, -0.0082,  0.0636,  0.0755, -0.0784, -0.0380, -0.0507,\n",
            "        -0.0814,  0.0696, -0.0448,  0.0727,  0.0349,  0.0719, -0.0808,  0.0005,\n",
            "         0.0227,  0.0535, -0.0625, -0.0427,  0.0362,  0.0326, -0.0642, -0.0366,\n",
            "        -0.0712,  0.0236, -0.0606,  0.0169, -0.0121, -0.0832,  0.0587, -0.0086,\n",
            "        -0.0797,  0.0153, -0.0412,  0.0763, -0.0297,  0.0830,  0.0516,  0.0279,\n",
            "         0.0768, -0.0142, -0.0533, -0.0177, -0.0216, -0.0692, -0.0120, -0.0254])\n",
            "fc2.weight tensor([[ 0.1059, -0.0310,  0.0077, -0.0945, -0.1070, -0.0982,  0.0119,  0.0787,\n",
            "          0.0425,  0.0983,  0.0880, -0.0757, -0.0299,  0.0039,  0.0210, -0.0083,\n",
            "         -0.0222, -0.0667,  0.0350, -0.0165,  0.0105, -0.0073,  0.0865,  0.0528,\n",
            "          0.1199,  0.0080,  0.1169, -0.0530,  0.0741,  0.0346,  0.0873,  0.1067,\n",
            "         -0.0065,  0.0636,  0.0777, -0.0530,  0.0345,  0.0829, -0.1168,  0.0855,\n",
            "         -0.0967, -0.0801,  0.0846, -0.0548,  0.0803, -0.0136,  0.0910,  0.0568,\n",
            "         -0.0594,  0.0595,  0.0403, -0.0273, -0.1198, -0.0651,  0.0132,  0.1146,\n",
            "         -0.1216,  0.0988, -0.0754, -0.0677, -0.1164, -0.0266, -0.1185, -0.1013]])\n",
            "fc2.bias tensor([-0.0311])\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 695,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 404,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.1567)"
            ]
          },
          "execution_count": 404,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tt = torch.tensor([[0.9531, 0.233]]).float()\n",
        "tb = torch.tensor([[1, 0]]).float()\n",
        "criterion(tt, tb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([])\n"
          ]
        }
      ],
      "source": [
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Intiate Sequence, Basically Create the transformermodel..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Training the Embedding Models**\n",
        "\n",
        "Below is the code that allows us to embed our sentence and floating parameters to a higer dimensional space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InajYBPlYpno"
      },
      "source": [
        "**MLP Encoder**\n",
        "\n",
        "Now if you want to share the same MLP encoder for all numerical inputs (regardless of whether they are radius or height measurements,  etc), then your MLP encoder would take in R^1 and output R^d. These are floating point values, for both input and output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUDrvlGoYo0Q",
        "outputId": "69090ab0-6628-4ebb-963b-ed23cd3ee8aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
            "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
            "        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
            "        [ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14]])\n",
            "tensor([[20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
            "        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
            "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
            "        [ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([11, 15,  8,  1, 18, 25, 19, 12, 16, 22,  7, 21, 10, 30,  5, 17,  9,  6,\n",
              "        31, 23,  3, 14, 24,  4, 13, 29, 27, 20, 26,  2, 28,  0])"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ff3 = np.arange(0, 10, 1)\n",
        "ff1 = np.arange(30, 40, 1)\n",
        "ff2 = np.arange(20, 30, 1)\n",
        "ff4 = np.arange(5, 15, 1)\n",
        "\n",
        "idx = torch.tensor(np.array([ff1, ff3, ff2, ff4]))\n",
        "print(idx)\n",
        "\n",
        "idx=idx[torch.randperm(idx.size()[0])]\n",
        "print(idx)\n",
        "\n",
        "torch.randperm(32)\n",
        "\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "177def0c22df55f44c7bc43ed6b35a63880eb2c6466160d1b315a26cc91306d6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
